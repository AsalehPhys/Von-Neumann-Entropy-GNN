{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8270379d-d02d-4309-89e6-d4499b3d5ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 09:08:36 [INFO] Loaded pretrained model successfully\n",
      "2025-02-25 09:08:49 [INFO] Epoch 1/200:\n",
      "2025-02-25 09:08:49 [INFO]   Training Loss: 0.002567\n",
      "2025-02-25 09:08:49 [INFO]   Training MAE: 0.041783\n",
      "2025-02-25 09:08:49 [INFO]   Validation Loss: 0.000933\n",
      "2025-02-25 09:08:49 [INFO]   Validation MAE: 0.024295\n",
      "2025-02-25 09:08:50 [INFO]   Saved new best model (val_loss=0.000933)\n",
      "2025-02-25 09:08:59 [INFO] Epoch 2/200:\n",
      "2025-02-25 09:08:59 [INFO]   Training Loss: 0.001146\n",
      "2025-02-25 09:08:59 [INFO]   Training MAE: 0.028328\n",
      "2025-02-25 09:08:59 [INFO]   Validation Loss: 0.000707\n",
      "2025-02-25 09:08:59 [INFO]   Validation MAE: 0.020978\n",
      "2025-02-25 09:09:00 [INFO]   Saved new best model (val_loss=0.000707)\n",
      "2025-02-25 09:09:09 [INFO] Epoch 3/200:\n",
      "2025-02-25 09:09:09 [INFO]   Training Loss: 0.000948\n",
      "2025-02-25 09:09:09 [INFO]   Training MAE: 0.026270\n",
      "2025-02-25 09:09:09 [INFO]   Validation Loss: 0.000655\n",
      "2025-02-25 09:09:09 [INFO]   Validation MAE: 0.020442\n",
      "2025-02-25 09:09:09 [INFO]   Saved new best model (val_loss=0.000655)\n",
      "2025-02-25 09:09:18 [INFO] Epoch 4/200:\n",
      "2025-02-25 09:09:18 [INFO]   Training Loss: 0.000799\n",
      "2025-02-25 09:09:18 [INFO]   Training MAE: 0.024072\n",
      "2025-02-25 09:09:18 [INFO]   Validation Loss: 0.000568\n",
      "2025-02-25 09:09:18 [INFO]   Validation MAE: 0.019069\n",
      "2025-02-25 09:09:18 [INFO]   Saved new best model (val_loss=0.000568)\n",
      "2025-02-25 09:09:27 [INFO] Epoch 5/200:\n",
      "2025-02-25 09:09:27 [INFO]   Training Loss: 0.000727\n",
      "2025-02-25 09:09:27 [INFO]   Training MAE: 0.023108\n",
      "2025-02-25 09:09:27 [INFO]   Validation Loss: 0.000570\n",
      "2025-02-25 09:09:27 [INFO]   Validation MAE: 0.018617\n",
      "2025-02-25 09:09:37 [INFO] Epoch 6/200:\n",
      "2025-02-25 09:09:37 [INFO]   Training Loss: 0.000723\n",
      "2025-02-25 09:09:37 [INFO]   Training MAE: 0.023382\n",
      "2025-02-25 09:09:37 [INFO]   Validation Loss: 0.000494\n",
      "2025-02-25 09:09:37 [INFO]   Validation MAE: 0.017183\n",
      "2025-02-25 09:09:37 [INFO]   Saved new best model (val_loss=0.000494)\n",
      "2025-02-25 09:09:47 [INFO] Epoch 7/200:\n",
      "2025-02-25 09:09:47 [INFO]   Training Loss: 0.000631\n",
      "2025-02-25 09:09:47 [INFO]   Training MAE: 0.021515\n",
      "2025-02-25 09:09:47 [INFO]   Validation Loss: 0.000454\n",
      "2025-02-25 09:09:47 [INFO]   Validation MAE: 0.016845\n",
      "2025-02-25 09:09:47 [INFO]   Saved new best model (val_loss=0.000454)\n",
      "2025-02-25 09:09:57 [INFO] Epoch 8/200:\n",
      "2025-02-25 09:09:57 [INFO]   Training Loss: 0.000593\n",
      "2025-02-25 09:09:57 [INFO]   Training MAE: 0.020999\n",
      "2025-02-25 09:09:57 [INFO]   Validation Loss: 0.000472\n",
      "2025-02-25 09:09:57 [INFO]   Validation MAE: 0.016647\n",
      "2025-02-25 09:10:06 [INFO] Epoch 9/200:\n",
      "2025-02-25 09:10:06 [INFO]   Training Loss: 0.000584\n",
      "2025-02-25 09:10:06 [INFO]   Training MAE: 0.021259\n",
      "2025-02-25 09:10:06 [INFO]   Validation Loss: 0.000489\n",
      "2025-02-25 09:10:06 [INFO]   Validation MAE: 0.016962\n",
      "2025-02-25 09:10:16 [INFO] Epoch 10/200:\n",
      "2025-02-25 09:10:16 [INFO]   Training Loss: 0.000539\n",
      "2025-02-25 09:10:16 [INFO]   Training MAE: 0.019888\n",
      "2025-02-25 09:10:16 [INFO]   Validation Loss: 0.000439\n",
      "2025-02-25 09:10:16 [INFO]   Validation MAE: 0.016211\n",
      "2025-02-25 09:10:16 [INFO]   Saved new best model (val_loss=0.000439)\n",
      "2025-02-25 09:10:25 [INFO] Epoch 11/200:\n",
      "2025-02-25 09:10:25 [INFO]   Training Loss: 0.000550\n",
      "2025-02-25 09:10:25 [INFO]   Training MAE: 0.019953\n",
      "2025-02-25 09:10:25 [INFO]   Validation Loss: 0.000446\n",
      "2025-02-25 09:10:25 [INFO]   Validation MAE: 0.016420\n",
      "2025-02-25 09:10:35 [INFO] Epoch 12/200:\n",
      "2025-02-25 09:10:35 [INFO]   Training Loss: 0.000509\n",
      "2025-02-25 09:10:35 [INFO]   Training MAE: 0.019831\n",
      "2025-02-25 09:10:35 [INFO]   Validation Loss: 0.000434\n",
      "2025-02-25 09:10:35 [INFO]   Validation MAE: 0.015542\n",
      "2025-02-25 09:10:35 [INFO]   Saved new best model (val_loss=0.000434)\n",
      "2025-02-25 09:10:45 [INFO] Epoch 13/200:\n",
      "2025-02-25 09:10:45 [INFO]   Training Loss: 0.000506\n",
      "2025-02-25 09:10:45 [INFO]   Training MAE: 0.019672\n",
      "2025-02-25 09:10:45 [INFO]   Validation Loss: 0.000437\n",
      "2025-02-25 09:10:45 [INFO]   Validation MAE: 0.015744\n",
      "2025-02-25 09:10:56 [INFO] Epoch 14/200:\n",
      "2025-02-25 09:10:56 [INFO]   Training Loss: 0.000497\n",
      "2025-02-25 09:10:56 [INFO]   Training MAE: 0.019484\n",
      "2025-02-25 09:10:56 [INFO]   Validation Loss: 0.000424\n",
      "2025-02-25 09:10:56 [INFO]   Validation MAE: 0.015339\n",
      "2025-02-25 09:10:56 [INFO]   Saved new best model (val_loss=0.000424)\n",
      "2025-02-25 09:11:06 [INFO] Epoch 15/200:\n",
      "2025-02-25 09:11:06 [INFO]   Training Loss: 0.000526\n",
      "2025-02-25 09:11:06 [INFO]   Training MAE: 0.020160\n",
      "2025-02-25 09:11:06 [INFO]   Validation Loss: 0.000456\n",
      "2025-02-25 09:11:06 [INFO]   Validation MAE: 0.016966\n",
      "2025-02-25 09:11:16 [INFO] Epoch 16/200:\n",
      "2025-02-25 09:11:16 [INFO]   Training Loss: 0.000476\n",
      "2025-02-25 09:11:16 [INFO]   Training MAE: 0.018998\n",
      "2025-02-25 09:11:16 [INFO]   Validation Loss: 0.000481\n",
      "2025-02-25 09:11:16 [INFO]   Validation MAE: 0.017260\n",
      "2025-02-25 09:11:25 [INFO] Epoch 17/200:\n",
      "2025-02-25 09:11:25 [INFO]   Training Loss: 0.000466\n",
      "2025-02-25 09:11:25 [INFO]   Training MAE: 0.019082\n",
      "2025-02-25 09:11:25 [INFO]   Validation Loss: 0.000442\n",
      "2025-02-25 09:11:25 [INFO]   Validation MAE: 0.015680\n",
      "2025-02-25 09:11:35 [INFO] Epoch 18/200:\n",
      "2025-02-25 09:11:35 [INFO]   Training Loss: 0.000477\n",
      "2025-02-25 09:11:35 [INFO]   Training MAE: 0.019200\n",
      "2025-02-25 09:11:35 [INFO]   Validation Loss: 0.000462\n",
      "2025-02-25 09:11:35 [INFO]   Validation MAE: 0.016222\n",
      "2025-02-25 09:11:46 [INFO] Epoch 19/200:\n",
      "2025-02-25 09:11:46 [INFO]   Training Loss: 0.000468\n",
      "2025-02-25 09:11:46 [INFO]   Training MAE: 0.018925\n",
      "2025-02-25 09:11:46 [INFO]   Validation Loss: 0.000417\n",
      "2025-02-25 09:11:46 [INFO]   Validation MAE: 0.015310\n",
      "2025-02-25 09:11:46 [INFO]   Saved new best model (val_loss=0.000417)\n",
      "2025-02-25 09:11:57 [INFO] Epoch 20/200:\n",
      "2025-02-25 09:11:57 [INFO]   Training Loss: 0.000452\n",
      "2025-02-25 09:11:57 [INFO]   Training MAE: 0.018939\n",
      "2025-02-25 09:11:57 [INFO]   Validation Loss: 0.000428\n",
      "2025-02-25 09:11:57 [INFO]   Validation MAE: 0.015647\n",
      "2025-02-25 09:12:08 [INFO] Epoch 21/200:\n",
      "2025-02-25 09:12:08 [INFO]   Training Loss: 0.000509\n",
      "2025-02-25 09:12:08 [INFO]   Training MAE: 0.019936\n",
      "2025-02-25 09:12:08 [INFO]   Validation Loss: 0.000556\n",
      "2025-02-25 09:12:08 [INFO]   Validation MAE: 0.017744\n",
      "2025-02-25 09:12:18 [INFO] Epoch 22/200:\n",
      "2025-02-25 09:12:18 [INFO]   Training Loss: 0.000523\n",
      "2025-02-25 09:12:18 [INFO]   Training MAE: 0.020222\n",
      "2025-02-25 09:12:18 [INFO]   Validation Loss: 0.000516\n",
      "2025-02-25 09:12:18 [INFO]   Validation MAE: 0.017561\n",
      "2025-02-25 09:12:28 [INFO] Epoch 23/200:\n",
      "2025-02-25 09:12:28 [INFO]   Training Loss: 0.000512\n",
      "2025-02-25 09:12:28 [INFO]   Training MAE: 0.020308\n",
      "2025-02-25 09:12:28 [INFO]   Validation Loss: 0.000433\n",
      "2025-02-25 09:12:28 [INFO]   Validation MAE: 0.015331\n",
      "2025-02-25 09:12:37 [INFO] Epoch 24/200:\n",
      "2025-02-25 09:12:37 [INFO]   Training Loss: 0.000502\n",
      "2025-02-25 09:12:37 [INFO]   Training MAE: 0.019888\n",
      "2025-02-25 09:12:37 [INFO]   Validation Loss: 0.000447\n",
      "2025-02-25 09:12:37 [INFO]   Validation MAE: 0.015626\n",
      "2025-02-25 09:12:46 [INFO] Epoch 25/200:\n",
      "2025-02-25 09:12:46 [INFO]   Training Loss: 0.000453\n",
      "2025-02-25 09:12:46 [INFO]   Training MAE: 0.019216\n",
      "2025-02-25 09:12:46 [INFO]   Validation Loss: 0.000392\n",
      "2025-02-25 09:12:46 [INFO]   Validation MAE: 0.014746\n",
      "2025-02-25 09:12:47 [INFO]   Saved new best model (val_loss=0.000392)\n",
      "2025-02-25 09:12:56 [INFO] Epoch 26/200:\n",
      "2025-02-25 09:12:56 [INFO]   Training Loss: 0.000455\n",
      "2025-02-25 09:12:56 [INFO]   Training MAE: 0.019010\n",
      "2025-02-25 09:12:56 [INFO]   Validation Loss: 0.000376\n",
      "2025-02-25 09:12:56 [INFO]   Validation MAE: 0.014874\n",
      "2025-02-25 09:12:56 [INFO]   Saved new best model (val_loss=0.000376)\n",
      "2025-02-25 09:13:06 [INFO] Epoch 27/200:\n",
      "2025-02-25 09:13:06 [INFO]   Training Loss: 0.000421\n",
      "2025-02-25 09:13:06 [INFO]   Training MAE: 0.018161\n",
      "2025-02-25 09:13:06 [INFO]   Validation Loss: 0.000363\n",
      "2025-02-25 09:13:06 [INFO]   Validation MAE: 0.014177\n",
      "2025-02-25 09:13:06 [INFO]   Saved new best model (val_loss=0.000363)\n",
      "2025-02-25 09:13:15 [INFO] Epoch 28/200:\n",
      "2025-02-25 09:13:15 [INFO]   Training Loss: 0.000404\n",
      "2025-02-25 09:13:15 [INFO]   Training MAE: 0.017895\n",
      "2025-02-25 09:13:15 [INFO]   Validation Loss: 0.000392\n",
      "2025-02-25 09:13:15 [INFO]   Validation MAE: 0.014923\n",
      "2025-02-25 09:13:26 [INFO] Epoch 29/200:\n",
      "2025-02-25 09:13:26 [INFO]   Training Loss: 0.000400\n",
      "2025-02-25 09:13:26 [INFO]   Training MAE: 0.018098\n",
      "2025-02-25 09:13:26 [INFO]   Validation Loss: 0.000363\n",
      "2025-02-25 09:13:26 [INFO]   Validation MAE: 0.014520\n",
      "2025-02-25 09:13:37 [INFO] Epoch 30/200:\n",
      "2025-02-25 09:13:37 [INFO]   Training Loss: 0.000413\n",
      "2025-02-25 09:13:37 [INFO]   Training MAE: 0.017909\n",
      "2025-02-25 09:13:37 [INFO]   Validation Loss: 0.000356\n",
      "2025-02-25 09:13:37 [INFO]   Validation MAE: 0.014178\n",
      "2025-02-25 09:13:37 [INFO]   Saved new best model (val_loss=0.000356)\n",
      "2025-02-25 09:13:48 [INFO] Epoch 31/200:\n",
      "2025-02-25 09:13:48 [INFO]   Training Loss: 0.000408\n",
      "2025-02-25 09:13:48 [INFO]   Training MAE: 0.018000\n",
      "2025-02-25 09:13:48 [INFO]   Validation Loss: 0.000359\n",
      "2025-02-25 09:13:48 [INFO]   Validation MAE: 0.015300\n",
      "2025-02-25 09:13:59 [INFO] Epoch 32/200:\n",
      "2025-02-25 09:13:59 [INFO]   Training Loss: 0.000389\n",
      "2025-02-25 09:13:59 [INFO]   Training MAE: 0.017536\n",
      "2025-02-25 09:13:59 [INFO]   Validation Loss: 0.000396\n",
      "2025-02-25 09:13:59 [INFO]   Validation MAE: 0.014905\n",
      "2025-02-25 09:14:10 [INFO] Epoch 33/200:\n",
      "2025-02-25 09:14:10 [INFO]   Training Loss: 0.000392\n",
      "2025-02-25 09:14:10 [INFO]   Training MAE: 0.017930\n",
      "2025-02-25 09:14:10 [INFO]   Validation Loss: 0.000355\n",
      "2025-02-25 09:14:10 [INFO]   Validation MAE: 0.014230\n",
      "2025-02-25 09:14:10 [INFO]   Saved new best model (val_loss=0.000355)\n",
      "2025-02-25 09:14:21 [INFO] Epoch 34/200:\n",
      "2025-02-25 09:14:21 [INFO]   Training Loss: 0.000360\n",
      "2025-02-25 09:14:21 [INFO]   Training MAE: 0.017102\n",
      "2025-02-25 09:14:21 [INFO]   Validation Loss: 0.000363\n",
      "2025-02-25 09:14:21 [INFO]   Validation MAE: 0.014437\n",
      "2025-02-25 09:14:32 [INFO] Epoch 35/200:\n",
      "2025-02-25 09:14:32 [INFO]   Training Loss: 0.000384\n",
      "2025-02-25 09:14:32 [INFO]   Training MAE: 0.017592\n",
      "2025-02-25 09:14:32 [INFO]   Validation Loss: 0.000361\n",
      "2025-02-25 09:14:32 [INFO]   Validation MAE: 0.014782\n",
      "2025-02-25 09:14:44 [INFO] Epoch 36/200:\n",
      "2025-02-25 09:14:44 [INFO]   Training Loss: 0.000371\n",
      "2025-02-25 09:14:44 [INFO]   Training MAE: 0.017289\n",
      "2025-02-25 09:14:44 [INFO]   Validation Loss: 0.000388\n",
      "2025-02-25 09:14:44 [INFO]   Validation MAE: 0.014983\n",
      "2025-02-25 09:14:55 [INFO] Epoch 37/200:\n",
      "2025-02-25 09:14:55 [INFO]   Training Loss: 0.000354\n",
      "2025-02-25 09:14:55 [INFO]   Training MAE: 0.016756\n",
      "2025-02-25 09:14:55 [INFO]   Validation Loss: 0.000402\n",
      "2025-02-25 09:14:55 [INFO]   Validation MAE: 0.014657\n",
      "2025-02-25 09:15:06 [INFO] Epoch 38/200:\n",
      "2025-02-25 09:15:06 [INFO]   Training Loss: 0.000363\n",
      "2025-02-25 09:15:06 [INFO]   Training MAE: 0.017097\n",
      "2025-02-25 09:15:06 [INFO]   Validation Loss: 0.000371\n",
      "2025-02-25 09:15:06 [INFO]   Validation MAE: 0.014191\n",
      "2025-02-25 09:15:17 [INFO] Epoch 39/200:\n",
      "2025-02-25 09:15:17 [INFO]   Training Loss: 0.000354\n",
      "2025-02-25 09:15:17 [INFO]   Training MAE: 0.017157\n",
      "2025-02-25 09:15:17 [INFO]   Validation Loss: 0.000342\n",
      "2025-02-25 09:15:17 [INFO]   Validation MAE: 0.013922\n",
      "2025-02-25 09:15:17 [INFO]   Saved new best model (val_loss=0.000342)\n",
      "2025-02-25 09:15:28 [INFO] Epoch 40/200:\n",
      "2025-02-25 09:15:28 [INFO]   Training Loss: 0.000331\n",
      "2025-02-25 09:15:28 [INFO]   Training MAE: 0.016389\n",
      "2025-02-25 09:15:28 [INFO]   Validation Loss: 0.000340\n",
      "2025-02-25 09:15:28 [INFO]   Validation MAE: 0.013555\n",
      "2025-02-25 09:15:28 [INFO]   Saved new best model (val_loss=0.000340)\n",
      "2025-02-25 09:15:39 [INFO] Epoch 41/200:\n",
      "2025-02-25 09:15:39 [INFO]   Training Loss: 0.000362\n",
      "2025-02-25 09:15:39 [INFO]   Training MAE: 0.016923\n",
      "2025-02-25 09:15:39 [INFO]   Validation Loss: 0.000352\n",
      "2025-02-25 09:15:39 [INFO]   Validation MAE: 0.014124\n",
      "2025-02-25 09:15:49 [INFO] Epoch 42/200:\n",
      "2025-02-25 09:15:49 [INFO]   Training Loss: 0.000362\n",
      "2025-02-25 09:15:49 [INFO]   Training MAE: 0.017091\n",
      "2025-02-25 09:15:49 [INFO]   Validation Loss: 0.000352\n",
      "2025-02-25 09:15:49 [INFO]   Validation MAE: 0.014555\n",
      "2025-02-25 09:16:00 [INFO] Epoch 43/200:\n",
      "2025-02-25 09:16:00 [INFO]   Training Loss: 0.000346\n",
      "2025-02-25 09:16:00 [INFO]   Training MAE: 0.016641\n",
      "2025-02-25 09:16:00 [INFO]   Validation Loss: 0.000312\n",
      "2025-02-25 09:16:00 [INFO]   Validation MAE: 0.013068\n",
      "2025-02-25 09:16:00 [INFO]   Saved new best model (val_loss=0.000312)\n",
      "2025-02-25 09:16:11 [INFO] Epoch 44/200:\n",
      "2025-02-25 09:16:11 [INFO]   Training Loss: 0.000345\n",
      "2025-02-25 09:16:11 [INFO]   Training MAE: 0.016650\n",
      "2025-02-25 09:16:11 [INFO]   Validation Loss: 0.000343\n",
      "2025-02-25 09:16:11 [INFO]   Validation MAE: 0.013739\n",
      "2025-02-25 09:16:22 [INFO] Epoch 45/200:\n",
      "2025-02-25 09:16:22 [INFO]   Training Loss: 0.000321\n",
      "2025-02-25 09:16:22 [INFO]   Training MAE: 0.016257\n",
      "2025-02-25 09:16:22 [INFO]   Validation Loss: 0.000375\n",
      "2025-02-25 09:16:22 [INFO]   Validation MAE: 0.014119\n",
      "2025-02-25 09:16:33 [INFO] Epoch 46/200:\n",
      "2025-02-25 09:16:33 [INFO]   Training Loss: 0.000337\n",
      "2025-02-25 09:16:33 [INFO]   Training MAE: 0.016393\n",
      "2025-02-25 09:16:33 [INFO]   Validation Loss: 0.000377\n",
      "2025-02-25 09:16:33 [INFO]   Validation MAE: 0.014554\n",
      "2025-02-25 09:16:44 [INFO] Epoch 47/200:\n",
      "2025-02-25 09:16:44 [INFO]   Training Loss: 0.000323\n",
      "2025-02-25 09:16:44 [INFO]   Training MAE: 0.016134\n",
      "2025-02-25 09:16:44 [INFO]   Validation Loss: 0.000364\n",
      "2025-02-25 09:16:44 [INFO]   Validation MAE: 0.014166\n",
      "2025-02-25 09:16:55 [INFO] Epoch 48/200:\n",
      "2025-02-25 09:16:55 [INFO]   Training Loss: 0.000329\n",
      "2025-02-25 09:16:55 [INFO]   Training MAE: 0.016343\n",
      "2025-02-25 09:16:55 [INFO]   Validation Loss: 0.000366\n",
      "2025-02-25 09:16:55 [INFO]   Validation MAE: 0.013982\n",
      "2025-02-25 09:17:06 [INFO] Epoch 49/200:\n",
      "2025-02-25 09:17:06 [INFO]   Training Loss: 0.000336\n",
      "2025-02-25 09:17:06 [INFO]   Training MAE: 0.016612\n",
      "2025-02-25 09:17:06 [INFO]   Validation Loss: 0.000325\n",
      "2025-02-25 09:17:06 [INFO]   Validation MAE: 0.013288\n",
      "2025-02-25 09:17:16 [INFO] Epoch 50/200:\n",
      "2025-02-25 09:17:16 [INFO]   Training Loss: 0.000328\n",
      "2025-02-25 09:17:16 [INFO]   Training MAE: 0.016490\n",
      "2025-02-25 09:17:16 [INFO]   Validation Loss: 0.000351\n",
      "2025-02-25 09:17:16 [INFO]   Validation MAE: 0.014196\n",
      "2025-02-25 09:17:27 [INFO] Epoch 51/200:\n",
      "2025-02-25 09:17:27 [INFO]   Training Loss: 0.000324\n",
      "2025-02-25 09:17:27 [INFO]   Training MAE: 0.016212\n",
      "2025-02-25 09:17:27 [INFO]   Validation Loss: 0.000332\n",
      "2025-02-25 09:17:27 [INFO]   Validation MAE: 0.013424\n",
      "2025-02-25 09:17:39 [INFO] Epoch 52/200:\n",
      "2025-02-25 09:17:39 [INFO]   Training Loss: 0.000322\n",
      "2025-02-25 09:17:39 [INFO]   Training MAE: 0.015965\n",
      "2025-02-25 09:17:39 [INFO]   Validation Loss: 0.000364\n",
      "2025-02-25 09:17:39 [INFO]   Validation MAE: 0.014354\n",
      "2025-02-25 09:17:50 [INFO] Epoch 53/200:\n",
      "2025-02-25 09:17:50 [INFO]   Training Loss: 0.000313\n",
      "2025-02-25 09:17:50 [INFO]   Training MAE: 0.016033\n",
      "2025-02-25 09:17:50 [INFO]   Validation Loss: 0.000331\n",
      "2025-02-25 09:17:50 [INFO]   Validation MAE: 0.013435\n",
      "2025-02-25 09:18:01 [INFO] Epoch 54/200:\n",
      "2025-02-25 09:18:01 [INFO]   Training Loss: 0.000321\n",
      "2025-02-25 09:18:01 [INFO]   Training MAE: 0.016112\n",
      "2025-02-25 09:18:01 [INFO]   Validation Loss: 0.000330\n",
      "2025-02-25 09:18:01 [INFO]   Validation MAE: 0.013566\n",
      "2025-02-25 09:18:12 [INFO] Epoch 55/200:\n",
      "2025-02-25 09:18:12 [INFO]   Training Loss: 0.000326\n",
      "2025-02-25 09:18:12 [INFO]   Training MAE: 0.016133\n",
      "2025-02-25 09:18:12 [INFO]   Validation Loss: 0.000351\n",
      "2025-02-25 09:18:12 [INFO]   Validation MAE: 0.013880\n",
      "2025-02-25 09:18:22 [INFO] Epoch 56/200:\n",
      "2025-02-25 09:18:22 [INFO]   Training Loss: 0.000322\n",
      "2025-02-25 09:18:22 [INFO]   Training MAE: 0.016144\n",
      "2025-02-25 09:18:22 [INFO]   Validation Loss: 0.000331\n",
      "2025-02-25 09:18:22 [INFO]   Validation MAE: 0.013435\n",
      "2025-02-25 09:18:32 [INFO] Epoch 57/200:\n",
      "2025-02-25 09:18:32 [INFO]   Training Loss: 0.000319\n",
      "2025-02-25 09:18:32 [INFO]   Training MAE: 0.016132\n",
      "2025-02-25 09:18:32 [INFO]   Validation Loss: 0.000337\n",
      "2025-02-25 09:18:32 [INFO]   Validation MAE: 0.013522\n",
      "2025-02-25 09:18:42 [INFO] Epoch 58/200:\n",
      "2025-02-25 09:18:42 [INFO]   Training Loss: 0.000316\n",
      "2025-02-25 09:18:42 [INFO]   Training MAE: 0.015897\n",
      "2025-02-25 09:18:42 [INFO]   Validation Loss: 0.000341\n",
      "2025-02-25 09:18:42 [INFO]   Validation MAE: 0.013445\n",
      "2025-02-25 09:18:53 [INFO] Epoch 59/200:\n",
      "2025-02-25 09:18:53 [INFO]   Training Loss: 0.000321\n",
      "2025-02-25 09:18:53 [INFO]   Training MAE: 0.016074\n",
      "2025-02-25 09:18:53 [INFO]   Validation Loss: 0.000331\n",
      "2025-02-25 09:18:53 [INFO]   Validation MAE: 0.013231\n",
      "2025-02-25 09:19:04 [INFO] Epoch 60/200:\n",
      "2025-02-25 09:19:04 [INFO]   Training Loss: 0.000320\n",
      "2025-02-25 09:19:04 [INFO]   Training MAE: 0.016223\n",
      "2025-02-25 09:19:04 [INFO]   Validation Loss: 0.000351\n",
      "2025-02-25 09:19:04 [INFO]   Validation MAE: 0.013635\n",
      "2025-02-25 09:19:15 [INFO] Epoch 61/200:\n",
      "2025-02-25 09:19:15 [INFO]   Training Loss: 0.000352\n",
      "2025-02-25 09:19:15 [INFO]   Training MAE: 0.017038\n",
      "2025-02-25 09:19:15 [INFO]   Validation Loss: 0.000323\n",
      "2025-02-25 09:19:15 [INFO]   Validation MAE: 0.013722\n",
      "2025-02-25 09:19:26 [INFO] Epoch 62/200:\n",
      "2025-02-25 09:19:26 [INFO]   Training Loss: 0.000366\n",
      "2025-02-25 09:19:26 [INFO]   Training MAE: 0.017387\n",
      "2025-02-25 09:19:26 [INFO]   Validation Loss: 0.000337\n",
      "2025-02-25 09:19:26 [INFO]   Validation MAE: 0.014218\n",
      "2025-02-25 09:19:37 [INFO] Epoch 63/200:\n",
      "2025-02-25 09:19:37 [INFO]   Training Loss: 0.000376\n",
      "2025-02-25 09:19:37 [INFO]   Training MAE: 0.017498\n",
      "2025-02-25 09:19:37 [INFO]   Validation Loss: 0.000356\n",
      "2025-02-25 09:19:37 [INFO]   Validation MAE: 0.015284\n",
      "2025-02-25 09:19:48 [INFO] Epoch 64/200:\n",
      "2025-02-25 09:19:48 [INFO]   Training Loss: 0.000362\n",
      "2025-02-25 09:19:48 [INFO]   Training MAE: 0.017096\n",
      "2025-02-25 09:19:48 [INFO]   Validation Loss: 0.000422\n",
      "2025-02-25 09:19:48 [INFO]   Validation MAE: 0.014784\n",
      "2025-02-25 09:20:00 [INFO] Epoch 65/200:\n",
      "2025-02-25 09:20:00 [INFO]   Training Loss: 0.000391\n",
      "2025-02-25 09:20:00 [INFO]   Training MAE: 0.017840\n",
      "2025-02-25 09:20:00 [INFO]   Validation Loss: 0.000338\n",
      "2025-02-25 09:20:00 [INFO]   Validation MAE: 0.013764\n",
      "2025-02-25 09:20:11 [INFO] Epoch 66/200:\n",
      "2025-02-25 09:20:11 [INFO]   Training Loss: 0.000369\n",
      "2025-02-25 09:20:11 [INFO]   Training MAE: 0.017504\n",
      "2025-02-25 09:20:11 [INFO]   Validation Loss: 0.000315\n",
      "2025-02-25 09:20:11 [INFO]   Validation MAE: 0.013466\n",
      "2025-02-25 09:20:21 [INFO] Epoch 67/200:\n",
      "2025-02-25 09:20:21 [INFO]   Training Loss: 0.000391\n",
      "2025-02-25 09:20:21 [INFO]   Training MAE: 0.018044\n",
      "2025-02-25 09:20:21 [INFO]   Validation Loss: 0.000355\n",
      "2025-02-25 09:20:21 [INFO]   Validation MAE: 0.015229\n",
      "2025-02-25 09:20:33 [INFO] Epoch 68/200:\n",
      "2025-02-25 09:20:33 [INFO]   Training Loss: 0.000410\n",
      "2025-02-25 09:20:33 [INFO]   Training MAE: 0.018620\n",
      "2025-02-25 09:20:33 [INFO]   Validation Loss: 0.000317\n",
      "2025-02-25 09:20:33 [INFO]   Validation MAE: 0.013558\n",
      "2025-02-25 09:20:43 [INFO] Epoch 69/200:\n",
      "2025-02-25 09:20:43 [INFO]   Training Loss: 0.000357\n",
      "2025-02-25 09:20:43 [INFO]   Training MAE: 0.017222\n",
      "2025-02-25 09:20:43 [INFO]   Validation Loss: 0.000405\n",
      "2025-02-25 09:20:43 [INFO]   Validation MAE: 0.016080\n",
      "2025-02-25 09:20:53 [INFO] Epoch 70/200:\n",
      "2025-02-25 09:20:53 [INFO]   Training Loss: 0.000359\n",
      "2025-02-25 09:20:53 [INFO]   Training MAE: 0.017308\n",
      "2025-02-25 09:20:53 [INFO]   Validation Loss: 0.000331\n",
      "2025-02-25 09:20:53 [INFO]   Validation MAE: 0.013557\n",
      "2025-02-25 09:21:03 [INFO] Epoch 71/200:\n",
      "2025-02-25 09:21:03 [INFO]   Training Loss: 0.000358\n",
      "2025-02-25 09:21:03 [INFO]   Training MAE: 0.017600\n",
      "2025-02-25 09:21:03 [INFO]   Validation Loss: 0.000324\n",
      "2025-02-25 09:21:03 [INFO]   Validation MAE: 0.013374\n",
      "2025-02-25 09:21:14 [INFO] Epoch 72/200:\n",
      "2025-02-25 09:21:14 [INFO]   Training Loss: 0.000345\n",
      "2025-02-25 09:21:14 [INFO]   Training MAE: 0.016876\n",
      "2025-02-25 09:21:14 [INFO]   Validation Loss: 0.000296\n",
      "2025-02-25 09:21:14 [INFO]   Validation MAE: 0.012889\n",
      "2025-02-25 09:21:14 [INFO]   Saved new best model (val_loss=0.000296)\n",
      "2025-02-25 09:21:25 [INFO] Epoch 73/200:\n",
      "2025-02-25 09:21:25 [INFO]   Training Loss: 0.000329\n",
      "2025-02-25 09:21:25 [INFO]   Training MAE: 0.016226\n",
      "2025-02-25 09:21:25 [INFO]   Validation Loss: 0.000297\n",
      "2025-02-25 09:21:25 [INFO]   Validation MAE: 0.013251\n",
      "2025-02-25 09:21:36 [INFO] Epoch 74/200:\n",
      "2025-02-25 09:21:36 [INFO]   Training Loss: 0.000335\n",
      "2025-02-25 09:21:36 [INFO]   Training MAE: 0.016736\n",
      "2025-02-25 09:21:36 [INFO]   Validation Loss: 0.000337\n",
      "2025-02-25 09:21:36 [INFO]   Validation MAE: 0.013382\n",
      "2025-02-25 09:21:47 [INFO] Epoch 75/200:\n",
      "2025-02-25 09:21:47 [INFO]   Training Loss: 0.000350\n",
      "2025-02-25 09:21:47 [INFO]   Training MAE: 0.017039\n",
      "2025-02-25 09:21:47 [INFO]   Validation Loss: 0.000366\n",
      "2025-02-25 09:21:47 [INFO]   Validation MAE: 0.014459\n",
      "2025-02-25 09:21:57 [INFO] Epoch 76/200:\n",
      "2025-02-25 09:21:57 [INFO]   Training Loss: 0.000336\n",
      "2025-02-25 09:21:57 [INFO]   Training MAE: 0.016590\n",
      "2025-02-25 09:21:57 [INFO]   Validation Loss: 0.000304\n",
      "2025-02-25 09:21:57 [INFO]   Validation MAE: 0.013039\n",
      "2025-02-25 09:22:07 [INFO] Epoch 77/200:\n",
      "2025-02-25 09:22:07 [INFO]   Training Loss: 0.000333\n",
      "2025-02-25 09:22:07 [INFO]   Training MAE: 0.016751\n",
      "2025-02-25 09:22:07 [INFO]   Validation Loss: 0.000329\n",
      "2025-02-25 09:22:07 [INFO]   Validation MAE: 0.013803\n",
      "2025-02-25 09:22:18 [INFO] Epoch 78/200:\n",
      "2025-02-25 09:22:18 [INFO]   Training Loss: 0.000311\n",
      "2025-02-25 09:22:18 [INFO]   Training MAE: 0.016201\n",
      "2025-02-25 09:22:18 [INFO]   Validation Loss: 0.000371\n",
      "2025-02-25 09:22:18 [INFO]   Validation MAE: 0.014125\n",
      "2025-02-25 09:22:28 [INFO] Epoch 79/200:\n",
      "2025-02-25 09:22:28 [INFO]   Training Loss: 0.000336\n",
      "2025-02-25 09:22:28 [INFO]   Training MAE: 0.016498\n",
      "2025-02-25 09:22:28 [INFO]   Validation Loss: 0.000343\n",
      "2025-02-25 09:22:28 [INFO]   Validation MAE: 0.014033\n",
      "2025-02-25 09:22:38 [INFO] Epoch 80/200:\n",
      "2025-02-25 09:22:38 [INFO]   Training Loss: 0.000325\n",
      "2025-02-25 09:22:38 [INFO]   Training MAE: 0.016152\n",
      "2025-02-25 09:22:38 [INFO]   Validation Loss: 0.000365\n",
      "2025-02-25 09:22:38 [INFO]   Validation MAE: 0.013869\n",
      "2025-02-25 09:22:47 [INFO] Epoch 81/200:\n",
      "2025-02-25 09:22:47 [INFO]   Training Loss: 0.000319\n",
      "2025-02-25 09:22:47 [INFO]   Training MAE: 0.016173\n",
      "2025-02-25 09:22:47 [INFO]   Validation Loss: 0.000363\n",
      "2025-02-25 09:22:47 [INFO]   Validation MAE: 0.013765\n",
      "2025-02-25 09:22:57 [INFO] Epoch 82/200:\n",
      "2025-02-25 09:22:57 [INFO]   Training Loss: 0.000340\n",
      "2025-02-25 09:22:57 [INFO]   Training MAE: 0.016993\n",
      "2025-02-25 09:22:57 [INFO]   Validation Loss: 0.000350\n",
      "2025-02-25 09:22:57 [INFO]   Validation MAE: 0.014290\n",
      "2025-02-25 09:23:06 [INFO] Epoch 83/200:\n",
      "2025-02-25 09:23:06 [INFO]   Training Loss: 0.000298\n",
      "2025-02-25 09:23:06 [INFO]   Training MAE: 0.015840\n",
      "2025-02-25 09:23:06 [INFO]   Validation Loss: 0.000296\n",
      "2025-02-25 09:23:06 [INFO]   Validation MAE: 0.012989\n",
      "2025-02-25 09:23:07 [INFO]   Saved new best model (val_loss=0.000296)\n",
      "2025-02-25 09:23:16 [INFO] Epoch 84/200:\n",
      "2025-02-25 09:23:16 [INFO]   Training Loss: 0.000311\n",
      "2025-02-25 09:23:16 [INFO]   Training MAE: 0.016161\n",
      "2025-02-25 09:23:16 [INFO]   Validation Loss: 0.000294\n",
      "2025-02-25 09:23:16 [INFO]   Validation MAE: 0.012634\n",
      "2025-02-25 09:23:16 [INFO]   Saved new best model (val_loss=0.000294)\n",
      "2025-02-25 09:23:25 [INFO] Epoch 85/200:\n",
      "2025-02-25 09:23:25 [INFO]   Training Loss: 0.000310\n",
      "2025-02-25 09:23:25 [INFO]   Training MAE: 0.016217\n",
      "2025-02-25 09:23:25 [INFO]   Validation Loss: 0.000336\n",
      "2025-02-25 09:23:25 [INFO]   Validation MAE: 0.013692\n",
      "2025-02-25 09:23:35 [INFO] Epoch 86/200:\n",
      "2025-02-25 09:23:35 [INFO]   Training Loss: 0.000305\n",
      "2025-02-25 09:23:35 [INFO]   Training MAE: 0.015942\n",
      "2025-02-25 09:23:35 [INFO]   Validation Loss: 0.000313\n",
      "2025-02-25 09:23:35 [INFO]   Validation MAE: 0.012906\n",
      "2025-02-25 09:23:44 [INFO] Epoch 87/200:\n",
      "2025-02-25 09:23:44 [INFO]   Training Loss: 0.000317\n",
      "2025-02-25 09:23:44 [INFO]   Training MAE: 0.016172\n",
      "2025-02-25 09:23:44 [INFO]   Validation Loss: 0.000308\n",
      "2025-02-25 09:23:44 [INFO]   Validation MAE: 0.013223\n",
      "2025-02-25 09:23:54 [INFO] Epoch 88/200:\n",
      "2025-02-25 09:23:54 [INFO]   Training Loss: 0.000315\n",
      "2025-02-25 09:23:54 [INFO]   Training MAE: 0.016058\n",
      "2025-02-25 09:23:54 [INFO]   Validation Loss: 0.000354\n",
      "2025-02-25 09:23:54 [INFO]   Validation MAE: 0.014401\n",
      "2025-02-25 09:24:03 [INFO] Epoch 89/200:\n",
      "2025-02-25 09:24:03 [INFO]   Training Loss: 0.000309\n",
      "2025-02-25 09:24:03 [INFO]   Training MAE: 0.016019\n",
      "2025-02-25 09:24:03 [INFO]   Validation Loss: 0.000316\n",
      "2025-02-25 09:24:03 [INFO]   Validation MAE: 0.013294\n",
      "2025-02-25 09:24:13 [INFO] Epoch 90/200:\n",
      "2025-02-25 09:24:13 [INFO]   Training Loss: 0.000302\n",
      "2025-02-25 09:24:13 [INFO]   Training MAE: 0.015825\n",
      "2025-02-25 09:24:13 [INFO]   Validation Loss: 0.000313\n",
      "2025-02-25 09:24:13 [INFO]   Validation MAE: 0.013063\n",
      "2025-02-25 09:24:22 [INFO] Epoch 91/200:\n",
      "2025-02-25 09:24:22 [INFO]   Training Loss: 0.000321\n",
      "2025-02-25 09:24:22 [INFO]   Training MAE: 0.016362\n",
      "2025-02-25 09:24:22 [INFO]   Validation Loss: 0.000338\n",
      "2025-02-25 09:24:22 [INFO]   Validation MAE: 0.013420\n",
      "2025-02-25 09:24:32 [INFO] Epoch 92/200:\n",
      "2025-02-25 09:24:32 [INFO]   Training Loss: 0.000282\n",
      "2025-02-25 09:24:32 [INFO]   Training MAE: 0.015339\n",
      "2025-02-25 09:24:32 [INFO]   Validation Loss: 0.000315\n",
      "2025-02-25 09:24:32 [INFO]   Validation MAE: 0.012946\n",
      "2025-02-25 09:24:42 [INFO] Epoch 93/200:\n",
      "2025-02-25 09:24:42 [INFO]   Training Loss: 0.000302\n",
      "2025-02-25 09:24:42 [INFO]   Training MAE: 0.015752\n",
      "2025-02-25 09:24:42 [INFO]   Validation Loss: 0.000330\n",
      "2025-02-25 09:24:42 [INFO]   Validation MAE: 0.013669\n",
      "2025-02-25 09:24:53 [INFO] Epoch 94/200:\n",
      "2025-02-25 09:24:53 [INFO]   Training Loss: 0.000293\n",
      "2025-02-25 09:24:53 [INFO]   Training MAE: 0.015846\n",
      "2025-02-25 09:24:53 [INFO]   Validation Loss: 0.000326\n",
      "2025-02-25 09:24:53 [INFO]   Validation MAE: 0.013633\n",
      "2025-02-25 09:25:04 [INFO] Epoch 95/200:\n",
      "2025-02-25 09:25:04 [INFO]   Training Loss: 0.000298\n",
      "2025-02-25 09:25:04 [INFO]   Training MAE: 0.015363\n",
      "2025-02-25 09:25:04 [INFO]   Validation Loss: 0.000306\n",
      "2025-02-25 09:25:04 [INFO]   Validation MAE: 0.013064\n",
      "2025-02-25 09:25:13 [INFO] Epoch 96/200:\n",
      "2025-02-25 09:25:13 [INFO]   Training Loss: 0.000290\n",
      "2025-02-25 09:25:13 [INFO]   Training MAE: 0.015521\n",
      "2025-02-25 09:25:13 [INFO]   Validation Loss: 0.000294\n",
      "2025-02-25 09:25:13 [INFO]   Validation MAE: 0.012463\n",
      "2025-02-25 09:25:23 [INFO] Epoch 97/200:\n",
      "2025-02-25 09:25:23 [INFO]   Training Loss: 0.000274\n",
      "2025-02-25 09:25:23 [INFO]   Training MAE: 0.015231\n",
      "2025-02-25 09:25:23 [INFO]   Validation Loss: 0.000318\n",
      "2025-02-25 09:25:23 [INFO]   Validation MAE: 0.012721\n",
      "2025-02-25 09:25:32 [INFO] Epoch 98/200:\n",
      "2025-02-25 09:25:32 [INFO]   Training Loss: 0.000269\n",
      "2025-02-25 09:25:32 [INFO]   Training MAE: 0.015012\n",
      "2025-02-25 09:25:32 [INFO]   Validation Loss: 0.000306\n",
      "2025-02-25 09:25:32 [INFO]   Validation MAE: 0.012667\n",
      "2025-02-25 09:25:41 [INFO] Epoch 99/200:\n",
      "2025-02-25 09:25:41 [INFO]   Training Loss: 0.000299\n",
      "2025-02-25 09:25:41 [INFO]   Training MAE: 0.015754\n",
      "2025-02-25 09:25:41 [INFO]   Validation Loss: 0.000334\n",
      "2025-02-25 09:25:41 [INFO]   Validation MAE: 0.013337\n",
      "2025-02-25 09:25:51 [INFO] Epoch 100/200:\n",
      "2025-02-25 09:25:51 [INFO]   Training Loss: 0.000290\n",
      "2025-02-25 09:25:51 [INFO]   Training MAE: 0.015579\n",
      "2025-02-25 09:25:51 [INFO]   Validation Loss: 0.000302\n",
      "2025-02-25 09:25:51 [INFO]   Validation MAE: 0.012783\n",
      "2025-02-25 09:26:01 [INFO] Epoch 101/200:\n",
      "2025-02-25 09:26:01 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 09:26:01 [INFO]   Training MAE: 0.015349\n",
      "2025-02-25 09:26:01 [INFO]   Validation Loss: 0.000286\n",
      "2025-02-25 09:26:01 [INFO]   Validation MAE: 0.012671\n",
      "2025-02-25 09:26:01 [INFO]   Saved new best model (val_loss=0.000286)\n",
      "2025-02-25 09:26:10 [INFO] Epoch 102/200:\n",
      "2025-02-25 09:26:10 [INFO]   Training Loss: 0.000282\n",
      "2025-02-25 09:26:10 [INFO]   Training MAE: 0.015291\n",
      "2025-02-25 09:26:10 [INFO]   Validation Loss: 0.000309\n",
      "2025-02-25 09:26:10 [INFO]   Validation MAE: 0.012723\n",
      "2025-02-25 09:26:20 [INFO] Epoch 103/200:\n",
      "2025-02-25 09:26:20 [INFO]   Training Loss: 0.000297\n",
      "2025-02-25 09:26:20 [INFO]   Training MAE: 0.015671\n",
      "2025-02-25 09:26:20 [INFO]   Validation Loss: 0.000314\n",
      "2025-02-25 09:26:20 [INFO]   Validation MAE: 0.013931\n",
      "2025-02-25 09:26:30 [INFO] Epoch 104/200:\n",
      "2025-02-25 09:26:30 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 09:26:30 [INFO]   Training MAE: 0.015312\n",
      "2025-02-25 09:26:30 [INFO]   Validation Loss: 0.000296\n",
      "2025-02-25 09:26:30 [INFO]   Validation MAE: 0.012639\n",
      "2025-02-25 09:26:39 [INFO] Epoch 105/200:\n",
      "2025-02-25 09:26:39 [INFO]   Training Loss: 0.000282\n",
      "2025-02-25 09:26:39 [INFO]   Training MAE: 0.015147\n",
      "2025-02-25 09:26:39 [INFO]   Validation Loss: 0.000310\n",
      "2025-02-25 09:26:39 [INFO]   Validation MAE: 0.012652\n",
      "2025-02-25 09:26:49 [INFO] Epoch 106/200:\n",
      "2025-02-25 09:26:49 [INFO]   Training Loss: 0.000281\n",
      "2025-02-25 09:26:49 [INFO]   Training MAE: 0.015236\n",
      "2025-02-25 09:26:49 [INFO]   Validation Loss: 0.000299\n",
      "2025-02-25 09:26:49 [INFO]   Validation MAE: 0.012509\n",
      "2025-02-25 09:26:59 [INFO] Epoch 107/200:\n",
      "2025-02-25 09:26:59 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 09:26:59 [INFO]   Training MAE: 0.015501\n",
      "2025-02-25 09:26:59 [INFO]   Validation Loss: 0.000284\n",
      "2025-02-25 09:26:59 [INFO]   Validation MAE: 0.012289\n",
      "2025-02-25 09:26:59 [INFO]   Saved new best model (val_loss=0.000284)\n",
      "2025-02-25 09:27:08 [INFO] Epoch 108/200:\n",
      "2025-02-25 09:27:08 [INFO]   Training Loss: 0.000284\n",
      "2025-02-25 09:27:08 [INFO]   Training MAE: 0.015222\n",
      "2025-02-25 09:27:08 [INFO]   Validation Loss: 0.000317\n",
      "2025-02-25 09:27:08 [INFO]   Validation MAE: 0.013072\n",
      "2025-02-25 09:27:18 [INFO] Epoch 109/200:\n",
      "2025-02-25 09:27:18 [INFO]   Training Loss: 0.000270\n",
      "2025-02-25 09:27:18 [INFO]   Training MAE: 0.014944\n",
      "2025-02-25 09:27:18 [INFO]   Validation Loss: 0.000307\n",
      "2025-02-25 09:27:18 [INFO]   Validation MAE: 0.012629\n",
      "2025-02-25 09:27:27 [INFO] Epoch 110/200:\n",
      "2025-02-25 09:27:27 [INFO]   Training Loss: 0.000259\n",
      "2025-02-25 09:27:27 [INFO]   Training MAE: 0.014708\n",
      "2025-02-25 09:27:27 [INFO]   Validation Loss: 0.000309\n",
      "2025-02-25 09:27:27 [INFO]   Validation MAE: 0.012708\n",
      "2025-02-25 09:27:36 [INFO] Epoch 111/200:\n",
      "2025-02-25 09:27:36 [INFO]   Training Loss: 0.000265\n",
      "2025-02-25 09:27:36 [INFO]   Training MAE: 0.014896\n",
      "2025-02-25 09:27:36 [INFO]   Validation Loss: 0.000317\n",
      "2025-02-25 09:27:36 [INFO]   Validation MAE: 0.012843\n",
      "2025-02-25 09:27:45 [INFO] Epoch 112/200:\n",
      "2025-02-25 09:27:45 [INFO]   Training Loss: 0.000269\n",
      "2025-02-25 09:27:45 [INFO]   Training MAE: 0.014970\n",
      "2025-02-25 09:27:45 [INFO]   Validation Loss: 0.000288\n",
      "2025-02-25 09:27:45 [INFO]   Validation MAE: 0.012641\n",
      "2025-02-25 09:27:55 [INFO] Epoch 113/200:\n",
      "2025-02-25 09:27:55 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 09:27:55 [INFO]   Training MAE: 0.015338\n",
      "2025-02-25 09:27:55 [INFO]   Validation Loss: 0.000322\n",
      "2025-02-25 09:27:55 [INFO]   Validation MAE: 0.013297\n",
      "2025-02-25 09:28:04 [INFO] Epoch 114/200:\n",
      "2025-02-25 09:28:04 [INFO]   Training Loss: 0.000273\n",
      "2025-02-25 09:28:04 [INFO]   Training MAE: 0.015010\n",
      "2025-02-25 09:28:04 [INFO]   Validation Loss: 0.000294\n",
      "2025-02-25 09:28:04 [INFO]   Validation MAE: 0.012500\n",
      "2025-02-25 09:28:13 [INFO] Epoch 115/200:\n",
      "2025-02-25 09:28:13 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 09:28:13 [INFO]   Training MAE: 0.015166\n",
      "2025-02-25 09:28:13 [INFO]   Validation Loss: 0.000329\n",
      "2025-02-25 09:28:13 [INFO]   Validation MAE: 0.013339\n",
      "2025-02-25 09:28:23 [INFO] Epoch 116/200:\n",
      "2025-02-25 09:28:23 [INFO]   Training Loss: 0.000250\n",
      "2025-02-25 09:28:23 [INFO]   Training MAE: 0.014312\n",
      "2025-02-25 09:28:23 [INFO]   Validation Loss: 0.000295\n",
      "2025-02-25 09:28:23 [INFO]   Validation MAE: 0.012311\n",
      "2025-02-25 09:28:32 [INFO] Epoch 117/200:\n",
      "2025-02-25 09:28:32 [INFO]   Training Loss: 0.000269\n",
      "2025-02-25 09:28:32 [INFO]   Training MAE: 0.014944\n",
      "2025-02-25 09:28:32 [INFO]   Validation Loss: 0.000312\n",
      "2025-02-25 09:28:32 [INFO]   Validation MAE: 0.012889\n",
      "2025-02-25 09:28:42 [INFO] Epoch 118/200:\n",
      "2025-02-25 09:28:42 [INFO]   Training Loss: 0.000275\n",
      "2025-02-25 09:28:42 [INFO]   Training MAE: 0.014994\n",
      "2025-02-25 09:28:42 [INFO]   Validation Loss: 0.000289\n",
      "2025-02-25 09:28:42 [INFO]   Validation MAE: 0.012331\n",
      "2025-02-25 09:28:51 [INFO] Epoch 119/200:\n",
      "2025-02-25 09:28:51 [INFO]   Training Loss: 0.000259\n",
      "2025-02-25 09:28:51 [INFO]   Training MAE: 0.014651\n",
      "2025-02-25 09:28:51 [INFO]   Validation Loss: 0.000295\n",
      "2025-02-25 09:28:51 [INFO]   Validation MAE: 0.012427\n",
      "2025-02-25 09:29:01 [INFO] Epoch 120/200:\n",
      "2025-02-25 09:29:01 [INFO]   Training Loss: 0.000258\n",
      "2025-02-25 09:29:01 [INFO]   Training MAE: 0.014675\n",
      "2025-02-25 09:29:01 [INFO]   Validation Loss: 0.000303\n",
      "2025-02-25 09:29:01 [INFO]   Validation MAE: 0.012508\n",
      "2025-02-25 09:29:10 [INFO] Epoch 121/200:\n",
      "2025-02-25 09:29:10 [INFO]   Training Loss: 0.000266\n",
      "2025-02-25 09:29:10 [INFO]   Training MAE: 0.014785\n",
      "2025-02-25 09:29:10 [INFO]   Validation Loss: 0.000309\n",
      "2025-02-25 09:29:10 [INFO]   Validation MAE: 0.012556\n",
      "2025-02-25 09:29:19 [INFO] Epoch 122/200:\n",
      "2025-02-25 09:29:19 [INFO]   Training Loss: 0.000248\n",
      "2025-02-25 09:29:19 [INFO]   Training MAE: 0.014404\n",
      "2025-02-25 09:29:19 [INFO]   Validation Loss: 0.000306\n",
      "2025-02-25 09:29:19 [INFO]   Validation MAE: 0.012575\n",
      "2025-02-25 09:29:28 [INFO] Epoch 123/200:\n",
      "2025-02-25 09:29:28 [INFO]   Training Loss: 0.000263\n",
      "2025-02-25 09:29:28 [INFO]   Training MAE: 0.014606\n",
      "2025-02-25 09:29:28 [INFO]   Validation Loss: 0.000295\n",
      "2025-02-25 09:29:28 [INFO]   Validation MAE: 0.012420\n",
      "2025-02-25 09:29:37 [INFO] Epoch 124/200:\n",
      "2025-02-25 09:29:37 [INFO]   Training Loss: 0.000255\n",
      "2025-02-25 09:29:37 [INFO]   Training MAE: 0.014539\n",
      "2025-02-25 09:29:37 [INFO]   Validation Loss: 0.000288\n",
      "2025-02-25 09:29:37 [INFO]   Validation MAE: 0.012193\n",
      "2025-02-25 09:29:47 [INFO] Epoch 125/200:\n",
      "2025-02-25 09:29:47 [INFO]   Training Loss: 0.000267\n",
      "2025-02-25 09:29:47 [INFO]   Training MAE: 0.014811\n",
      "2025-02-25 09:29:47 [INFO]   Validation Loss: 0.000308\n",
      "2025-02-25 09:29:47 [INFO]   Validation MAE: 0.012553\n",
      "2025-02-25 09:29:56 [INFO] Epoch 126/200:\n",
      "2025-02-25 09:29:56 [INFO]   Training Loss: 0.000263\n",
      "2025-02-25 09:29:56 [INFO]   Training MAE: 0.014845\n",
      "2025-02-25 09:29:56 [INFO]   Validation Loss: 0.000304\n",
      "2025-02-25 09:29:56 [INFO]   Validation MAE: 0.012594\n",
      "2025-02-25 09:30:05 [INFO] Epoch 127/200:\n",
      "2025-02-25 09:30:05 [INFO]   Training Loss: 0.000268\n",
      "2025-02-25 09:30:05 [INFO]   Training MAE: 0.014986\n",
      "2025-02-25 09:30:05 [INFO]   Validation Loss: 0.000315\n",
      "2025-02-25 09:30:05 [INFO]   Validation MAE: 0.012983\n",
      "2025-02-25 09:30:14 [INFO] Epoch 128/200:\n",
      "2025-02-25 09:30:14 [INFO]   Training Loss: 0.000273\n",
      "2025-02-25 09:30:14 [INFO]   Training MAE: 0.014859\n",
      "2025-02-25 09:30:14 [INFO]   Validation Loss: 0.000300\n",
      "2025-02-25 09:30:14 [INFO]   Validation MAE: 0.012367\n",
      "2025-02-25 09:30:23 [INFO] Epoch 129/200:\n",
      "2025-02-25 09:30:23 [INFO]   Training Loss: 0.000272\n",
      "2025-02-25 09:30:23 [INFO]   Training MAE: 0.014710\n",
      "2025-02-25 09:30:23 [INFO]   Validation Loss: 0.000297\n",
      "2025-02-25 09:30:23 [INFO]   Validation MAE: 0.012376\n",
      "2025-02-25 09:30:33 [INFO] Epoch 130/200:\n",
      "2025-02-25 09:30:33 [INFO]   Training Loss: 0.000257\n",
      "2025-02-25 09:30:33 [INFO]   Training MAE: 0.014403\n",
      "2025-02-25 09:30:33 [INFO]   Validation Loss: 0.000317\n",
      "2025-02-25 09:30:33 [INFO]   Validation MAE: 0.012724\n",
      "2025-02-25 09:30:42 [INFO] Epoch 131/200:\n",
      "2025-02-25 09:30:42 [INFO]   Training Loss: 0.000254\n",
      "2025-02-25 09:30:42 [INFO]   Training MAE: 0.014604\n",
      "2025-02-25 09:30:42 [INFO]   Validation Loss: 0.000294\n",
      "2025-02-25 09:30:42 [INFO]   Validation MAE: 0.012314\n",
      "2025-02-25 09:30:51 [INFO] Epoch 132/200:\n",
      "2025-02-25 09:30:51 [INFO]   Training Loss: 0.000272\n",
      "2025-02-25 09:30:51 [INFO]   Training MAE: 0.015014\n",
      "2025-02-25 09:30:51 [INFO]   Validation Loss: 0.000311\n",
      "2025-02-25 09:30:51 [INFO]   Validation MAE: 0.012716\n",
      "2025-02-25 09:31:00 [INFO] Epoch 133/200:\n",
      "2025-02-25 09:31:00 [INFO]   Training Loss: 0.000249\n",
      "2025-02-25 09:31:00 [INFO]   Training MAE: 0.014560\n",
      "2025-02-25 09:31:00 [INFO]   Validation Loss: 0.000295\n",
      "2025-02-25 09:31:00 [INFO]   Validation MAE: 0.012463\n",
      "2025-02-25 09:31:09 [INFO] Epoch 134/200:\n",
      "2025-02-25 09:31:09 [INFO]   Training Loss: 0.000252\n",
      "2025-02-25 09:31:09 [INFO]   Training MAE: 0.014462\n",
      "2025-02-25 09:31:09 [INFO]   Validation Loss: 0.000304\n",
      "2025-02-25 09:31:09 [INFO]   Validation MAE: 0.012453\n",
      "2025-02-25 09:31:19 [INFO] Epoch 135/200:\n",
      "2025-02-25 09:31:19 [INFO]   Training Loss: 0.000257\n",
      "2025-02-25 09:31:19 [INFO]   Training MAE: 0.014678\n",
      "2025-02-25 09:31:19 [INFO]   Validation Loss: 0.000316\n",
      "2025-02-25 09:31:19 [INFO]   Validation MAE: 0.012717\n",
      "2025-02-25 09:31:28 [INFO] Epoch 136/200:\n",
      "2025-02-25 09:31:28 [INFO]   Training Loss: 0.000252\n",
      "2025-02-25 09:31:28 [INFO]   Training MAE: 0.014565\n",
      "2025-02-25 09:31:28 [INFO]   Validation Loss: 0.000318\n",
      "2025-02-25 09:31:28 [INFO]   Validation MAE: 0.012830\n",
      "2025-02-25 09:31:37 [INFO] Epoch 137/200:\n",
      "2025-02-25 09:31:37 [INFO]   Training Loss: 0.000261\n",
      "2025-02-25 09:31:37 [INFO]   Training MAE: 0.014740\n",
      "2025-02-25 09:31:37 [INFO]   Validation Loss: 0.000301\n",
      "2025-02-25 09:31:37 [INFO]   Validation MAE: 0.012356\n",
      "2025-02-25 09:31:46 [INFO] Epoch 138/200:\n",
      "2025-02-25 09:31:46 [INFO]   Training Loss: 0.000260\n",
      "2025-02-25 09:31:46 [INFO]   Training MAE: 0.014605\n",
      "2025-02-25 09:31:46 [INFO]   Validation Loss: 0.000295\n",
      "2025-02-25 09:31:46 [INFO]   Validation MAE: 0.012413\n",
      "2025-02-25 09:31:55 [INFO] Epoch 139/200:\n",
      "2025-02-25 09:31:55 [INFO]   Training Loss: 0.000272\n",
      "2025-02-25 09:31:55 [INFO]   Training MAE: 0.014676\n",
      "2025-02-25 09:31:55 [INFO]   Validation Loss: 0.000312\n",
      "2025-02-25 09:31:55 [INFO]   Validation MAE: 0.013005\n",
      "2025-02-25 09:32:04 [INFO] Epoch 140/200:\n",
      "2025-02-25 09:32:04 [INFO]   Training Loss: 0.000251\n",
      "2025-02-25 09:32:04 [INFO]   Training MAE: 0.014303\n",
      "2025-02-25 09:32:04 [INFO]   Validation Loss: 0.000300\n",
      "2025-02-25 09:32:04 [INFO]   Validation MAE: 0.012570\n",
      "2025-02-25 09:32:14 [INFO] Epoch 141/200:\n",
      "2025-02-25 09:32:14 [INFO]   Training Loss: 0.000290\n",
      "2025-02-25 09:32:14 [INFO]   Training MAE: 0.015350\n",
      "2025-02-25 09:32:14 [INFO]   Validation Loss: 0.000289\n",
      "2025-02-25 09:32:14 [INFO]   Validation MAE: 0.012606\n",
      "2025-02-25 09:32:23 [INFO] Epoch 142/200:\n",
      "2025-02-25 09:32:23 [INFO]   Training Loss: 0.000306\n",
      "2025-02-25 09:32:23 [INFO]   Training MAE: 0.015948\n",
      "2025-02-25 09:32:23 [INFO]   Validation Loss: 0.000344\n",
      "2025-02-25 09:32:23 [INFO]   Validation MAE: 0.013271\n",
      "2025-02-25 09:32:32 [INFO] Epoch 143/200:\n",
      "2025-02-25 09:32:32 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 09:32:32 [INFO]   Training MAE: 0.015308\n",
      "2025-02-25 09:32:32 [INFO]   Validation Loss: 0.000317\n",
      "2025-02-25 09:32:32 [INFO]   Validation MAE: 0.013257\n",
      "2025-02-25 09:32:41 [INFO] Epoch 144/200:\n",
      "2025-02-25 09:32:41 [INFO]   Training Loss: 0.000311\n",
      "2025-02-25 09:32:41 [INFO]   Training MAE: 0.015845\n",
      "2025-02-25 09:32:41 [INFO]   Validation Loss: 0.000311\n",
      "2025-02-25 09:32:41 [INFO]   Validation MAE: 0.013039\n",
      "2025-02-25 09:32:50 [INFO] Epoch 145/200:\n",
      "2025-02-25 09:32:50 [INFO]   Training Loss: 0.000327\n",
      "2025-02-25 09:32:50 [INFO]   Training MAE: 0.016715\n",
      "2025-02-25 09:32:50 [INFO]   Validation Loss: 0.000301\n",
      "2025-02-25 09:32:50 [INFO]   Validation MAE: 0.012869\n",
      "2025-02-25 09:33:00 [INFO] Epoch 146/200:\n",
      "2025-02-25 09:33:00 [INFO]   Training Loss: 0.000310\n",
      "2025-02-25 09:33:00 [INFO]   Training MAE: 0.016024\n",
      "2025-02-25 09:33:00 [INFO]   Validation Loss: 0.000377\n",
      "2025-02-25 09:33:00 [INFO]   Validation MAE: 0.014009\n",
      "2025-02-25 09:33:09 [INFO] Epoch 147/200:\n",
      "2025-02-25 09:33:09 [INFO]   Training Loss: 0.000316\n",
      "2025-02-25 09:33:09 [INFO]   Training MAE: 0.016158\n",
      "2025-02-25 09:33:09 [INFO]   Validation Loss: 0.000320\n",
      "2025-02-25 09:33:09 [INFO]   Validation MAE: 0.013546\n",
      "2025-02-25 09:33:18 [INFO] Epoch 148/200:\n",
      "2025-02-25 09:33:18 [INFO]   Training Loss: 0.000309\n",
      "2025-02-25 09:33:18 [INFO]   Training MAE: 0.016031\n",
      "2025-02-25 09:33:18 [INFO]   Validation Loss: 0.000274\n",
      "2025-02-25 09:33:18 [INFO]   Validation MAE: 0.012623\n",
      "2025-02-25 09:33:18 [INFO]   Saved new best model (val_loss=0.000274)\n",
      "2025-02-25 09:33:27 [INFO] Epoch 149/200:\n",
      "2025-02-25 09:33:27 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 09:33:27 [INFO]   Training MAE: 0.015303\n",
      "2025-02-25 09:33:27 [INFO]   Validation Loss: 0.000266\n",
      "2025-02-25 09:33:27 [INFO]   Validation MAE: 0.012183\n",
      "2025-02-25 09:33:27 [INFO]   Saved new best model (val_loss=0.000266)\n",
      "2025-02-25 09:33:37 [INFO] Epoch 150/200:\n",
      "2025-02-25 09:33:37 [INFO]   Training Loss: 0.000333\n",
      "2025-02-25 09:33:37 [INFO]   Training MAE: 0.016825\n",
      "2025-02-25 09:33:37 [INFO]   Validation Loss: 0.000293\n",
      "2025-02-25 09:33:37 [INFO]   Validation MAE: 0.013536\n",
      "2025-02-25 09:33:46 [INFO] Epoch 151/200:\n",
      "2025-02-25 09:33:46 [INFO]   Training Loss: 0.000317\n",
      "2025-02-25 09:33:46 [INFO]   Training MAE: 0.016329\n",
      "2025-02-25 09:33:46 [INFO]   Validation Loss: 0.000272\n",
      "2025-02-25 09:33:46 [INFO]   Validation MAE: 0.012570\n",
      "2025-02-25 09:33:55 [INFO] Epoch 152/200:\n",
      "2025-02-25 09:33:55 [INFO]   Training Loss: 0.000325\n",
      "2025-02-25 09:33:55 [INFO]   Training MAE: 0.016681\n",
      "2025-02-25 09:33:55 [INFO]   Validation Loss: 0.000295\n",
      "2025-02-25 09:33:55 [INFO]   Validation MAE: 0.012950\n",
      "2025-02-25 09:34:04 [INFO] Epoch 153/200:\n",
      "2025-02-25 09:34:04 [INFO]   Training Loss: 0.000318\n",
      "2025-02-25 09:34:04 [INFO]   Training MAE: 0.016532\n",
      "2025-02-25 09:34:04 [INFO]   Validation Loss: 0.000285\n",
      "2025-02-25 09:34:05 [INFO]   Validation MAE: 0.013073\n",
      "2025-02-25 09:34:14 [INFO] Epoch 154/200:\n",
      "2025-02-25 09:34:14 [INFO]   Training Loss: 0.000296\n",
      "2025-02-25 09:34:14 [INFO]   Training MAE: 0.015941\n",
      "2025-02-25 09:34:14 [INFO]   Validation Loss: 0.000269\n",
      "2025-02-25 09:34:14 [INFO]   Validation MAE: 0.012705\n",
      "2025-02-25 09:34:23 [INFO] Epoch 155/200:\n",
      "2025-02-25 09:34:23 [INFO]   Training Loss: 0.000311\n",
      "2025-02-25 09:34:23 [INFO]   Training MAE: 0.016100\n",
      "2025-02-25 09:34:23 [INFO]   Validation Loss: 0.000281\n",
      "2025-02-25 09:34:23 [INFO]   Validation MAE: 0.012535\n",
      "2025-02-25 09:34:32 [INFO] Epoch 156/200:\n",
      "2025-02-25 09:34:32 [INFO]   Training Loss: 0.000282\n",
      "2025-02-25 09:34:32 [INFO]   Training MAE: 0.015314\n",
      "2025-02-25 09:34:32 [INFO]   Validation Loss: 0.000304\n",
      "2025-02-25 09:34:32 [INFO]   Validation MAE: 0.012866\n",
      "2025-02-25 09:34:41 [INFO] Epoch 157/200:\n",
      "2025-02-25 09:34:41 [INFO]   Training Loss: 0.000301\n",
      "2025-02-25 09:34:41 [INFO]   Training MAE: 0.016025\n",
      "2025-02-25 09:34:41 [INFO]   Validation Loss: 0.000301\n",
      "2025-02-25 09:34:41 [INFO]   Validation MAE: 0.012712\n",
      "2025-02-25 09:34:50 [INFO] Epoch 158/200:\n",
      "2025-02-25 09:34:50 [INFO]   Training Loss: 0.000318\n",
      "2025-02-25 09:34:50 [INFO]   Training MAE: 0.016186\n",
      "2025-02-25 09:34:50 [INFO]   Validation Loss: 0.000287\n",
      "2025-02-25 09:34:50 [INFO]   Validation MAE: 0.012813\n",
      "2025-02-25 09:34:59 [INFO] Epoch 159/200:\n",
      "2025-02-25 09:34:59 [INFO]   Training Loss: 0.000304\n",
      "2025-02-25 09:34:59 [INFO]   Training MAE: 0.015887\n",
      "2025-02-25 09:34:59 [INFO]   Validation Loss: 0.000311\n",
      "2025-02-25 09:34:59 [INFO]   Validation MAE: 0.013161\n",
      "2025-02-25 09:35:09 [INFO] Epoch 160/200:\n",
      "2025-02-25 09:35:09 [INFO]   Training Loss: 0.000292\n",
      "2025-02-25 09:35:09 [INFO]   Training MAE: 0.015507\n",
      "2025-02-25 09:35:09 [INFO]   Validation Loss: 0.000356\n",
      "2025-02-25 09:35:09 [INFO]   Validation MAE: 0.013624\n",
      "2025-02-25 09:35:18 [INFO] Epoch 161/200:\n",
      "2025-02-25 09:35:18 [INFO]   Training Loss: 0.000291\n",
      "2025-02-25 09:35:18 [INFO]   Training MAE: 0.015589\n",
      "2025-02-25 09:35:18 [INFO]   Validation Loss: 0.000310\n",
      "2025-02-25 09:35:18 [INFO]   Validation MAE: 0.013217\n",
      "2025-02-25 09:35:27 [INFO] Epoch 162/200:\n",
      "2025-02-25 09:35:27 [INFO]   Training Loss: 0.000270\n",
      "2025-02-25 09:35:27 [INFO]   Training MAE: 0.015316\n",
      "2025-02-25 09:35:27 [INFO]   Validation Loss: 0.000295\n",
      "2025-02-25 09:35:27 [INFO]   Validation MAE: 0.013144\n",
      "2025-02-25 09:35:36 [INFO] Epoch 163/200:\n",
      "2025-02-25 09:35:36 [INFO]   Training Loss: 0.000276\n",
      "2025-02-25 09:35:36 [INFO]   Training MAE: 0.015402\n",
      "2025-02-25 09:35:36 [INFO]   Validation Loss: 0.000307\n",
      "2025-02-25 09:35:36 [INFO]   Validation MAE: 0.012758\n",
      "2025-02-25 09:35:46 [INFO] Epoch 164/200:\n",
      "2025-02-25 09:35:46 [INFO]   Training Loss: 0.000283\n",
      "2025-02-25 09:35:46 [INFO]   Training MAE: 0.015620\n",
      "2025-02-25 09:35:46 [INFO]   Validation Loss: 0.000338\n",
      "2025-02-25 09:35:46 [INFO]   Validation MAE: 0.013523\n",
      "2025-02-25 09:35:55 [INFO] Epoch 165/200:\n",
      "2025-02-25 09:35:55 [INFO]   Training Loss: 0.000281\n",
      "2025-02-25 09:35:55 [INFO]   Training MAE: 0.015111\n",
      "2025-02-25 09:35:55 [INFO]   Validation Loss: 0.000320\n",
      "2025-02-25 09:35:55 [INFO]   Validation MAE: 0.013537\n",
      "2025-02-25 09:36:04 [INFO] Epoch 166/200:\n",
      "2025-02-25 09:36:04 [INFO]   Training Loss: 0.000283\n",
      "2025-02-25 09:36:04 [INFO]   Training MAE: 0.015546\n",
      "2025-02-25 09:36:04 [INFO]   Validation Loss: 0.000354\n",
      "2025-02-25 09:36:04 [INFO]   Validation MAE: 0.013419\n",
      "2025-02-25 09:36:13 [INFO] Epoch 167/200:\n",
      "2025-02-25 09:36:13 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 09:36:13 [INFO]   Training MAE: 0.015379\n",
      "2025-02-25 09:36:13 [INFO]   Validation Loss: 0.000321\n",
      "2025-02-25 09:36:13 [INFO]   Validation MAE: 0.013325\n",
      "2025-02-25 09:36:22 [INFO] Epoch 168/200:\n",
      "2025-02-25 09:36:22 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 09:36:22 [INFO]   Training MAE: 0.015603\n",
      "2025-02-25 09:36:22 [INFO]   Validation Loss: 0.000367\n",
      "2025-02-25 09:36:22 [INFO]   Validation MAE: 0.014445\n",
      "2025-02-25 09:36:31 [INFO] Epoch 169/200:\n",
      "2025-02-25 09:36:31 [INFO]   Training Loss: 0.000274\n",
      "2025-02-25 09:36:31 [INFO]   Training MAE: 0.015237\n",
      "2025-02-25 09:36:31 [INFO]   Validation Loss: 0.000302\n",
      "2025-02-25 09:36:31 [INFO]   Validation MAE: 0.013143\n",
      "2025-02-25 09:36:41 [INFO] Epoch 170/200:\n",
      "2025-02-25 09:36:41 [INFO]   Training Loss: 0.000265\n",
      "2025-02-25 09:36:41 [INFO]   Training MAE: 0.015081\n",
      "2025-02-25 09:36:41 [INFO]   Validation Loss: 0.000328\n",
      "2025-02-25 09:36:41 [INFO]   Validation MAE: 0.013177\n",
      "2025-02-25 09:36:50 [INFO] Epoch 171/200:\n",
      "2025-02-25 09:36:50 [INFO]   Training Loss: 0.000301\n",
      "2025-02-25 09:36:50 [INFO]   Training MAE: 0.016094\n",
      "2025-02-25 09:36:50 [INFO]   Validation Loss: 0.000343\n",
      "2025-02-25 09:36:50 [INFO]   Validation MAE: 0.013668\n",
      "2025-02-25 09:37:00 [INFO] Epoch 172/200:\n",
      "2025-02-25 09:37:00 [INFO]   Training Loss: 0.000288\n",
      "2025-02-25 09:37:00 [INFO]   Training MAE: 0.015582\n",
      "2025-02-25 09:37:00 [INFO]   Validation Loss: 0.000354\n",
      "2025-02-25 09:37:00 [INFO]   Validation MAE: 0.013575\n",
      "2025-02-25 09:37:08 [INFO] Epoch 173/200:\n",
      "2025-02-25 09:37:08 [INFO]   Training Loss: 0.000302\n",
      "2025-02-25 09:37:08 [INFO]   Training MAE: 0.015902\n",
      "2025-02-25 09:37:08 [INFO]   Validation Loss: 0.000313\n",
      "2025-02-25 09:37:08 [INFO]   Validation MAE: 0.012995\n",
      "2025-02-25 09:37:17 [INFO] Epoch 174/200:\n",
      "2025-02-25 09:37:17 [INFO]   Training Loss: 0.000301\n",
      "2025-02-25 09:37:17 [INFO]   Training MAE: 0.015725\n",
      "2025-02-25 09:37:17 [INFO]   Validation Loss: 0.000317\n",
      "2025-02-25 09:37:17 [INFO]   Validation MAE: 0.012950\n",
      "2025-02-25 09:37:26 [INFO] Epoch 175/200:\n",
      "2025-02-25 09:37:26 [INFO]   Training Loss: 0.000293\n",
      "2025-02-25 09:37:26 [INFO]   Training MAE: 0.015739\n",
      "2025-02-25 09:37:26 [INFO]   Validation Loss: 0.000338\n",
      "2025-02-25 09:37:26 [INFO]   Validation MAE: 0.013728\n",
      "2025-02-25 09:37:35 [INFO] Epoch 176/200:\n",
      "2025-02-25 09:37:35 [INFO]   Training Loss: 0.000309\n",
      "2025-02-25 09:37:35 [INFO]   Training MAE: 0.015792\n",
      "2025-02-25 09:37:35 [INFO]   Validation Loss: 0.000395\n",
      "2025-02-25 09:37:35 [INFO]   Validation MAE: 0.014640\n",
      "2025-02-25 09:37:44 [INFO] Epoch 177/200:\n",
      "2025-02-25 09:37:44 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 09:37:44 [INFO]   Training MAE: 0.015468\n",
      "2025-02-25 09:37:44 [INFO]   Validation Loss: 0.000305\n",
      "2025-02-25 09:37:44 [INFO]   Validation MAE: 0.012994\n",
      "2025-02-25 09:37:53 [INFO] Epoch 178/200:\n",
      "2025-02-25 09:37:53 [INFO]   Training Loss: 0.000311\n",
      "2025-02-25 09:37:53 [INFO]   Training MAE: 0.015975\n",
      "2025-02-25 09:37:53 [INFO]   Validation Loss: 0.000324\n",
      "2025-02-25 09:37:53 [INFO]   Validation MAE: 0.012871\n",
      "2025-02-25 09:38:02 [INFO] Epoch 179/200:\n",
      "2025-02-25 09:38:02 [INFO]   Training Loss: 0.000274\n",
      "2025-02-25 09:38:02 [INFO]   Training MAE: 0.015492\n",
      "2025-02-25 09:38:02 [INFO]   Validation Loss: 0.000314\n",
      "2025-02-25 09:38:02 [INFO]   Validation MAE: 0.013568\n",
      "2025-02-25 09:38:11 [INFO] Epoch 180/200:\n",
      "2025-02-25 09:38:11 [INFO]   Training Loss: 0.000288\n",
      "2025-02-25 09:38:11 [INFO]   Training MAE: 0.015376\n",
      "2025-02-25 09:38:11 [INFO]   Validation Loss: 0.000309\n",
      "2025-02-25 09:38:11 [INFO]   Validation MAE: 0.012635\n",
      "2025-02-25 09:38:20 [INFO] Epoch 181/200:\n",
      "2025-02-25 09:38:20 [INFO]   Training Loss: 0.000278\n",
      "2025-02-25 09:38:20 [INFO]   Training MAE: 0.015388\n",
      "2025-02-25 09:38:20 [INFO]   Validation Loss: 0.000324\n",
      "2025-02-25 09:38:20 [INFO]   Validation MAE: 0.013186\n",
      "2025-02-25 09:38:29 [INFO] Epoch 182/200:\n",
      "2025-02-25 09:38:29 [INFO]   Training Loss: 0.000285\n",
      "2025-02-25 09:38:29 [INFO]   Training MAE: 0.015667\n",
      "2025-02-25 09:38:29 [INFO]   Validation Loss: 0.000277\n",
      "2025-02-25 09:38:29 [INFO]   Validation MAE: 0.012244\n",
      "2025-02-25 09:38:37 [INFO] Epoch 183/200:\n",
      "2025-02-25 09:38:37 [INFO]   Training Loss: 0.000267\n",
      "2025-02-25 09:38:37 [INFO]   Training MAE: 0.014957\n",
      "2025-02-25 09:38:37 [INFO]   Validation Loss: 0.000308\n",
      "2025-02-25 09:38:37 [INFO]   Validation MAE: 0.012916\n",
      "2025-02-25 09:38:46 [INFO] Epoch 184/200:\n",
      "2025-02-25 09:38:46 [INFO]   Training Loss: 0.000272\n",
      "2025-02-25 09:38:46 [INFO]   Training MAE: 0.015251\n",
      "2025-02-25 09:38:46 [INFO]   Validation Loss: 0.000318\n",
      "2025-02-25 09:38:46 [INFO]   Validation MAE: 0.013380\n",
      "2025-02-25 09:38:55 [INFO] Epoch 185/200:\n",
      "2025-02-25 09:38:55 [INFO]   Training Loss: 0.000259\n",
      "2025-02-25 09:38:55 [INFO]   Training MAE: 0.014648\n",
      "2025-02-25 09:38:55 [INFO]   Validation Loss: 0.000293\n",
      "2025-02-25 09:38:55 [INFO]   Validation MAE: 0.012847\n",
      "2025-02-25 09:39:04 [INFO] Epoch 186/200:\n",
      "2025-02-25 09:39:04 [INFO]   Training Loss: 0.000273\n",
      "2025-02-25 09:39:04 [INFO]   Training MAE: 0.015122\n",
      "2025-02-25 09:39:04 [INFO]   Validation Loss: 0.000279\n",
      "2025-02-25 09:39:04 [INFO]   Validation MAE: 0.012244\n",
      "2025-02-25 09:39:14 [INFO] Epoch 187/200:\n",
      "2025-02-25 09:39:14 [INFO]   Training Loss: 0.000274\n",
      "2025-02-25 09:39:14 [INFO]   Training MAE: 0.015031\n",
      "2025-02-25 09:39:14 [INFO]   Validation Loss: 0.000343\n",
      "2025-02-25 09:39:14 [INFO]   Validation MAE: 0.013342\n",
      "2025-02-25 09:39:24 [INFO] Epoch 188/200:\n",
      "2025-02-25 09:39:24 [INFO]   Training Loss: 0.000276\n",
      "2025-02-25 09:39:24 [INFO]   Training MAE: 0.015416\n",
      "2025-02-25 09:39:24 [INFO]   Validation Loss: 0.000331\n",
      "2025-02-25 09:39:24 [INFO]   Validation MAE: 0.013284\n",
      "2025-02-25 09:39:34 [INFO] Epoch 189/200:\n",
      "2025-02-25 09:39:34 [INFO]   Training Loss: 0.000265\n",
      "2025-02-25 09:39:34 [INFO]   Training MAE: 0.014905\n",
      "2025-02-25 09:39:34 [INFO]   Validation Loss: 0.000299\n",
      "2025-02-25 09:39:34 [INFO]   Validation MAE: 0.012558\n",
      "2025-02-25 09:39:44 [INFO] Epoch 190/200:\n",
      "2025-02-25 09:39:44 [INFO]   Training Loss: 0.000275\n",
      "2025-02-25 09:39:44 [INFO]   Training MAE: 0.015160\n",
      "2025-02-25 09:39:44 [INFO]   Validation Loss: 0.000307\n",
      "2025-02-25 09:39:44 [INFO]   Validation MAE: 0.013161\n",
      "2025-02-25 09:39:55 [INFO] Epoch 191/200:\n",
      "2025-02-25 09:39:55 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 09:39:55 [INFO]   Training MAE: 0.015684\n",
      "2025-02-25 09:39:55 [INFO]   Validation Loss: 0.000302\n",
      "2025-02-25 09:39:55 [INFO]   Validation MAE: 0.012683\n",
      "2025-02-25 09:40:05 [INFO] Epoch 192/200:\n",
      "2025-02-25 09:40:05 [INFO]   Training Loss: 0.000285\n",
      "2025-02-25 09:40:05 [INFO]   Training MAE: 0.015532\n",
      "2025-02-25 09:40:05 [INFO]   Validation Loss: 0.000387\n",
      "2025-02-25 09:40:05 [INFO]   Validation MAE: 0.014151\n",
      "2025-02-25 09:40:15 [INFO] Epoch 193/200:\n",
      "2025-02-25 09:40:15 [INFO]   Training Loss: 0.000281\n",
      "2025-02-25 09:40:15 [INFO]   Training MAE: 0.015201\n",
      "2025-02-25 09:40:15 [INFO]   Validation Loss: 0.000284\n",
      "2025-02-25 09:40:15 [INFO]   Validation MAE: 0.012402\n",
      "2025-02-25 09:40:25 [INFO] Epoch 194/200:\n",
      "2025-02-25 09:40:25 [INFO]   Training Loss: 0.000263\n",
      "2025-02-25 09:40:25 [INFO]   Training MAE: 0.014952\n",
      "2025-02-25 09:40:25 [INFO]   Validation Loss: 0.000306\n",
      "2025-02-25 09:40:25 [INFO]   Validation MAE: 0.012740\n",
      "2025-02-25 09:40:36 [INFO] Epoch 195/200:\n",
      "2025-02-25 09:40:36 [INFO]   Training Loss: 0.000261\n",
      "2025-02-25 09:40:36 [INFO]   Training MAE: 0.014832\n",
      "2025-02-25 09:40:36 [INFO]   Validation Loss: 0.000313\n",
      "2025-02-25 09:40:36 [INFO]   Validation MAE: 0.012527\n",
      "2025-02-25 09:40:46 [INFO] Epoch 196/200:\n",
      "2025-02-25 09:40:46 [INFO]   Training Loss: 0.000262\n",
      "2025-02-25 09:40:46 [INFO]   Training MAE: 0.015019\n",
      "2025-02-25 09:40:46 [INFO]   Validation Loss: 0.000307\n",
      "2025-02-25 09:40:46 [INFO]   Validation MAE: 0.012746\n",
      "2025-02-25 09:40:55 [INFO] Epoch 197/200:\n",
      "2025-02-25 09:40:55 [INFO]   Training Loss: 0.000258\n",
      "2025-02-25 09:40:55 [INFO]   Training MAE: 0.014827\n",
      "2025-02-25 09:40:55 [INFO]   Validation Loss: 0.000282\n",
      "2025-02-25 09:40:55 [INFO]   Validation MAE: 0.012200\n",
      "2025-02-25 09:41:05 [INFO] Epoch 198/200:\n",
      "2025-02-25 09:41:05 [INFO]   Training Loss: 0.000252\n",
      "2025-02-25 09:41:05 [INFO]   Training MAE: 0.014620\n",
      "2025-02-25 09:41:05 [INFO]   Validation Loss: 0.000350\n",
      "2025-02-25 09:41:05 [INFO]   Validation MAE: 0.013136\n",
      "2025-02-25 09:41:14 [INFO] Epoch 199/200:\n",
      "2025-02-25 09:41:14 [INFO]   Training Loss: 0.000259\n",
      "2025-02-25 09:41:14 [INFO]   Training MAE: 0.014729\n",
      "2025-02-25 09:41:14 [INFO]   Validation Loss: 0.000284\n",
      "2025-02-25 09:41:14 [INFO]   Validation MAE: 0.012188\n",
      "2025-02-25 09:41:14 [INFO] Early stopping triggered\n",
      "2025-02-25 09:41:14 [INFO] Fine-tuning completed\n",
      "2025-02-25 09:41:14 [INFO] Best validation loss: 0.000266\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Import your existing model and dataset classes\n",
    "from Train2_12 import ExperimentalGNN, SpinSystemDataset, PhysicalScaleAwareLoss\n",
    "\n",
    "# Fine-tuning configuration\n",
    "FINETUNE_CONFIG = {\n",
    "    'pretrained_model_path': 'best_model_rung1_6_pre.pth',\n",
    "    'processed_dir_larger': './processed_experimentalrung7-8_10k_r6',\n",
    "    'processed_file_name': 'data.pt',\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.5e-4,\n",
    "    'weight_decay': 1.5e-4,\n",
    "    'num_epochs': 200,\n",
    "    'patience': 50,\n",
    "    'finetuned_model_path': 'finetuned_model.pth',\n",
    "    'dropout_p': 0.3,\n",
    "    'grad_clip': 0.5,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "\n",
    "def fine_tune_model():\n",
    "    setup_logging()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load the pretrained model\n",
    "    model = ExperimentalGNN(\n",
    "        hidden_channels=512,\n",
    "        dropout_p=FINETUNE_CONFIG['dropout_p']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load pretrained weights\n",
    "    pretrained_state_dict = torch.load(FINETUNE_CONFIG['pretrained_model_path'], map_location=device)\n",
    "    model.load_state_dict(pretrained_state_dict)\n",
    "    logging.info(\"Loaded pretrained model successfully\")\n",
    "\n",
    "    # Load the new dataset with larger system sizes\n",
    "    dataset = SpinSystemDataset(root=FINETUNE_CONFIG['processed_dir_larger'])\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(FINETUNE_CONFIG['random_seed'])\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "    # Initialize loss and optimizer\n",
    "    criterion = PhysicalScaleAwareLoss(physics_weight=0.5)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=FINETUNE_CONFIG['learning_rate'],\n",
    "        weight_decay=FINETUNE_CONFIG['weight_decay']\n",
    "    )\n",
    "\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=20,\n",
    "        T_mult=2,\n",
    "        eta_min=1e-7\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(FINETUNE_CONFIG['num_epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_mae = 0\n",
    "        total_train_samples = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            pred_s = model(data)\n",
    "            targets = data.y.squeeze().to(device)\n",
    "            system_size = data.system_size.squeeze(-1).to(device)\n",
    "            subsystem_size = data.nA.squeeze(-1).to(device)\n",
    "            \n",
    "            loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "            loss.backward()\n",
    "            \n",
    "            if FINETUNE_CONFIG['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), FINETUNE_CONFIG['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate MAE for this batch\n",
    "            mae = torch.abs(pred_s - targets).sum().item()\n",
    "            train_mae += mae\n",
    "            total_train_samples += data.num_graphs\n",
    "            total_train_loss += loss.item() * data.num_graphs\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataset)\n",
    "        avg_train_mae = train_mae / total_train_samples\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_mae = 0\n",
    "        total_val_samples = 0\n",
    "        all_val_preds = []\n",
    "        all_val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                pred_s = model(data)\n",
    "                targets = data.y.squeeze().to(device)  # Added .to(device)\n",
    "                system_size = data.system_size.squeeze(-1).to(device)  # Added .to(device)\n",
    "                subsystem_size = data.nA.squeeze(-1).to(device)  # Added .to(device)\n",
    "                \n",
    "                loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "                total_val_loss += loss.item() * data.num_graphs\n",
    "                \n",
    "                # Calculate MAE for this batch\n",
    "                mae = torch.abs(pred_s - targets).sum().item()\n",
    "                val_mae += mae\n",
    "                total_val_samples += data.num_graphs\n",
    "                \n",
    "                # Store CPU tensors for numpy conversion\n",
    "                all_val_preds.extend(pred_s.cpu().numpy())\n",
    "                all_val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_dataset)\n",
    "        avg_val_mae = val_mae / total_val_samples\n",
    "        scheduler.step()\n",
    "\n",
    "        logging.info(f'Epoch {epoch+1}/{FINETUNE_CONFIG[\"num_epochs\"]}:')\n",
    "        logging.info(f'  Training Loss: {avg_train_loss:.6f}')\n",
    "        logging.info(f'  Training MAE: {avg_train_mae:.6f}')\n",
    "        logging.info(f'  Validation Loss: {avg_val_loss:.6f}')\n",
    "        logging.info(f'  Validation MAE: {avg_val_mae:.6f}')\n",
    "\n",
    "        # Save best model and early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), FINETUNE_CONFIG['finetuned_model_path'])\n",
    "            logging.info(f'  Saved new best model (val_loss={best_val_loss:.6f})')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= FINETUNE_CONFIG['patience']:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    logging.info('Fine-tuning completed')\n",
    "    logging.info(f'Best validation loss: {best_val_loss:.6f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fine_tune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb05717-95ca-42bb-82f3-675566a55a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 09:41:14 [INFO] Logging initialized\n",
      "2025-02-25 09:41:14 [INFO] Using device: cuda\n",
      "2025-02-25 09:41:14 [INFO] Current working directory: C:\\Users\\amssa\\Documents\\Codes\\New\\Von-Neumann-Entropy-GNN\\Size14\n",
      "2025-02-25 09:41:14 [INFO] Directory ./processed_experimentalrung7-8_10k_r6 exists\n",
      "2025-02-25 09:41:14 [INFO] Files in ./processed_experimentalrung7-8_10k_r6: ['processed', 'raw']\n",
      "2025-02-25 09:41:14 [INFO] Processed directory exists: ./processed_experimentalrung7-8_10k_r6\\processed\n",
      "2025-02-25 09:41:14 [INFO] Files in processed dir: ['data.pt', 'pre_filter.pt', 'pre_transform.pt', 'processed', 'raw']\n",
      "2025-02-25 09:41:14 [INFO] Directory ./processed_experimentalrung7-8_10k_r6_2 exists\n",
      "2025-02-25 09:41:14 [INFO] Files in ./processed_experimentalrung7-8_10k_r6_2: ['processed', 'raw']\n",
      "2025-02-25 09:41:14 [INFO] Processed directory exists: ./processed_experimentalrung7-8_10k_r6_2\\processed\n",
      "2025-02-25 09:41:14 [INFO] Files in processed dir: ['data.pt', 'pre_filter.pt', 'pre_transform.pt']\n",
      "2025-02-25 09:41:14 [INFO] Loaded pretrained model successfully\n",
      "2025-02-25 09:41:14 [INFO] Found PyG dataset file: ./processed_experimentalrung7-8_10k_r6\\processed\\data.pt\n",
      "2025-02-25 09:41:14 [INFO] Found PyG dataset file: ./processed_experimentalrung7-8_10k_r6_2\\processed\\data.pt\n",
      "2025-02-25 09:41:14 [INFO] Found 1 files in ./processed_experimentalrung7-8_10k_r6 matching the pattern\n",
      "2025-02-25 09:41:14 [INFO]   - ./processed_experimentalrung7-8_10k_r6\\processed\\data.pt\n",
      "2025-02-25 09:41:14 [INFO] Found 1 files in ./processed_experimentalrung7-8_10k_r6_2 matching the pattern\n",
      "2025-02-25 09:41:14 [INFO]   - ./processed_experimentalrung7-8_10k_r6_2\\processed\\data.pt\n",
      "2025-02-25 09:41:14 [INFO] Attempting to load PyG dataset from ./processed_experimentalrung7-8_10k_r6\n",
      "2025-02-25 09:41:14 [INFO] Processed directory exists: ./processed_experimentalrung7-8_10k_r6\\processed\n",
      "2025-02-25 09:41:14 [INFO] Files in processed directory: ['data.pt', 'pre_filter.pt', 'pre_transform.pt', 'processed', 'raw']\n",
      "2025-02-25 09:41:14 [INFO] Successfully loaded PyG dataset from ./processed_experimentalrung7-8_10k_r6 with 10000 samples\n",
      "2025-02-25 09:41:14 [INFO] Attempting to load PyG dataset from ./processed_experimentalrung7-8_10k_r6_2\n",
      "2025-02-25 09:41:14 [INFO] Processed directory exists: ./processed_experimentalrung7-8_10k_r6_2\\processed\n",
      "2025-02-25 09:41:14 [INFO] Files in processed directory: ['data.pt', 'pre_filter.pt', 'pre_transform.pt']\n",
      "2025-02-25 09:41:14 [INFO] Successfully loaded PyG dataset from ./processed_experimentalrung7-8_10k_r6_2 with 10000 samples\n",
      "2025-02-25 09:41:14 [INFO] Combined dataset contains 20000 samples total\n",
      "2025-02-25 09:41:36 [INFO] Epoch 1/200:\n",
      "2025-02-25 09:41:36 [INFO]   Training Loss: 0.001785\n",
      "2025-02-25 09:41:36 [INFO]   Training MAE: 0.034906\n",
      "2025-02-25 09:41:36 [INFO]   Validation Loss: 0.000745\n",
      "2025-02-25 09:41:36 [INFO]   Validation MAE: 0.020850\n",
      "2025-02-25 09:41:37 [INFO]   Saved new best model (val_loss=0.000745)\n",
      "2025-02-25 09:41:56 [INFO] Epoch 2/200:\n",
      "2025-02-25 09:41:56 [INFO]   Training Loss: 0.000887\n",
      "2025-02-25 09:41:56 [INFO]   Training MAE: 0.025156\n",
      "2025-02-25 09:41:56 [INFO]   Validation Loss: 0.000501\n",
      "2025-02-25 09:41:56 [INFO]   Validation MAE: 0.016926\n",
      "2025-02-25 09:41:56 [INFO]   Saved new best model (val_loss=0.000501)\n",
      "2025-02-25 09:42:15 [INFO] Epoch 3/200:\n",
      "2025-02-25 09:42:15 [INFO]   Training Loss: 0.000748\n",
      "2025-02-25 09:42:15 [INFO]   Training MAE: 0.023303\n",
      "2025-02-25 09:42:15 [INFO]   Validation Loss: 0.000432\n",
      "2025-02-25 09:42:15 [INFO]   Validation MAE: 0.016353\n",
      "2025-02-25 09:42:15 [INFO]   Saved new best model (val_loss=0.000432)\n",
      "2025-02-25 09:42:34 [INFO] Epoch 4/200:\n",
      "2025-02-25 09:42:34 [INFO]   Training Loss: 0.000654\n",
      "2025-02-25 09:42:34 [INFO]   Training MAE: 0.022343\n",
      "2025-02-25 09:42:34 [INFO]   Validation Loss: 0.000388\n",
      "2025-02-25 09:42:34 [INFO]   Validation MAE: 0.015235\n",
      "2025-02-25 09:42:34 [INFO]   Saved new best model (val_loss=0.000388)\n",
      "2025-02-25 09:42:53 [INFO] Epoch 5/200:\n",
      "2025-02-25 09:42:53 [INFO]   Training Loss: 0.000619\n",
      "2025-02-25 09:42:53 [INFO]   Training MAE: 0.021534\n",
      "2025-02-25 09:42:53 [INFO]   Validation Loss: 0.000407\n",
      "2025-02-25 09:42:53 [INFO]   Validation MAE: 0.015493\n",
      "2025-02-25 09:43:12 [INFO] Epoch 6/200:\n",
      "2025-02-25 09:43:12 [INFO]   Training Loss: 0.000555\n",
      "2025-02-25 09:43:12 [INFO]   Training MAE: 0.020595\n",
      "2025-02-25 09:43:12 [INFO]   Validation Loss: 0.000339\n",
      "2025-02-25 09:43:12 [INFO]   Validation MAE: 0.014294\n",
      "2025-02-25 09:43:12 [INFO]   Saved new best model (val_loss=0.000339)\n",
      "2025-02-25 09:43:31 [INFO] Epoch 7/200:\n",
      "2025-02-25 09:43:31 [INFO]   Training Loss: 0.000522\n",
      "2025-02-25 09:43:31 [INFO]   Training MAE: 0.019949\n",
      "2025-02-25 09:43:31 [INFO]   Validation Loss: 0.000336\n",
      "2025-02-25 09:43:31 [INFO]   Validation MAE: 0.014014\n",
      "2025-02-25 09:43:31 [INFO]   Saved new best model (val_loss=0.000336)\n",
      "2025-02-25 09:43:50 [INFO] Epoch 8/200:\n",
      "2025-02-25 09:43:50 [INFO]   Training Loss: 0.000499\n",
      "2025-02-25 09:43:50 [INFO]   Training MAE: 0.019819\n",
      "2025-02-25 09:43:50 [INFO]   Validation Loss: 0.000297\n",
      "2025-02-25 09:43:50 [INFO]   Validation MAE: 0.013268\n",
      "2025-02-25 09:43:50 [INFO]   Saved new best model (val_loss=0.000297)\n",
      "2025-02-25 09:44:09 [INFO] Epoch 9/200:\n",
      "2025-02-25 09:44:09 [INFO]   Training Loss: 0.000477\n",
      "2025-02-25 09:44:09 [INFO]   Training MAE: 0.019478\n",
      "2025-02-25 09:44:09 [INFO]   Validation Loss: 0.000314\n",
      "2025-02-25 09:44:09 [INFO]   Validation MAE: 0.014165\n",
      "2025-02-25 09:44:28 [INFO] Epoch 10/200:\n",
      "2025-02-25 09:44:28 [INFO]   Training Loss: 0.000469\n",
      "2025-02-25 09:44:28 [INFO]   Training MAE: 0.019223\n",
      "2025-02-25 09:44:28 [INFO]   Validation Loss: 0.000287\n",
      "2025-02-25 09:44:28 [INFO]   Validation MAE: 0.013137\n",
      "2025-02-25 09:44:28 [INFO]   Saved new best model (val_loss=0.000287)\n",
      "2025-02-25 09:44:47 [INFO] Epoch 11/200:\n",
      "2025-02-25 09:44:47 [INFO]   Training Loss: 0.000452\n",
      "2025-02-25 09:44:47 [INFO]   Training MAE: 0.018845\n",
      "2025-02-25 09:44:47 [INFO]   Validation Loss: 0.000303\n",
      "2025-02-25 09:44:47 [INFO]   Validation MAE: 0.013646\n",
      "2025-02-25 09:45:06 [INFO] Epoch 12/200:\n",
      "2025-02-25 09:45:06 [INFO]   Training Loss: 0.000447\n",
      "2025-02-25 09:45:06 [INFO]   Training MAE: 0.018727\n",
      "2025-02-25 09:45:06 [INFO]   Validation Loss: 0.000292\n",
      "2025-02-25 09:45:06 [INFO]   Validation MAE: 0.013182\n",
      "2025-02-25 09:45:25 [INFO] Epoch 13/200:\n",
      "2025-02-25 09:45:25 [INFO]   Training Loss: 0.000436\n",
      "2025-02-25 09:45:25 [INFO]   Training MAE: 0.018420\n",
      "2025-02-25 09:45:25 [INFO]   Validation Loss: 0.000276\n",
      "2025-02-25 09:45:25 [INFO]   Validation MAE: 0.012833\n",
      "2025-02-25 09:45:25 [INFO]   Saved new best model (val_loss=0.000276)\n",
      "2025-02-25 09:45:44 [INFO] Epoch 14/200:\n",
      "2025-02-25 09:45:44 [INFO]   Training Loss: 0.000438\n",
      "2025-02-25 09:45:44 [INFO]   Training MAE: 0.018412\n",
      "2025-02-25 09:45:44 [INFO]   Validation Loss: 0.000269\n",
      "2025-02-25 09:45:44 [INFO]   Validation MAE: 0.012757\n",
      "2025-02-25 09:45:45 [INFO]   Saved new best model (val_loss=0.000269)\n",
      "2025-02-25 09:46:04 [INFO] Epoch 15/200:\n",
      "2025-02-25 09:46:04 [INFO]   Training Loss: 0.000415\n",
      "2025-02-25 09:46:04 [INFO]   Training MAE: 0.018101\n",
      "2025-02-25 09:46:04 [INFO]   Validation Loss: 0.000253\n",
      "2025-02-25 09:46:04 [INFO]   Validation MAE: 0.012205\n",
      "2025-02-25 09:46:04 [INFO]   Saved new best model (val_loss=0.000253)\n",
      "2025-02-25 09:46:23 [INFO] Epoch 16/200:\n",
      "2025-02-25 09:46:23 [INFO]   Training Loss: 0.000404\n",
      "2025-02-25 09:46:23 [INFO]   Training MAE: 0.017972\n",
      "2025-02-25 09:46:23 [INFO]   Validation Loss: 0.000265\n",
      "2025-02-25 09:46:23 [INFO]   Validation MAE: 0.012725\n",
      "2025-02-25 09:46:42 [INFO] Epoch 17/200:\n",
      "2025-02-25 09:46:42 [INFO]   Training Loss: 0.000394\n",
      "2025-02-25 09:46:42 [INFO]   Training MAE: 0.017600\n",
      "2025-02-25 09:46:42 [INFO]   Validation Loss: 0.000255\n",
      "2025-02-25 09:46:42 [INFO]   Validation MAE: 0.012192\n",
      "2025-02-25 09:47:02 [INFO] Epoch 18/200:\n",
      "2025-02-25 09:47:02 [INFO]   Training Loss: 0.000391\n",
      "2025-02-25 09:47:02 [INFO]   Training MAE: 0.017615\n",
      "2025-02-25 09:47:02 [INFO]   Validation Loss: 0.000276\n",
      "2025-02-25 09:47:02 [INFO]   Validation MAE: 0.013150\n",
      "2025-02-25 09:47:21 [INFO] Epoch 19/200:\n",
      "2025-02-25 09:47:21 [INFO]   Training Loss: 0.000396\n",
      "2025-02-25 09:47:21 [INFO]   Training MAE: 0.017628\n",
      "2025-02-25 09:47:21 [INFO]   Validation Loss: 0.000260\n",
      "2025-02-25 09:47:21 [INFO]   Validation MAE: 0.012500\n",
      "2025-02-25 09:47:41 [INFO] Epoch 20/200:\n",
      "2025-02-25 09:47:41 [INFO]   Training Loss: 0.000403\n",
      "2025-02-25 09:47:41 [INFO]   Training MAE: 0.017714\n",
      "2025-02-25 09:47:41 [INFO]   Validation Loss: 0.000254\n",
      "2025-02-25 09:47:41 [INFO]   Validation MAE: 0.012197\n",
      "2025-02-25 09:48:00 [INFO] Epoch 21/200:\n",
      "2025-02-25 09:48:00 [INFO]   Training Loss: 0.000458\n",
      "2025-02-25 09:48:00 [INFO]   Training MAE: 0.019167\n",
      "2025-02-25 09:48:00 [INFO]   Validation Loss: 0.000256\n",
      "2025-02-25 09:48:00 [INFO]   Validation MAE: 0.012363\n",
      "2025-02-25 09:48:19 [INFO] Epoch 22/200:\n",
      "2025-02-25 09:48:19 [INFO]   Training Loss: 0.000458\n",
      "2025-02-25 09:48:19 [INFO]   Training MAE: 0.019094\n",
      "2025-02-25 09:48:19 [INFO]   Validation Loss: 0.000326\n",
      "2025-02-25 09:48:19 [INFO]   Validation MAE: 0.014278\n",
      "2025-02-25 09:48:39 [INFO] Epoch 23/200:\n",
      "2025-02-25 09:48:39 [INFO]   Training Loss: 0.000424\n",
      "2025-02-25 09:48:39 [INFO]   Training MAE: 0.018402\n",
      "2025-02-25 09:48:39 [INFO]   Validation Loss: 0.000258\n",
      "2025-02-25 09:48:39 [INFO]   Validation MAE: 0.012270\n",
      "2025-02-25 09:48:58 [INFO] Epoch 24/200:\n",
      "2025-02-25 09:48:58 [INFO]   Training Loss: 0.000437\n",
      "2025-02-25 09:48:58 [INFO]   Training MAE: 0.018671\n",
      "2025-02-25 09:48:58 [INFO]   Validation Loss: 0.000254\n",
      "2025-02-25 09:48:58 [INFO]   Validation MAE: 0.012613\n",
      "2025-02-25 09:49:18 [INFO] Epoch 25/200:\n",
      "2025-02-25 09:49:18 [INFO]   Training Loss: 0.000408\n",
      "2025-02-25 09:49:18 [INFO]   Training MAE: 0.018065\n",
      "2025-02-25 09:49:18 [INFO]   Validation Loss: 0.000239\n",
      "2025-02-25 09:49:18 [INFO]   Validation MAE: 0.011561\n",
      "2025-02-25 09:49:18 [INFO]   Saved new best model (val_loss=0.000239)\n",
      "2025-02-25 09:49:37 [INFO] Epoch 26/200:\n",
      "2025-02-25 09:49:37 [INFO]   Training Loss: 0.000415\n",
      "2025-02-25 09:49:37 [INFO]   Training MAE: 0.018141\n",
      "2025-02-25 09:49:37 [INFO]   Validation Loss: 0.000236\n",
      "2025-02-25 09:49:37 [INFO]   Validation MAE: 0.011890\n",
      "2025-02-25 09:49:37 [INFO]   Saved new best model (val_loss=0.000236)\n",
      "2025-02-25 09:49:56 [INFO] Epoch 27/200:\n",
      "2025-02-25 09:49:56 [INFO]   Training Loss: 0.000386\n",
      "2025-02-25 09:49:56 [INFO]   Training MAE: 0.017789\n",
      "2025-02-25 09:49:56 [INFO]   Validation Loss: 0.000258\n",
      "2025-02-25 09:49:56 [INFO]   Validation MAE: 0.012603\n",
      "2025-02-25 09:50:16 [INFO] Epoch 28/200:\n",
      "2025-02-25 09:50:16 [INFO]   Training Loss: 0.000376\n",
      "2025-02-25 09:50:16 [INFO]   Training MAE: 0.017414\n",
      "2025-02-25 09:50:16 [INFO]   Validation Loss: 0.000262\n",
      "2025-02-25 09:50:16 [INFO]   Validation MAE: 0.012954\n",
      "2025-02-25 09:50:35 [INFO] Epoch 29/200:\n",
      "2025-02-25 09:50:35 [INFO]   Training Loss: 0.000376\n",
      "2025-02-25 09:50:35 [INFO]   Training MAE: 0.017512\n",
      "2025-02-25 09:50:35 [INFO]   Validation Loss: 0.000257\n",
      "2025-02-25 09:50:35 [INFO]   Validation MAE: 0.012266\n",
      "2025-02-25 09:50:54 [INFO] Epoch 30/200:\n",
      "2025-02-25 09:50:54 [INFO]   Training Loss: 0.000387\n",
      "2025-02-25 09:50:54 [INFO]   Training MAE: 0.017818\n",
      "2025-02-25 09:50:54 [INFO]   Validation Loss: 0.000250\n",
      "2025-02-25 09:50:54 [INFO]   Validation MAE: 0.012494\n",
      "2025-02-25 09:51:13 [INFO] Epoch 31/200:\n",
      "2025-02-25 09:51:13 [INFO]   Training Loss: 0.000359\n",
      "2025-02-25 09:51:13 [INFO]   Training MAE: 0.017328\n",
      "2025-02-25 09:51:13 [INFO]   Validation Loss: 0.000248\n",
      "2025-02-25 09:51:13 [INFO]   Validation MAE: 0.012944\n",
      "2025-02-25 09:51:33 [INFO] Epoch 32/200:\n",
      "2025-02-25 09:51:33 [INFO]   Training Loss: 0.000369\n",
      "2025-02-25 09:51:33 [INFO]   Training MAE: 0.017355\n",
      "2025-02-25 09:51:33 [INFO]   Validation Loss: 0.000222\n",
      "2025-02-25 09:51:33 [INFO]   Validation MAE: 0.011186\n",
      "2025-02-25 09:51:33 [INFO]   Saved new best model (val_loss=0.000222)\n",
      "2025-02-25 09:51:52 [INFO] Epoch 33/200:\n",
      "2025-02-25 09:51:52 [INFO]   Training Loss: 0.000369\n",
      "2025-02-25 09:51:52 [INFO]   Training MAE: 0.017396\n",
      "2025-02-25 09:51:52 [INFO]   Validation Loss: 0.000231\n",
      "2025-02-25 09:51:52 [INFO]   Validation MAE: 0.011400\n",
      "2025-02-25 09:52:12 [INFO] Epoch 34/200:\n",
      "2025-02-25 09:52:12 [INFO]   Training Loss: 0.000376\n",
      "2025-02-25 09:52:12 [INFO]   Training MAE: 0.017223\n",
      "2025-02-25 09:52:12 [INFO]   Validation Loss: 0.000243\n",
      "2025-02-25 09:52:12 [INFO]   Validation MAE: 0.012209\n",
      "2025-02-25 09:52:31 [INFO] Epoch 35/200:\n",
      "2025-02-25 09:52:31 [INFO]   Training Loss: 0.000346\n",
      "2025-02-25 09:52:31 [INFO]   Training MAE: 0.016659\n",
      "2025-02-25 09:52:31 [INFO]   Validation Loss: 0.000214\n",
      "2025-02-25 09:52:31 [INFO]   Validation MAE: 0.010872\n",
      "2025-02-25 09:52:31 [INFO]   Saved new best model (val_loss=0.000214)\n",
      "2025-02-25 09:52:50 [INFO] Epoch 36/200:\n",
      "2025-02-25 09:52:50 [INFO]   Training Loss: 0.000356\n",
      "2025-02-25 09:52:50 [INFO]   Training MAE: 0.017115\n",
      "2025-02-25 09:52:50 [INFO]   Validation Loss: 0.000220\n",
      "2025-02-25 09:52:50 [INFO]   Validation MAE: 0.011478\n",
      "2025-02-25 09:53:09 [INFO] Epoch 37/200:\n",
      "2025-02-25 09:53:09 [INFO]   Training Loss: 0.000341\n",
      "2025-02-25 09:53:09 [INFO]   Training MAE: 0.016842\n",
      "2025-02-25 09:53:09 [INFO]   Validation Loss: 0.000259\n",
      "2025-02-25 09:53:09 [INFO]   Validation MAE: 0.013085\n",
      "2025-02-25 09:53:28 [INFO] Epoch 38/200:\n",
      "2025-02-25 09:53:28 [INFO]   Training Loss: 0.000369\n",
      "2025-02-25 09:53:28 [INFO]   Training MAE: 0.017452\n",
      "2025-02-25 09:53:28 [INFO]   Validation Loss: 0.000208\n",
      "2025-02-25 09:53:28 [INFO]   Validation MAE: 0.010966\n",
      "2025-02-25 09:53:28 [INFO]   Saved new best model (val_loss=0.000208)\n",
      "2025-02-25 09:53:46 [INFO] Epoch 39/200:\n",
      "2025-02-25 09:53:46 [INFO]   Training Loss: 0.000345\n",
      "2025-02-25 09:53:46 [INFO]   Training MAE: 0.016875\n",
      "2025-02-25 09:53:46 [INFO]   Validation Loss: 0.000211\n",
      "2025-02-25 09:53:46 [INFO]   Validation MAE: 0.011141\n",
      "2025-02-25 09:54:04 [INFO] Epoch 40/200:\n",
      "2025-02-25 09:54:04 [INFO]   Training Loss: 0.000325\n",
      "2025-02-25 09:54:04 [INFO]   Training MAE: 0.016432\n",
      "2025-02-25 09:54:04 [INFO]   Validation Loss: 0.000206\n",
      "2025-02-25 09:54:04 [INFO]   Validation MAE: 0.011024\n",
      "2025-02-25 09:54:05 [INFO]   Saved new best model (val_loss=0.000206)\n",
      "2025-02-25 09:54:23 [INFO] Epoch 41/200:\n",
      "2025-02-25 09:54:23 [INFO]   Training Loss: 0.000337\n",
      "2025-02-25 09:54:23 [INFO]   Training MAE: 0.016782\n",
      "2025-02-25 09:54:23 [INFO]   Validation Loss: 0.000213\n",
      "2025-02-25 09:54:23 [INFO]   Validation MAE: 0.011112\n",
      "2025-02-25 09:54:42 [INFO] Epoch 42/200:\n",
      "2025-02-25 09:54:42 [INFO]   Training Loss: 0.000337\n",
      "2025-02-25 09:54:42 [INFO]   Training MAE: 0.016638\n",
      "2025-02-25 09:54:42 [INFO]   Validation Loss: 0.000240\n",
      "2025-02-25 09:54:42 [INFO]   Validation MAE: 0.012139\n",
      "2025-02-25 09:55:01 [INFO] Epoch 43/200:\n",
      "2025-02-25 09:55:01 [INFO]   Training Loss: 0.000336\n",
      "2025-02-25 09:55:01 [INFO]   Training MAE: 0.016762\n",
      "2025-02-25 09:55:01 [INFO]   Validation Loss: 0.000239\n",
      "2025-02-25 09:55:01 [INFO]   Validation MAE: 0.011903\n",
      "2025-02-25 09:55:20 [INFO] Epoch 44/200:\n",
      "2025-02-25 09:55:20 [INFO]   Training Loss: 0.000313\n",
      "2025-02-25 09:55:20 [INFO]   Training MAE: 0.016060\n",
      "2025-02-25 09:55:20 [INFO]   Validation Loss: 0.000208\n",
      "2025-02-25 09:55:20 [INFO]   Validation MAE: 0.010734\n",
      "2025-02-25 09:55:39 [INFO] Epoch 45/200:\n",
      "2025-02-25 09:55:39 [INFO]   Training Loss: 0.000307\n",
      "2025-02-25 09:55:39 [INFO]   Training MAE: 0.015857\n",
      "2025-02-25 09:55:39 [INFO]   Validation Loss: 0.000231\n",
      "2025-02-25 09:55:39 [INFO]   Validation MAE: 0.011495\n",
      "2025-02-25 09:55:59 [INFO] Epoch 46/200:\n",
      "2025-02-25 09:55:59 [INFO]   Training Loss: 0.000318\n",
      "2025-02-25 09:55:59 [INFO]   Training MAE: 0.016078\n",
      "2025-02-25 09:55:59 [INFO]   Validation Loss: 0.000227\n",
      "2025-02-25 09:55:59 [INFO]   Validation MAE: 0.011407\n",
      "2025-02-25 09:56:18 [INFO] Epoch 47/200:\n",
      "2025-02-25 09:56:18 [INFO]   Training Loss: 0.000295\n",
      "2025-02-25 09:56:18 [INFO]   Training MAE: 0.015573\n",
      "2025-02-25 09:56:18 [INFO]   Validation Loss: 0.000213\n",
      "2025-02-25 09:56:18 [INFO]   Validation MAE: 0.010995\n",
      "2025-02-25 09:56:38 [INFO] Epoch 48/200:\n",
      "2025-02-25 09:56:38 [INFO]   Training Loss: 0.000311\n",
      "2025-02-25 09:56:38 [INFO]   Training MAE: 0.015894\n",
      "2025-02-25 09:56:38 [INFO]   Validation Loss: 0.000212\n",
      "2025-02-25 09:56:38 [INFO]   Validation MAE: 0.010861\n",
      "2025-02-25 09:56:57 [INFO] Epoch 49/200:\n",
      "2025-02-25 09:56:57 [INFO]   Training Loss: 0.000304\n",
      "2025-02-25 09:56:57 [INFO]   Training MAE: 0.015695\n",
      "2025-02-25 09:56:57 [INFO]   Validation Loss: 0.000211\n",
      "2025-02-25 09:56:57 [INFO]   Validation MAE: 0.010969\n",
      "2025-02-25 09:57:16 [INFO] Epoch 50/200:\n",
      "2025-02-25 09:57:16 [INFO]   Training Loss: 0.000302\n",
      "2025-02-25 09:57:16 [INFO]   Training MAE: 0.015688\n",
      "2025-02-25 09:57:16 [INFO]   Validation Loss: 0.000234\n",
      "2025-02-25 09:57:16 [INFO]   Validation MAE: 0.011506\n",
      "2025-02-25 09:57:35 [INFO] Epoch 51/200:\n",
      "2025-02-25 09:57:35 [INFO]   Training Loss: 0.000304\n",
      "2025-02-25 09:57:35 [INFO]   Training MAE: 0.015848\n",
      "2025-02-25 09:57:35 [INFO]   Validation Loss: 0.000210\n",
      "2025-02-25 09:57:35 [INFO]   Validation MAE: 0.010850\n",
      "2025-02-25 09:57:54 [INFO] Epoch 52/200:\n",
      "2025-02-25 09:57:54 [INFO]   Training Loss: 0.000291\n",
      "2025-02-25 09:57:54 [INFO]   Training MAE: 0.015399\n",
      "2025-02-25 09:57:54 [INFO]   Validation Loss: 0.000203\n",
      "2025-02-25 09:57:54 [INFO]   Validation MAE: 0.010562\n",
      "2025-02-25 09:57:54 [INFO]   Saved new best model (val_loss=0.000203)\n",
      "2025-02-25 09:58:14 [INFO] Epoch 53/200:\n",
      "2025-02-25 09:58:14 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 09:58:14 [INFO]   Training MAE: 0.015395\n",
      "2025-02-25 09:58:14 [INFO]   Validation Loss: 0.000220\n",
      "2025-02-25 09:58:14 [INFO]   Validation MAE: 0.011459\n",
      "2025-02-25 09:58:33 [INFO] Epoch 54/200:\n",
      "2025-02-25 09:58:33 [INFO]   Training Loss: 0.000308\n",
      "2025-02-25 09:58:33 [INFO]   Training MAE: 0.015724\n",
      "2025-02-25 09:58:33 [INFO]   Validation Loss: 0.000200\n",
      "2025-02-25 09:58:33 [INFO]   Validation MAE: 0.010530\n",
      "2025-02-25 09:58:33 [INFO]   Saved new best model (val_loss=0.000200)\n",
      "2025-02-25 09:58:52 [INFO] Epoch 55/200:\n",
      "2025-02-25 09:58:52 [INFO]   Training Loss: 0.000300\n",
      "2025-02-25 09:58:52 [INFO]   Training MAE: 0.015587\n",
      "2025-02-25 09:58:52 [INFO]   Validation Loss: 0.000211\n",
      "2025-02-25 09:58:52 [INFO]   Validation MAE: 0.010987\n",
      "2025-02-25 09:59:11 [INFO] Epoch 56/200:\n",
      "2025-02-25 09:59:11 [INFO]   Training Loss: 0.000292\n",
      "2025-02-25 09:59:11 [INFO]   Training MAE: 0.015369\n",
      "2025-02-25 09:59:11 [INFO]   Validation Loss: 0.000209\n",
      "2025-02-25 09:59:11 [INFO]   Validation MAE: 0.010779\n",
      "2025-02-25 09:59:30 [INFO] Epoch 57/200:\n",
      "2025-02-25 09:59:30 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 09:59:30 [INFO]   Training MAE: 0.015614\n",
      "2025-02-25 09:59:30 [INFO]   Validation Loss: 0.000217\n",
      "2025-02-25 09:59:30 [INFO]   Validation MAE: 0.011242\n",
      "2025-02-25 09:59:49 [INFO] Epoch 58/200:\n",
      "2025-02-25 09:59:49 [INFO]   Training Loss: 0.000296\n",
      "2025-02-25 09:59:49 [INFO]   Training MAE: 0.015574\n",
      "2025-02-25 09:59:49 [INFO]   Validation Loss: 0.000208\n",
      "2025-02-25 09:59:49 [INFO]   Validation MAE: 0.010932\n",
      "2025-02-25 10:00:08 [INFO] Epoch 59/200:\n",
      "2025-02-25 10:00:08 [INFO]   Training Loss: 0.000290\n",
      "2025-02-25 10:00:08 [INFO]   Training MAE: 0.015384\n",
      "2025-02-25 10:00:08 [INFO]   Validation Loss: 0.000205\n",
      "2025-02-25 10:00:08 [INFO]   Validation MAE: 0.010608\n",
      "2025-02-25 10:00:27 [INFO] Epoch 60/200:\n",
      "2025-02-25 10:00:27 [INFO]   Training Loss: 0.000295\n",
      "2025-02-25 10:00:27 [INFO]   Training MAE: 0.015553\n",
      "2025-02-25 10:00:27 [INFO]   Validation Loss: 0.000203\n",
      "2025-02-25 10:00:27 [INFO]   Validation MAE: 0.010635\n",
      "2025-02-25 10:00:47 [INFO] Epoch 61/200:\n",
      "2025-02-25 10:00:47 [INFO]   Training Loss: 0.000332\n",
      "2025-02-25 10:00:47 [INFO]   Training MAE: 0.016709\n",
      "2025-02-25 10:00:47 [INFO]   Validation Loss: 0.000231\n",
      "2025-02-25 10:00:47 [INFO]   Validation MAE: 0.011770\n",
      "2025-02-25 10:01:06 [INFO] Epoch 62/200:\n",
      "2025-02-25 10:01:06 [INFO]   Training Loss: 0.000328\n",
      "2025-02-25 10:01:06 [INFO]   Training MAE: 0.016499\n",
      "2025-02-25 10:01:06 [INFO]   Validation Loss: 0.000232\n",
      "2025-02-25 10:01:06 [INFO]   Validation MAE: 0.012132\n",
      "2025-02-25 10:01:24 [INFO] Epoch 63/200:\n",
      "2025-02-25 10:01:24 [INFO]   Training Loss: 0.000360\n",
      "2025-02-25 10:01:24 [INFO]   Training MAE: 0.017233\n",
      "2025-02-25 10:01:24 [INFO]   Validation Loss: 0.000277\n",
      "2025-02-25 10:01:24 [INFO]   Validation MAE: 0.012948\n",
      "2025-02-25 10:01:43 [INFO] Epoch 64/200:\n",
      "2025-02-25 10:01:43 [INFO]   Training Loss: 0.000352\n",
      "2025-02-25 10:01:43 [INFO]   Training MAE: 0.017006\n",
      "2025-02-25 10:01:43 [INFO]   Validation Loss: 0.000245\n",
      "2025-02-25 10:01:43 [INFO]   Validation MAE: 0.012081\n",
      "2025-02-25 10:02:02 [INFO] Epoch 65/200:\n",
      "2025-02-25 10:02:02 [INFO]   Training Loss: 0.000342\n",
      "2025-02-25 10:02:02 [INFO]   Training MAE: 0.016925\n",
      "2025-02-25 10:02:02 [INFO]   Validation Loss: 0.000228\n",
      "2025-02-25 10:02:02 [INFO]   Validation MAE: 0.011378\n",
      "2025-02-25 10:02:21 [INFO] Epoch 66/200:\n",
      "2025-02-25 10:02:21 [INFO]   Training Loss: 0.000338\n",
      "2025-02-25 10:02:21 [INFO]   Training MAE: 0.016976\n",
      "2025-02-25 10:02:21 [INFO]   Validation Loss: 0.000236\n",
      "2025-02-25 10:02:21 [INFO]   Validation MAE: 0.011629\n",
      "2025-02-25 10:02:40 [INFO] Epoch 67/200:\n",
      "2025-02-25 10:02:40 [INFO]   Training Loss: 0.000340\n",
      "2025-02-25 10:02:40 [INFO]   Training MAE: 0.016821\n",
      "2025-02-25 10:02:40 [INFO]   Validation Loss: 0.000235\n",
      "2025-02-25 10:02:40 [INFO]   Validation MAE: 0.011737\n",
      "2025-02-25 10:02:58 [INFO] Epoch 68/200:\n",
      "2025-02-25 10:02:58 [INFO]   Training Loss: 0.000323\n",
      "2025-02-25 10:02:58 [INFO]   Training MAE: 0.016346\n",
      "2025-02-25 10:02:58 [INFO]   Validation Loss: 0.000220\n",
      "2025-02-25 10:02:58 [INFO]   Validation MAE: 0.011095\n",
      "2025-02-25 10:03:17 [INFO] Epoch 69/200:\n",
      "2025-02-25 10:03:17 [INFO]   Training Loss: 0.000327\n",
      "2025-02-25 10:03:17 [INFO]   Training MAE: 0.016486\n",
      "2025-02-25 10:03:17 [INFO]   Validation Loss: 0.000208\n",
      "2025-02-25 10:03:17 [INFO]   Validation MAE: 0.010712\n",
      "2025-02-25 10:03:35 [INFO] Epoch 70/200:\n",
      "2025-02-25 10:03:35 [INFO]   Training Loss: 0.000324\n",
      "2025-02-25 10:03:35 [INFO]   Training MAE: 0.016520\n",
      "2025-02-25 10:03:35 [INFO]   Validation Loss: 0.000233\n",
      "2025-02-25 10:03:35 [INFO]   Validation MAE: 0.011791\n",
      "2025-02-25 10:03:54 [INFO] Epoch 71/200:\n",
      "2025-02-25 10:03:54 [INFO]   Training Loss: 0.000339\n",
      "2025-02-25 10:03:54 [INFO]   Training MAE: 0.016698\n",
      "2025-02-25 10:03:54 [INFO]   Validation Loss: 0.000209\n",
      "2025-02-25 10:03:54 [INFO]   Validation MAE: 0.010881\n",
      "2025-02-25 10:04:12 [INFO] Epoch 72/200:\n",
      "2025-02-25 10:04:12 [INFO]   Training Loss: 0.000333\n",
      "2025-02-25 10:04:12 [INFO]   Training MAE: 0.016663\n",
      "2025-02-25 10:04:12 [INFO]   Validation Loss: 0.000229\n",
      "2025-02-25 10:04:12 [INFO]   Validation MAE: 0.011880\n",
      "2025-02-25 10:04:30 [INFO] Epoch 73/200:\n",
      "2025-02-25 10:04:30 [INFO]   Training Loss: 0.000327\n",
      "2025-02-25 10:04:30 [INFO]   Training MAE: 0.016654\n",
      "2025-02-25 10:04:30 [INFO]   Validation Loss: 0.000234\n",
      "2025-02-25 10:04:30 [INFO]   Validation MAE: 0.012232\n",
      "2025-02-25 10:04:49 [INFO] Epoch 74/200:\n",
      "2025-02-25 10:04:49 [INFO]   Training Loss: 0.000332\n",
      "2025-02-25 10:04:49 [INFO]   Training MAE: 0.016774\n",
      "2025-02-25 10:04:49 [INFO]   Validation Loss: 0.000230\n",
      "2025-02-25 10:04:49 [INFO]   Validation MAE: 0.011394\n",
      "2025-02-25 10:05:07 [INFO] Epoch 75/200:\n",
      "2025-02-25 10:05:07 [INFO]   Training Loss: 0.000306\n",
      "2025-02-25 10:05:07 [INFO]   Training MAE: 0.016007\n",
      "2025-02-25 10:05:07 [INFO]   Validation Loss: 0.000257\n",
      "2025-02-25 10:05:07 [INFO]   Validation MAE: 0.012234\n",
      "2025-02-25 10:05:27 [INFO] Epoch 76/200:\n",
      "2025-02-25 10:05:27 [INFO]   Training Loss: 0.000309\n",
      "2025-02-25 10:05:27 [INFO]   Training MAE: 0.015985\n",
      "2025-02-25 10:05:27 [INFO]   Validation Loss: 0.000207\n",
      "2025-02-25 10:05:27 [INFO]   Validation MAE: 0.010709\n",
      "2025-02-25 10:05:46 [INFO] Epoch 77/200:\n",
      "2025-02-25 10:05:46 [INFO]   Training Loss: 0.000317\n",
      "2025-02-25 10:05:46 [INFO]   Training MAE: 0.016228\n",
      "2025-02-25 10:05:46 [INFO]   Validation Loss: 0.000234\n",
      "2025-02-25 10:05:46 [INFO]   Validation MAE: 0.011646\n",
      "2025-02-25 10:06:06 [INFO] Epoch 78/200:\n",
      "2025-02-25 10:06:06 [INFO]   Training Loss: 0.000312\n",
      "2025-02-25 10:06:06 [INFO]   Training MAE: 0.016189\n",
      "2025-02-25 10:06:06 [INFO]   Validation Loss: 0.000219\n",
      "2025-02-25 10:06:06 [INFO]   Validation MAE: 0.011063\n",
      "2025-02-25 10:06:25 [INFO] Epoch 79/200:\n",
      "2025-02-25 10:06:25 [INFO]   Training Loss: 0.000305\n",
      "2025-02-25 10:06:25 [INFO]   Training MAE: 0.016072\n",
      "2025-02-25 10:06:25 [INFO]   Validation Loss: 0.000222\n",
      "2025-02-25 10:06:25 [INFO]   Validation MAE: 0.011215\n",
      "2025-02-25 10:06:45 [INFO] Epoch 80/200:\n",
      "2025-02-25 10:06:45 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:06:45 [INFO]   Training MAE: 0.015674\n",
      "2025-02-25 10:06:45 [INFO]   Validation Loss: 0.000224\n",
      "2025-02-25 10:06:45 [INFO]   Validation MAE: 0.011365\n",
      "2025-02-25 10:07:04 [INFO] Epoch 81/200:\n",
      "2025-02-25 10:07:04 [INFO]   Training Loss: 0.000298\n",
      "2025-02-25 10:07:04 [INFO]   Training MAE: 0.015763\n",
      "2025-02-25 10:07:04 [INFO]   Validation Loss: 0.000193\n",
      "2025-02-25 10:07:04 [INFO]   Validation MAE: 0.010262\n",
      "2025-02-25 10:07:04 [INFO]   Saved new best model (val_loss=0.000193)\n",
      "2025-02-25 10:07:24 [INFO] Epoch 82/200:\n",
      "2025-02-25 10:07:24 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 10:07:24 [INFO]   Training MAE: 0.015362\n",
      "2025-02-25 10:07:24 [INFO]   Validation Loss: 0.000219\n",
      "2025-02-25 10:07:24 [INFO]   Validation MAE: 0.011180\n",
      "2025-02-25 10:07:43 [INFO] Epoch 83/200:\n",
      "2025-02-25 10:07:43 [INFO]   Training Loss: 0.000295\n",
      "2025-02-25 10:07:43 [INFO]   Training MAE: 0.015797\n",
      "2025-02-25 10:07:43 [INFO]   Validation Loss: 0.000244\n",
      "2025-02-25 10:07:43 [INFO]   Validation MAE: 0.012078\n",
      "2025-02-25 10:08:03 [INFO] Epoch 84/200:\n",
      "2025-02-25 10:08:03 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:08:03 [INFO]   Training MAE: 0.015623\n",
      "2025-02-25 10:08:03 [INFO]   Validation Loss: 0.000203\n",
      "2025-02-25 10:08:03 [INFO]   Validation MAE: 0.010745\n",
      "2025-02-25 10:08:22 [INFO] Epoch 85/200:\n",
      "2025-02-25 10:08:22 [INFO]   Training Loss: 0.000299\n",
      "2025-02-25 10:08:22 [INFO]   Training MAE: 0.015827\n",
      "2025-02-25 10:08:22 [INFO]   Validation Loss: 0.000210\n",
      "2025-02-25 10:08:22 [INFO]   Validation MAE: 0.010989\n",
      "2025-02-25 10:08:41 [INFO] Epoch 86/200:\n",
      "2025-02-25 10:08:41 [INFO]   Training Loss: 0.000311\n",
      "2025-02-25 10:08:41 [INFO]   Training MAE: 0.016082\n",
      "2025-02-25 10:08:41 [INFO]   Validation Loss: 0.000198\n",
      "2025-02-25 10:08:41 [INFO]   Validation MAE: 0.010438\n",
      "2025-02-25 10:09:00 [INFO] Epoch 87/200:\n",
      "2025-02-25 10:09:00 [INFO]   Training Loss: 0.000296\n",
      "2025-02-25 10:09:00 [INFO]   Training MAE: 0.015701\n",
      "2025-02-25 10:09:00 [INFO]   Validation Loss: 0.000190\n",
      "2025-02-25 10:09:00 [INFO]   Validation MAE: 0.010271\n",
      "2025-02-25 10:09:00 [INFO]   Saved new best model (val_loss=0.000190)\n",
      "2025-02-25 10:09:19 [INFO] Epoch 88/200:\n",
      "2025-02-25 10:09:19 [INFO]   Training Loss: 0.000290\n",
      "2025-02-25 10:09:19 [INFO]   Training MAE: 0.015648\n",
      "2025-02-25 10:09:19 [INFO]   Validation Loss: 0.000209\n",
      "2025-02-25 10:09:19 [INFO]   Validation MAE: 0.010991\n",
      "2025-02-25 10:09:37 [INFO] Epoch 89/200:\n",
      "2025-02-25 10:09:37 [INFO]   Training Loss: 0.000303\n",
      "2025-02-25 10:09:37 [INFO]   Training MAE: 0.015960\n",
      "2025-02-25 10:09:37 [INFO]   Validation Loss: 0.000197\n",
      "2025-02-25 10:09:37 [INFO]   Validation MAE: 0.010414\n",
      "2025-02-25 10:09:55 [INFO] Epoch 90/200:\n",
      "2025-02-25 10:09:55 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:09:55 [INFO]   Training MAE: 0.015665\n",
      "2025-02-25 10:09:55 [INFO]   Validation Loss: 0.000196\n",
      "2025-02-25 10:09:55 [INFO]   Validation MAE: 0.010353\n",
      "2025-02-25 10:10:14 [INFO] Epoch 91/200:\n",
      "2025-02-25 10:10:14 [INFO]   Training Loss: 0.000288\n",
      "2025-02-25 10:10:14 [INFO]   Training MAE: 0.015452\n",
      "2025-02-25 10:10:14 [INFO]   Validation Loss: 0.000200\n",
      "2025-02-25 10:10:14 [INFO]   Validation MAE: 0.010581\n",
      "2025-02-25 10:10:33 [INFO] Epoch 92/200:\n",
      "2025-02-25 10:10:33 [INFO]   Training Loss: 0.000267\n",
      "2025-02-25 10:10:33 [INFO]   Training MAE: 0.015167\n",
      "2025-02-25 10:10:33 [INFO]   Validation Loss: 0.000202\n",
      "2025-02-25 10:10:33 [INFO]   Validation MAE: 0.010655\n",
      "2025-02-25 10:10:52 [INFO] Epoch 93/200:\n",
      "2025-02-25 10:10:52 [INFO]   Training Loss: 0.000289\n",
      "2025-02-25 10:10:52 [INFO]   Training MAE: 0.015553\n",
      "2025-02-25 10:10:52 [INFO]   Validation Loss: 0.000207\n",
      "2025-02-25 10:10:52 [INFO]   Validation MAE: 0.011042\n",
      "2025-02-25 10:11:12 [INFO] Epoch 94/200:\n",
      "2025-02-25 10:11:12 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 10:11:12 [INFO]   Training MAE: 0.015424\n",
      "2025-02-25 10:11:12 [INFO]   Validation Loss: 0.000196\n",
      "2025-02-25 10:11:12 [INFO]   Validation MAE: 0.010420\n",
      "2025-02-25 10:11:32 [INFO] Epoch 95/200:\n",
      "2025-02-25 10:11:32 [INFO]   Training Loss: 0.000296\n",
      "2025-02-25 10:11:32 [INFO]   Training MAE: 0.015665\n",
      "2025-02-25 10:11:32 [INFO]   Validation Loss: 0.000196\n",
      "2025-02-25 10:11:32 [INFO]   Validation MAE: 0.010307\n",
      "2025-02-25 10:11:51 [INFO] Epoch 96/200:\n",
      "2025-02-25 10:11:51 [INFO]   Training Loss: 0.000279\n",
      "2025-02-25 10:11:51 [INFO]   Training MAE: 0.015290\n",
      "2025-02-25 10:11:51 [INFO]   Validation Loss: 0.000197\n",
      "2025-02-25 10:11:51 [INFO]   Validation MAE: 0.010640\n",
      "2025-02-25 10:12:09 [INFO] Epoch 97/200:\n",
      "2025-02-25 10:12:09 [INFO]   Training Loss: 0.000275\n",
      "2025-02-25 10:12:09 [INFO]   Training MAE: 0.015235\n",
      "2025-02-25 10:12:09 [INFO]   Validation Loss: 0.000204\n",
      "2025-02-25 10:12:09 [INFO]   Validation MAE: 0.010430\n",
      "2025-02-25 10:12:28 [INFO] Epoch 98/200:\n",
      "2025-02-25 10:12:28 [INFO]   Training Loss: 0.000307\n",
      "2025-02-25 10:12:28 [INFO]   Training MAE: 0.015796\n",
      "2025-02-25 10:12:28 [INFO]   Validation Loss: 0.000262\n",
      "2025-02-25 10:12:28 [INFO]   Validation MAE: 0.012521\n",
      "2025-02-25 10:12:47 [INFO] Epoch 99/200:\n",
      "2025-02-25 10:12:47 [INFO]   Training Loss: 0.000282\n",
      "2025-02-25 10:12:47 [INFO]   Training MAE: 0.015585\n",
      "2025-02-25 10:12:47 [INFO]   Validation Loss: 0.000210\n",
      "2025-02-25 10:12:47 [INFO]   Validation MAE: 0.010736\n",
      "2025-02-25 10:13:06 [INFO] Epoch 100/200:\n",
      "2025-02-25 10:13:06 [INFO]   Training Loss: 0.000267\n",
      "2025-02-25 10:13:06 [INFO]   Training MAE: 0.015049\n",
      "2025-02-25 10:13:06 [INFO]   Validation Loss: 0.000196\n",
      "2025-02-25 10:13:06 [INFO]   Validation MAE: 0.010271\n",
      "2025-02-25 10:13:26 [INFO] Epoch 101/200:\n",
      "2025-02-25 10:13:26 [INFO]   Training Loss: 0.000288\n",
      "2025-02-25 10:13:26 [INFO]   Training MAE: 0.015597\n",
      "2025-02-25 10:13:26 [INFO]   Validation Loss: 0.000207\n",
      "2025-02-25 10:13:26 [INFO]   Validation MAE: 0.010835\n",
      "2025-02-25 10:13:45 [INFO] Epoch 102/200:\n",
      "2025-02-25 10:13:45 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 10:13:45 [INFO]   Training MAE: 0.015609\n",
      "2025-02-25 10:13:45 [INFO]   Validation Loss: 0.000202\n",
      "2025-02-25 10:13:45 [INFO]   Validation MAE: 0.010624\n",
      "2025-02-25 10:14:05 [INFO] Epoch 103/200:\n",
      "2025-02-25 10:14:05 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 10:14:05 [INFO]   Training MAE: 0.015343\n",
      "2025-02-25 10:14:05 [INFO]   Validation Loss: 0.000186\n",
      "2025-02-25 10:14:05 [INFO]   Validation MAE: 0.009854\n",
      "2025-02-25 10:14:05 [INFO]   Saved new best model (val_loss=0.000186)\n",
      "2025-02-25 10:14:23 [INFO] Epoch 104/200:\n",
      "2025-02-25 10:14:23 [INFO]   Training Loss: 0.000274\n",
      "2025-02-25 10:14:23 [INFO]   Training MAE: 0.015195\n",
      "2025-02-25 10:14:23 [INFO]   Validation Loss: 0.000191\n",
      "2025-02-25 10:14:23 [INFO]   Validation MAE: 0.010266\n",
      "2025-02-25 10:14:42 [INFO] Epoch 105/200:\n",
      "2025-02-25 10:14:42 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 10:14:42 [INFO]   Training MAE: 0.015384\n",
      "2025-02-25 10:14:42 [INFO]   Validation Loss: 0.000203\n",
      "2025-02-25 10:14:42 [INFO]   Validation MAE: 0.010648\n",
      "2025-02-25 10:15:00 [INFO] Epoch 106/200:\n",
      "2025-02-25 10:15:00 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 10:15:00 [INFO]   Training MAE: 0.015239\n",
      "2025-02-25 10:15:00 [INFO]   Validation Loss: 0.000219\n",
      "2025-02-25 10:15:00 [INFO]   Validation MAE: 0.011012\n",
      "2025-02-25 10:15:19 [INFO] Epoch 107/200:\n",
      "2025-02-25 10:15:19 [INFO]   Training Loss: 0.000270\n",
      "2025-02-25 10:15:19 [INFO]   Training MAE: 0.014989\n",
      "2025-02-25 10:15:19 [INFO]   Validation Loss: 0.000190\n",
      "2025-02-25 10:15:19 [INFO]   Validation MAE: 0.010144\n",
      "2025-02-25 10:15:39 [INFO] Epoch 108/200:\n",
      "2025-02-25 10:15:39 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 10:15:39 [INFO]   Training MAE: 0.015385\n",
      "2025-02-25 10:15:39 [INFO]   Validation Loss: 0.000186\n",
      "2025-02-25 10:15:39 [INFO]   Validation MAE: 0.009994\n",
      "2025-02-25 10:15:39 [INFO]   Saved new best model (val_loss=0.000186)\n",
      "2025-02-25 10:15:59 [INFO] Epoch 109/200:\n",
      "2025-02-25 10:15:59 [INFO]   Training Loss: 0.000262\n",
      "2025-02-25 10:15:59 [INFO]   Training MAE: 0.014857\n",
      "2025-02-25 10:15:59 [INFO]   Validation Loss: 0.000193\n",
      "2025-02-25 10:15:59 [INFO]   Validation MAE: 0.010227\n",
      "2025-02-25 10:16:19 [INFO] Epoch 110/200:\n",
      "2025-02-25 10:16:19 [INFO]   Training Loss: 0.000266\n",
      "2025-02-25 10:16:19 [INFO]   Training MAE: 0.014944\n",
      "2025-02-25 10:16:19 [INFO]   Validation Loss: 0.000205\n",
      "2025-02-25 10:16:19 [INFO]   Validation MAE: 0.010756\n",
      "2025-02-25 10:16:38 [INFO] Epoch 111/200:\n",
      "2025-02-25 10:16:38 [INFO]   Training Loss: 0.000248\n",
      "2025-02-25 10:16:38 [INFO]   Training MAE: 0.014618\n",
      "2025-02-25 10:16:38 [INFO]   Validation Loss: 0.000190\n",
      "2025-02-25 10:16:38 [INFO]   Validation MAE: 0.010082\n",
      "2025-02-25 10:16:57 [INFO] Epoch 112/200:\n",
      "2025-02-25 10:16:57 [INFO]   Training Loss: 0.000260\n",
      "2025-02-25 10:16:57 [INFO]   Training MAE: 0.014847\n",
      "2025-02-25 10:16:57 [INFO]   Validation Loss: 0.000191\n",
      "2025-02-25 10:16:57 [INFO]   Validation MAE: 0.010084\n",
      "2025-02-25 10:17:17 [INFO] Epoch 113/200:\n",
      "2025-02-25 10:17:17 [INFO]   Training Loss: 0.000260\n",
      "2025-02-25 10:17:17 [INFO]   Training MAE: 0.014804\n",
      "2025-02-25 10:17:17 [INFO]   Validation Loss: 0.000195\n",
      "2025-02-25 10:17:17 [INFO]   Validation MAE: 0.010259\n",
      "2025-02-25 10:17:36 [INFO] Epoch 114/200:\n",
      "2025-02-25 10:17:36 [INFO]   Training Loss: 0.000268\n",
      "2025-02-25 10:17:36 [INFO]   Training MAE: 0.015013\n",
      "2025-02-25 10:17:36 [INFO]   Validation Loss: 0.000195\n",
      "2025-02-25 10:17:36 [INFO]   Validation MAE: 0.010259\n",
      "2025-02-25 10:17:56 [INFO] Epoch 115/200:\n",
      "2025-02-25 10:17:56 [INFO]   Training Loss: 0.000264\n",
      "2025-02-25 10:17:56 [INFO]   Training MAE: 0.014789\n",
      "2025-02-25 10:17:56 [INFO]   Validation Loss: 0.000203\n",
      "2025-02-25 10:17:56 [INFO]   Validation MAE: 0.010566\n",
      "2025-02-25 10:18:16 [INFO] Epoch 116/200:\n",
      "2025-02-25 10:18:16 [INFO]   Training Loss: 0.000255\n",
      "2025-02-25 10:18:16 [INFO]   Training MAE: 0.014679\n",
      "2025-02-25 10:18:16 [INFO]   Validation Loss: 0.000206\n",
      "2025-02-25 10:18:16 [INFO]   Validation MAE: 0.010693\n",
      "2025-02-25 10:18:35 [INFO] Epoch 117/200:\n",
      "2025-02-25 10:18:35 [INFO]   Training Loss: 0.000250\n",
      "2025-02-25 10:18:35 [INFO]   Training MAE: 0.014466\n",
      "2025-02-25 10:18:35 [INFO]   Validation Loss: 0.000203\n",
      "2025-02-25 10:18:35 [INFO]   Validation MAE: 0.010616\n",
      "2025-02-25 10:18:53 [INFO] Epoch 118/200:\n",
      "2025-02-25 10:18:53 [INFO]   Training Loss: 0.000254\n",
      "2025-02-25 10:18:53 [INFO]   Training MAE: 0.014639\n",
      "2025-02-25 10:18:53 [INFO]   Validation Loss: 0.000196\n",
      "2025-02-25 10:18:53 [INFO]   Validation MAE: 0.010462\n",
      "2025-02-25 10:19:12 [INFO] Epoch 119/200:\n",
      "2025-02-25 10:19:12 [INFO]   Training Loss: 0.000257\n",
      "2025-02-25 10:19:12 [INFO]   Training MAE: 0.014604\n",
      "2025-02-25 10:19:12 [INFO]   Validation Loss: 0.000202\n",
      "2025-02-25 10:19:12 [INFO]   Validation MAE: 0.010627\n",
      "2025-02-25 10:19:32 [INFO] Epoch 120/200:\n",
      "2025-02-25 10:19:32 [INFO]   Training Loss: 0.000253\n",
      "2025-02-25 10:19:32 [INFO]   Training MAE: 0.014725\n",
      "2025-02-25 10:19:32 [INFO]   Validation Loss: 0.000183\n",
      "2025-02-25 10:19:32 [INFO]   Validation MAE: 0.009795\n",
      "2025-02-25 10:19:32 [INFO]   Saved new best model (val_loss=0.000183)\n",
      "2025-02-25 10:19:52 [INFO] Epoch 121/200:\n",
      "2025-02-25 10:19:52 [INFO]   Training Loss: 0.000256\n",
      "2025-02-25 10:19:52 [INFO]   Training MAE: 0.014752\n",
      "2025-02-25 10:19:52 [INFO]   Validation Loss: 0.000186\n",
      "2025-02-25 10:19:52 [INFO]   Validation MAE: 0.009954\n",
      "2025-02-25 10:20:11 [INFO] Epoch 122/200:\n",
      "2025-02-25 10:20:11 [INFO]   Training Loss: 0.000266\n",
      "2025-02-25 10:20:11 [INFO]   Training MAE: 0.014663\n",
      "2025-02-25 10:20:11 [INFO]   Validation Loss: 0.000201\n",
      "2025-02-25 10:20:11 [INFO]   Validation MAE: 0.010565\n",
      "2025-02-25 10:20:30 [INFO] Epoch 123/200:\n",
      "2025-02-25 10:20:30 [INFO]   Training Loss: 0.000254\n",
      "2025-02-25 10:20:30 [INFO]   Training MAE: 0.014472\n",
      "2025-02-25 10:20:30 [INFO]   Validation Loss: 0.000190\n",
      "2025-02-25 10:20:30 [INFO]   Validation MAE: 0.010024\n",
      "2025-02-25 10:20:49 [INFO] Epoch 124/200:\n",
      "2025-02-25 10:20:49 [INFO]   Training Loss: 0.000251\n",
      "2025-02-25 10:20:49 [INFO]   Training MAE: 0.014516\n",
      "2025-02-25 10:20:49 [INFO]   Validation Loss: 0.000188\n",
      "2025-02-25 10:20:49 [INFO]   Validation MAE: 0.009918\n",
      "2025-02-25 10:21:08 [INFO] Epoch 125/200:\n",
      "2025-02-25 10:21:08 [INFO]   Training Loss: 0.000253\n",
      "2025-02-25 10:21:08 [INFO]   Training MAE: 0.014501\n",
      "2025-02-25 10:21:08 [INFO]   Validation Loss: 0.000187\n",
      "2025-02-25 10:21:08 [INFO]   Validation MAE: 0.010035\n",
      "2025-02-25 10:21:27 [INFO] Epoch 126/200:\n",
      "2025-02-25 10:21:27 [INFO]   Training Loss: 0.000238\n",
      "2025-02-25 10:21:27 [INFO]   Training MAE: 0.014353\n",
      "2025-02-25 10:21:27 [INFO]   Validation Loss: 0.000211\n",
      "2025-02-25 10:21:27 [INFO]   Validation MAE: 0.010619\n",
      "2025-02-25 10:21:46 [INFO] Epoch 127/200:\n",
      "2025-02-25 10:21:46 [INFO]   Training Loss: 0.000243\n",
      "2025-02-25 10:21:46 [INFO]   Training MAE: 0.014223\n",
      "2025-02-25 10:21:46 [INFO]   Validation Loss: 0.000197\n",
      "2025-02-25 10:21:46 [INFO]   Validation MAE: 0.010207\n",
      "2025-02-25 10:22:05 [INFO] Epoch 128/200:\n",
      "2025-02-25 10:22:05 [INFO]   Training Loss: 0.000245\n",
      "2025-02-25 10:22:05 [INFO]   Training MAE: 0.014442\n",
      "2025-02-25 10:22:05 [INFO]   Validation Loss: 0.000196\n",
      "2025-02-25 10:22:05 [INFO]   Validation MAE: 0.010246\n",
      "2025-02-25 10:22:24 [INFO] Epoch 129/200:\n",
      "2025-02-25 10:22:24 [INFO]   Training Loss: 0.000252\n",
      "2025-02-25 10:22:24 [INFO]   Training MAE: 0.014421\n",
      "2025-02-25 10:22:24 [INFO]   Validation Loss: 0.000199\n",
      "2025-02-25 10:22:24 [INFO]   Validation MAE: 0.010432\n",
      "2025-02-25 10:22:43 [INFO] Epoch 130/200:\n",
      "2025-02-25 10:22:43 [INFO]   Training Loss: 0.000250\n",
      "2025-02-25 10:22:43 [INFO]   Training MAE: 0.014542\n",
      "2025-02-25 10:22:43 [INFO]   Validation Loss: 0.000193\n",
      "2025-02-25 10:22:43 [INFO]   Validation MAE: 0.010100\n",
      "2025-02-25 10:23:01 [INFO] Epoch 131/200:\n",
      "2025-02-25 10:23:01 [INFO]   Training Loss: 0.000247\n",
      "2025-02-25 10:23:01 [INFO]   Training MAE: 0.014335\n",
      "2025-02-25 10:23:01 [INFO]   Validation Loss: 0.000192\n",
      "2025-02-25 10:23:01 [INFO]   Validation MAE: 0.010119\n",
      "2025-02-25 10:23:20 [INFO] Epoch 132/200:\n",
      "2025-02-25 10:23:20 [INFO]   Training Loss: 0.000247\n",
      "2025-02-25 10:23:20 [INFO]   Training MAE: 0.014547\n",
      "2025-02-25 10:23:20 [INFO]   Validation Loss: 0.000185\n",
      "2025-02-25 10:23:20 [INFO]   Validation MAE: 0.009884\n",
      "2025-02-25 10:23:39 [INFO] Epoch 133/200:\n",
      "2025-02-25 10:23:39 [INFO]   Training Loss: 0.000248\n",
      "2025-02-25 10:23:39 [INFO]   Training MAE: 0.014373\n",
      "2025-02-25 10:23:39 [INFO]   Validation Loss: 0.000190\n",
      "2025-02-25 10:23:39 [INFO]   Validation MAE: 0.009966\n",
      "2025-02-25 10:23:58 [INFO] Epoch 134/200:\n",
      "2025-02-25 10:23:58 [INFO]   Training Loss: 0.000244\n",
      "2025-02-25 10:23:58 [INFO]   Training MAE: 0.014377\n",
      "2025-02-25 10:23:58 [INFO]   Validation Loss: 0.000186\n",
      "2025-02-25 10:23:58 [INFO]   Validation MAE: 0.009845\n",
      "2025-02-25 10:24:17 [INFO] Epoch 135/200:\n",
      "2025-02-25 10:24:17 [INFO]   Training Loss: 0.000251\n",
      "2025-02-25 10:24:17 [INFO]   Training MAE: 0.014419\n",
      "2025-02-25 10:24:17 [INFO]   Validation Loss: 0.000182\n",
      "2025-02-25 10:24:17 [INFO]   Validation MAE: 0.009675\n",
      "2025-02-25 10:24:17 [INFO]   Saved new best model (val_loss=0.000182)\n",
      "2025-02-25 10:24:37 [INFO] Epoch 136/200:\n",
      "2025-02-25 10:24:37 [INFO]   Training Loss: 0.000252\n",
      "2025-02-25 10:24:37 [INFO]   Training MAE: 0.014499\n",
      "2025-02-25 10:24:37 [INFO]   Validation Loss: 0.000189\n",
      "2025-02-25 10:24:37 [INFO]   Validation MAE: 0.009977\n",
      "2025-02-25 10:24:57 [INFO] Epoch 137/200:\n",
      "2025-02-25 10:24:57 [INFO]   Training Loss: 0.000245\n",
      "2025-02-25 10:24:57 [INFO]   Training MAE: 0.014408\n",
      "2025-02-25 10:24:57 [INFO]   Validation Loss: 0.000190\n",
      "2025-02-25 10:24:57 [INFO]   Validation MAE: 0.009970\n",
      "2025-02-25 10:25:17 [INFO] Epoch 138/200:\n",
      "2025-02-25 10:25:17 [INFO]   Training Loss: 0.000238\n",
      "2025-02-25 10:25:17 [INFO]   Training MAE: 0.014081\n",
      "2025-02-25 10:25:17 [INFO]   Validation Loss: 0.000192\n",
      "2025-02-25 10:25:17 [INFO]   Validation MAE: 0.010139\n",
      "2025-02-25 10:25:36 [INFO] Epoch 139/200:\n",
      "2025-02-25 10:25:36 [INFO]   Training Loss: 0.000259\n",
      "2025-02-25 10:25:36 [INFO]   Training MAE: 0.014657\n",
      "2025-02-25 10:25:36 [INFO]   Validation Loss: 0.000186\n",
      "2025-02-25 10:25:36 [INFO]   Validation MAE: 0.009851\n",
      "2025-02-25 10:25:58 [INFO] Epoch 140/200:\n",
      "2025-02-25 10:25:58 [INFO]   Training Loss: 0.000236\n",
      "2025-02-25 10:25:58 [INFO]   Training MAE: 0.013992\n",
      "2025-02-25 10:25:58 [INFO]   Validation Loss: 0.000187\n",
      "2025-02-25 10:25:58 [INFO]   Validation MAE: 0.009916\n",
      "2025-02-25 10:26:17 [INFO] Epoch 141/200:\n",
      "2025-02-25 10:26:17 [INFO]   Training Loss: 0.000280\n",
      "2025-02-25 10:26:17 [INFO]   Training MAE: 0.015325\n",
      "2025-02-25 10:26:17 [INFO]   Validation Loss: 0.000232\n",
      "2025-02-25 10:26:17 [INFO]   Validation MAE: 0.011603\n",
      "2025-02-25 10:26:36 [INFO] Epoch 142/200:\n",
      "2025-02-25 10:26:36 [INFO]   Training Loss: 0.000284\n",
      "2025-02-25 10:26:36 [INFO]   Training MAE: 0.015477\n",
      "2025-02-25 10:26:36 [INFO]   Validation Loss: 0.000287\n",
      "2025-02-25 10:26:36 [INFO]   Validation MAE: 0.013165\n",
      "2025-02-25 10:26:55 [INFO] Epoch 143/200:\n",
      "2025-02-25 10:26:55 [INFO]   Training Loss: 0.000307\n",
      "2025-02-25 10:26:55 [INFO]   Training MAE: 0.016125\n",
      "2025-02-25 10:26:55 [INFO]   Validation Loss: 0.000223\n",
      "2025-02-25 10:26:55 [INFO]   Validation MAE: 0.011343\n",
      "2025-02-25 10:27:14 [INFO] Epoch 144/200:\n",
      "2025-02-25 10:27:14 [INFO]   Training Loss: 0.000285\n",
      "2025-02-25 10:27:14 [INFO]   Training MAE: 0.015535\n",
      "2025-02-25 10:27:14 [INFO]   Validation Loss: 0.000231\n",
      "2025-02-25 10:27:14 [INFO]   Validation MAE: 0.011244\n",
      "2025-02-25 10:27:32 [INFO] Epoch 145/200:\n",
      "2025-02-25 10:27:32 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:27:32 [INFO]   Training MAE: 0.015670\n",
      "2025-02-25 10:27:32 [INFO]   Validation Loss: 0.000223\n",
      "2025-02-25 10:27:32 [INFO]   Validation MAE: 0.011569\n",
      "2025-02-25 10:27:51 [INFO] Epoch 146/200:\n",
      "2025-02-25 10:27:51 [INFO]   Training Loss: 0.000301\n",
      "2025-02-25 10:27:51 [INFO]   Training MAE: 0.016008\n",
      "2025-02-25 10:27:51 [INFO]   Validation Loss: 0.000200\n",
      "2025-02-25 10:27:51 [INFO]   Validation MAE: 0.010383\n",
      "2025-02-25 10:28:10 [INFO] Epoch 147/200:\n",
      "2025-02-25 10:28:10 [INFO]   Training Loss: 0.000293\n",
      "2025-02-25 10:28:10 [INFO]   Training MAE: 0.015732\n",
      "2025-02-25 10:28:10 [INFO]   Validation Loss: 0.000200\n",
      "2025-02-25 10:28:10 [INFO]   Validation MAE: 0.010459\n",
      "2025-02-25 10:28:30 [INFO] Epoch 148/200:\n",
      "2025-02-25 10:28:30 [INFO]   Training Loss: 0.000291\n",
      "2025-02-25 10:28:30 [INFO]   Training MAE: 0.015721\n",
      "2025-02-25 10:28:30 [INFO]   Validation Loss: 0.000237\n",
      "2025-02-25 10:28:30 [INFO]   Validation MAE: 0.011999\n",
      "2025-02-25 10:28:49 [INFO] Epoch 149/200:\n",
      "2025-02-25 10:28:49 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:28:49 [INFO]   Training MAE: 0.015669\n",
      "2025-02-25 10:28:49 [INFO]   Validation Loss: 0.000205\n",
      "2025-02-25 10:28:49 [INFO]   Validation MAE: 0.010609\n",
      "2025-02-25 10:29:08 [INFO] Epoch 150/200:\n",
      "2025-02-25 10:29:08 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:29:08 [INFO]   Training MAE: 0.015664\n",
      "2025-02-25 10:29:08 [INFO]   Validation Loss: 0.000222\n",
      "2025-02-25 10:29:08 [INFO]   Validation MAE: 0.011232\n",
      "2025-02-25 10:29:26 [INFO] Epoch 151/200:\n",
      "2025-02-25 10:29:26 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:29:26 [INFO]   Training MAE: 0.015780\n",
      "2025-02-25 10:29:26 [INFO]   Validation Loss: 0.000243\n",
      "2025-02-25 10:29:26 [INFO]   Validation MAE: 0.012122\n",
      "2025-02-25 10:29:45 [INFO] Epoch 152/200:\n",
      "2025-02-25 10:29:45 [INFO]   Training Loss: 0.000290\n",
      "2025-02-25 10:29:45 [INFO]   Training MAE: 0.015474\n",
      "2025-02-25 10:29:45 [INFO]   Validation Loss: 0.000223\n",
      "2025-02-25 10:29:45 [INFO]   Validation MAE: 0.010980\n",
      "2025-02-25 10:30:04 [INFO] Epoch 153/200:\n",
      "2025-02-25 10:30:04 [INFO]   Training Loss: 0.000289\n",
      "2025-02-25 10:30:04 [INFO]   Training MAE: 0.015538\n",
      "2025-02-25 10:30:04 [INFO]   Validation Loss: 0.000220\n",
      "2025-02-25 10:30:04 [INFO]   Validation MAE: 0.011490\n",
      "2025-02-25 10:30:22 [INFO] Epoch 154/200:\n",
      "2025-02-25 10:30:22 [INFO]   Training Loss: 0.000285\n",
      "2025-02-25 10:30:22 [INFO]   Training MAE: 0.015588\n",
      "2025-02-25 10:30:22 [INFO]   Validation Loss: 0.000228\n",
      "2025-02-25 10:30:22 [INFO]   Validation MAE: 0.011800\n",
      "2025-02-25 10:30:41 [INFO] Epoch 155/200:\n",
      "2025-02-25 10:30:41 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 10:30:41 [INFO]   Training MAE: 0.015593\n",
      "2025-02-25 10:30:41 [INFO]   Validation Loss: 0.000201\n",
      "2025-02-25 10:30:41 [INFO]   Validation MAE: 0.010678\n",
      "2025-02-25 10:31:01 [INFO] Epoch 156/200:\n",
      "2025-02-25 10:31:01 [INFO]   Training Loss: 0.000295\n",
      "2025-02-25 10:31:01 [INFO]   Training MAE: 0.015869\n",
      "2025-02-25 10:31:01 [INFO]   Validation Loss: 0.000214\n",
      "2025-02-25 10:31:01 [INFO]   Validation MAE: 0.011076\n",
      "2025-02-25 10:31:21 [INFO] Epoch 157/200:\n",
      "2025-02-25 10:31:21 [INFO]   Training Loss: 0.000301\n",
      "2025-02-25 10:31:21 [INFO]   Training MAE: 0.016102\n",
      "2025-02-25 10:31:21 [INFO]   Validation Loss: 0.000200\n",
      "2025-02-25 10:31:21 [INFO]   Validation MAE: 0.010584\n",
      "2025-02-25 10:31:40 [INFO] Epoch 158/200:\n",
      "2025-02-25 10:31:40 [INFO]   Training Loss: 0.000281\n",
      "2025-02-25 10:31:40 [INFO]   Training MAE: 0.015286\n",
      "2025-02-25 10:31:40 [INFO]   Validation Loss: 0.000198\n",
      "2025-02-25 10:31:40 [INFO]   Validation MAE: 0.010321\n",
      "2025-02-25 10:31:59 [INFO] Epoch 159/200:\n",
      "2025-02-25 10:31:59 [INFO]   Training Loss: 0.000279\n",
      "2025-02-25 10:31:59 [INFO]   Training MAE: 0.015412\n",
      "2025-02-25 10:31:59 [INFO]   Validation Loss: 0.000255\n",
      "2025-02-25 10:31:59 [INFO]   Validation MAE: 0.012216\n",
      "2025-02-25 10:32:18 [INFO] Epoch 160/200:\n",
      "2025-02-25 10:32:18 [INFO]   Training Loss: 0.000281\n",
      "2025-02-25 10:32:18 [INFO]   Training MAE: 0.015562\n",
      "2025-02-25 10:32:18 [INFO]   Validation Loss: 0.000200\n",
      "2025-02-25 10:32:18 [INFO]   Validation MAE: 0.010531\n",
      "2025-02-25 10:32:37 [INFO] Epoch 161/200:\n",
      "2025-02-25 10:32:37 [INFO]   Training Loss: 0.000282\n",
      "2025-02-25 10:32:37 [INFO]   Training MAE: 0.015702\n",
      "2025-02-25 10:32:37 [INFO]   Validation Loss: 0.000208\n",
      "2025-02-25 10:32:37 [INFO]   Validation MAE: 0.010668\n",
      "2025-02-25 10:32:57 [INFO] Epoch 162/200:\n",
      "2025-02-25 10:32:57 [INFO]   Training Loss: 0.000281\n",
      "2025-02-25 10:32:57 [INFO]   Training MAE: 0.015592\n",
      "2025-02-25 10:32:57 [INFO]   Validation Loss: 0.000213\n",
      "2025-02-25 10:32:57 [INFO]   Validation MAE: 0.011092\n",
      "2025-02-25 10:33:15 [INFO] Epoch 163/200:\n",
      "2025-02-25 10:33:15 [INFO]   Training Loss: 0.000277\n",
      "2025-02-25 10:33:15 [INFO]   Training MAE: 0.015371\n",
      "2025-02-25 10:33:15 [INFO]   Validation Loss: 0.000217\n",
      "2025-02-25 10:33:15 [INFO]   Validation MAE: 0.011433\n",
      "2025-02-25 10:33:34 [INFO] Epoch 164/200:\n",
      "2025-02-25 10:33:34 [INFO]   Training Loss: 0.000279\n",
      "2025-02-25 10:33:34 [INFO]   Training MAE: 0.015435\n",
      "2025-02-25 10:33:34 [INFO]   Validation Loss: 0.000203\n",
      "2025-02-25 10:33:34 [INFO]   Validation MAE: 0.010769\n",
      "2025-02-25 10:33:53 [INFO] Epoch 165/200:\n",
      "2025-02-25 10:33:53 [INFO]   Training Loss: 0.000287\n",
      "2025-02-25 10:33:53 [INFO]   Training MAE: 0.015662\n",
      "2025-02-25 10:33:53 [INFO]   Validation Loss: 0.000226\n",
      "2025-02-25 10:33:53 [INFO]   Validation MAE: 0.011720\n",
      "2025-02-25 10:34:13 [INFO] Epoch 166/200:\n",
      "2025-02-25 10:34:13 [INFO]   Training Loss: 0.000276\n",
      "2025-02-25 10:34:13 [INFO]   Training MAE: 0.015281\n",
      "2025-02-25 10:34:13 [INFO]   Validation Loss: 0.000191\n",
      "2025-02-25 10:34:13 [INFO]   Validation MAE: 0.010299\n",
      "2025-02-25 10:34:33 [INFO] Epoch 167/200:\n",
      "2025-02-25 10:34:33 [INFO]   Training Loss: 0.000275\n",
      "2025-02-25 10:34:33 [INFO]   Training MAE: 0.015294\n",
      "2025-02-25 10:34:33 [INFO]   Validation Loss: 0.000201\n",
      "2025-02-25 10:34:33 [INFO]   Validation MAE: 0.010424\n",
      "2025-02-25 10:34:53 [INFO] Epoch 168/200:\n",
      "2025-02-25 10:34:53 [INFO]   Training Loss: 0.000286\n",
      "2025-02-25 10:34:53 [INFO]   Training MAE: 0.015639\n",
      "2025-02-25 10:34:53 [INFO]   Validation Loss: 0.000196\n",
      "2025-02-25 10:34:53 [INFO]   Validation MAE: 0.010635\n",
      "2025-02-25 10:35:13 [INFO] Epoch 169/200:\n",
      "2025-02-25 10:35:13 [INFO]   Training Loss: 0.000269\n",
      "2025-02-25 10:35:13 [INFO]   Training MAE: 0.015134\n",
      "2025-02-25 10:35:13 [INFO]   Validation Loss: 0.000186\n",
      "2025-02-25 10:35:13 [INFO]   Validation MAE: 0.010317\n",
      "2025-02-25 10:35:32 [INFO] Epoch 170/200:\n",
      "2025-02-25 10:35:32 [INFO]   Training Loss: 0.000294\n",
      "2025-02-25 10:35:32 [INFO]   Training MAE: 0.015726\n",
      "2025-02-25 10:35:32 [INFO]   Validation Loss: 0.000216\n",
      "2025-02-25 10:35:32 [INFO]   Validation MAE: 0.011323\n",
      "2025-02-25 10:35:51 [INFO] Epoch 171/200:\n",
      "2025-02-25 10:35:51 [INFO]   Training Loss: 0.000276\n",
      "2025-02-25 10:35:51 [INFO]   Training MAE: 0.015358\n",
      "2025-02-25 10:35:51 [INFO]   Validation Loss: 0.000195\n",
      "2025-02-25 10:35:51 [INFO]   Validation MAE: 0.010324\n",
      "2025-02-25 10:36:11 [INFO] Epoch 172/200:\n",
      "2025-02-25 10:36:11 [INFO]   Training Loss: 0.000272\n",
      "2025-02-25 10:36:11 [INFO]   Training MAE: 0.015209\n",
      "2025-02-25 10:36:11 [INFO]   Validation Loss: 0.000287\n",
      "2025-02-25 10:36:11 [INFO]   Validation MAE: 0.013195\n",
      "2025-02-25 10:36:30 [INFO] Epoch 173/200:\n",
      "2025-02-25 10:36:30 [INFO]   Training Loss: 0.000289\n",
      "2025-02-25 10:36:30 [INFO]   Training MAE: 0.015705\n",
      "2025-02-25 10:36:30 [INFO]   Validation Loss: 0.000215\n",
      "2025-02-25 10:36:30 [INFO]   Validation MAE: 0.011398\n",
      "2025-02-25 10:36:48 [INFO] Epoch 174/200:\n",
      "2025-02-25 10:36:48 [INFO]   Training Loss: 0.000255\n",
      "2025-02-25 10:36:48 [INFO]   Training MAE: 0.014769\n",
      "2025-02-25 10:36:48 [INFO]   Validation Loss: 0.000202\n",
      "2025-02-25 10:36:48 [INFO]   Validation MAE: 0.010786\n",
      "2025-02-25 10:37:07 [INFO] Epoch 175/200:\n",
      "2025-02-25 10:37:07 [INFO]   Training Loss: 0.000257\n",
      "2025-02-25 10:37:07 [INFO]   Training MAE: 0.014828\n",
      "2025-02-25 10:37:07 [INFO]   Validation Loss: 0.000223\n",
      "2025-02-25 10:37:07 [INFO]   Validation MAE: 0.011164\n",
      "2025-02-25 10:37:26 [INFO] Epoch 176/200:\n",
      "2025-02-25 10:37:26 [INFO]   Training Loss: 0.000272\n",
      "2025-02-25 10:37:26 [INFO]   Training MAE: 0.015433\n",
      "2025-02-25 10:37:26 [INFO]   Validation Loss: 0.000225\n",
      "2025-02-25 10:37:26 [INFO]   Validation MAE: 0.011366\n",
      "2025-02-25 10:37:44 [INFO] Epoch 177/200:\n",
      "2025-02-25 10:37:44 [INFO]   Training Loss: 0.000269\n",
      "2025-02-25 10:37:44 [INFO]   Training MAE: 0.015141\n",
      "2025-02-25 10:37:44 [INFO]   Validation Loss: 0.000194\n",
      "2025-02-25 10:37:44 [INFO]   Validation MAE: 0.010376\n",
      "2025-02-25 10:38:04 [INFO] Epoch 178/200:\n",
      "2025-02-25 10:38:04 [INFO]   Training Loss: 0.000276\n",
      "2025-02-25 10:38:04 [INFO]   Training MAE: 0.015288\n",
      "2025-02-25 10:38:04 [INFO]   Validation Loss: 0.000214\n",
      "2025-02-25 10:38:04 [INFO]   Validation MAE: 0.011117\n",
      "2025-02-25 10:38:23 [INFO] Epoch 179/200:\n",
      "2025-02-25 10:38:23 [INFO]   Training Loss: 0.000261\n",
      "2025-02-25 10:38:23 [INFO]   Training MAE: 0.014923\n",
      "2025-02-25 10:38:23 [INFO]   Validation Loss: 0.000200\n",
      "2025-02-25 10:38:23 [INFO]   Validation MAE: 0.010716\n",
      "2025-02-25 10:38:42 [INFO] Epoch 180/200:\n",
      "2025-02-25 10:38:42 [INFO]   Training Loss: 0.000269\n",
      "2025-02-25 10:38:42 [INFO]   Training MAE: 0.015169\n",
      "2025-02-25 10:38:42 [INFO]   Validation Loss: 0.000194\n",
      "2025-02-25 10:38:42 [INFO]   Validation MAE: 0.010302\n",
      "2025-02-25 10:39:01 [INFO] Epoch 181/200:\n",
      "2025-02-25 10:39:01 [INFO]   Training Loss: 0.000274\n",
      "2025-02-25 10:39:01 [INFO]   Training MAE: 0.015434\n",
      "2025-02-25 10:39:01 [INFO]   Validation Loss: 0.000198\n",
      "2025-02-25 10:39:01 [INFO]   Validation MAE: 0.010605\n",
      "2025-02-25 10:39:19 [INFO] Epoch 182/200:\n",
      "2025-02-25 10:39:19 [INFO]   Training Loss: 0.000275\n",
      "2025-02-25 10:39:19 [INFO]   Training MAE: 0.015371\n",
      "2025-02-25 10:39:19 [INFO]   Validation Loss: 0.000189\n",
      "2025-02-25 10:39:19 [INFO]   Validation MAE: 0.010169\n",
      "2025-02-25 10:39:38 [INFO] Epoch 183/200:\n",
      "2025-02-25 10:39:38 [INFO]   Training Loss: 0.000271\n",
      "2025-02-25 10:39:38 [INFO]   Training MAE: 0.015143\n",
      "2025-02-25 10:39:38 [INFO]   Validation Loss: 0.000206\n",
      "2025-02-25 10:39:38 [INFO]   Validation MAE: 0.010924\n",
      "2025-02-25 10:39:56 [INFO] Epoch 184/200:\n",
      "2025-02-25 10:39:56 [INFO]   Training Loss: 0.000273\n",
      "2025-02-25 10:39:56 [INFO]   Training MAE: 0.015291\n",
      "2025-02-25 10:39:56 [INFO]   Validation Loss: 0.000191\n",
      "2025-02-25 10:39:56 [INFO]   Validation MAE: 0.010356\n",
      "2025-02-25 10:40:16 [INFO] Epoch 185/200:\n",
      "2025-02-25 10:40:16 [INFO]   Training Loss: 0.000266\n",
      "2025-02-25 10:40:16 [INFO]   Training MAE: 0.014985\n",
      "2025-02-25 10:40:16 [INFO]   Validation Loss: 0.000204\n",
      "2025-02-25 10:40:16 [INFO]   Validation MAE: 0.010905\n",
      "2025-02-25 10:40:16 [INFO] Early stopping triggered\n",
      "2025-02-25 10:40:16 [INFO] Fine-tuning completed\n",
      "2025-02-25 10:40:16 [INFO] Best validation loss: 0.000182\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Import your existing model and dataset classes\n",
    "from Train2_12 import ExperimentalGNN, SpinSystemDataset, PhysicalScaleAwareLoss\n",
    "\n",
    "# Fine-tuning configuration\n",
    "FINETUNE_CONFIG = {\n",
    "    'pretrained_model_path': 'best_model_rung1_6_pre.pth',\n",
    "    'data_dirs': [\n",
    "        './processed_experimentalrung7-8_10k_r6',\n",
    "        './processed_experimentalrung7-8_10k_r6_2'\n",
    "    ],  # List of directories containing .pt files\n",
    "    'processed_file_pattern': 'data*.pt',  # Pattern to match multiple files\n",
    "    'alternative_file_paths': [\n",
    "        # Add direct paths to specific .pt files if needed\n",
    "        # './processed_data/data_v1.pt',\n",
    "        # './processed_data/data_v2.pt'\n",
    "    ],\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.5e-4,\n",
    "    'weight_decay': 1.5e-4,\n",
    "    'num_epochs': 200,\n",
    "    'patience': 50,\n",
    "    'finetuned_model_path': 'finetuned_model.pth',\n",
    "    'dropout_p': 0.3,\n",
    "    'grad_clip': 0.5,\n",
    "    'random_seed': 42,\n",
    "    'verbose_logging': True  # Set to True for detailed debug information\n",
    "}\n",
    "\n",
    "def setup_logging():\n",
    "    level = logging.DEBUG if FINETUNE_CONFIG.get('verbose_logging', False) else logging.INFO\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "    # Create file handler\n",
    "    file_handler = logging.FileHandler('finetuning.log')\n",
    "    file_handler.setLevel(level)\n",
    "    file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))\n",
    "    \n",
    "    # Add file handler to root logger\n",
    "    logging.getLogger('').addHandler(file_handler)\n",
    "    \n",
    "    logging.info(\"Logging initialized\")\n",
    "\n",
    "class DirectPTFileDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset that loads directly from specified .pt files\"\"\"\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "        logging.info(f\"Attempting to load {len(file_paths)} PT files directly\")\n",
    "        \n",
    "        # Load all data from these files\n",
    "        self.data_list = []\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            if not os.path.exists(file_path):\n",
    "                logging.error(f\"File does not exist: {file_path}\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                logging.info(f\"Loading file: {file_path}\")\n",
    "                data_obj = torch.load(file_path)\n",
    "                \n",
    "                if isinstance(data_obj, list):\n",
    "                    logging.info(f\"Loaded list of {len(data_obj)} objects from {file_path}\")\n",
    "                    self.data_list.extend(data_obj)\n",
    "                elif hasattr(data_obj, 'x'):\n",
    "                    logging.info(f\"Loaded single data object from {file_path}\")\n",
    "                    self.data_list.append(data_obj)\n",
    "                else:\n",
    "                    logging.warning(f\"Unrecognized data format in {file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {file_path}: {str(e)}\", exc_info=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "class CustomSpinSystemDataset(SpinSystemDataset):\n",
    "    \"\"\"Extended version of SpinSystemDataset with better error handling\"\"\"\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        try:\n",
    "            # Check if the path exists\n",
    "            if not os.path.exists(root):\n",
    "                logging.error(f\"Directory does not exist: {root}\")\n",
    "                raise FileNotFoundError(f\"Directory does not exist: {root}\")\n",
    "                \n",
    "            # Try to initialize with original SpinSystemDataset\n",
    "            super(CustomSpinSystemDataset, self).__init__(root=root, transform=transform, pre_transform=pre_transform)\n",
    "            \n",
    "            # Look for processed directory and check its contents\n",
    "            processed_dir = os.path.join(root, 'processed')\n",
    "            if os.path.exists(processed_dir):\n",
    "                logging.info(f\"Processed directory exists: {processed_dir}\")\n",
    "                processed_files = os.listdir(processed_dir)\n",
    "                logging.info(f\"Files in processed directory: {processed_files}\")\n",
    "            else:\n",
    "                logging.warning(f\"No 'processed' directory found in {root}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error initializing CustomSpinSystemDataset: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "\n",
    "    def download(self):\n",
    "        # Override to avoid download attempts\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        # Override to avoid processing attempts if files already exist\n",
    "        processed_file_path = os.path.join(self.processed_dir, 'data.pt')\n",
    "        if os.path.exists(processed_file_path):\n",
    "            logging.info(f\"Processed file already exists: {processed_file_path}\")\n",
    "        else:\n",
    "            logging.warning(f\"Processed file does not exist: {processed_file_path}\")\n",
    "            # We would need to implement the processing logic here if needed\n",
    "            raise FileNotFoundError(f\"Required processed file not found: {processed_file_path}\")\n",
    "            \n",
    "    def _download(self):\n",
    "        # Override internal method\n",
    "        pass\n",
    "        \n",
    "    def _process(self):\n",
    "        # Override internal method if files exist\n",
    "        if not os.path.exists(os.path.join(self.processed_dir, 'data.pt')):\n",
    "            logging.error(f\"Processed file not found at {os.path.join(self.processed_dir, 'data.pt')}\")\n",
    "            raise FileNotFoundError(f\"Required processed file not found\")\n",
    "\n",
    "    \n",
    "    def _merge_data(self, data1, slices1, data2, slices2):\n",
    "        \"\"\"Merge two datasets together\"\"\"\n",
    "        # Create new data object with combined attributes\n",
    "        merged_data = data1.__class__()\n",
    "        \n",
    "        # Combine all attributes from both data objects\n",
    "        for key in data1.keys:\n",
    "            # Get the attribute from both datasets\n",
    "            item1, item2 = getattr(data1, key), getattr(data2, key)\n",
    "            \n",
    "            # Concatenate the attributes\n",
    "            if torch.is_tensor(item1) and torch.is_tensor(item2):\n",
    "                merged_attr = torch.cat([item1, item2], dim=data1.__cat_dim__(key, item1))\n",
    "            else:\n",
    "                merged_attr = item1 + item2  # For non-tensor attributes like edge_index\n",
    "                \n",
    "            setattr(merged_data, key, merged_attr)\n",
    "            \n",
    "        # Update the slices for the merged data\n",
    "        merged_slices = {}\n",
    "        for key in slices1.keys():\n",
    "            if key in slices2:\n",
    "                # Get the current maximum index from the first slice\n",
    "                offset = slices1[key][-1]\n",
    "                \n",
    "                # Add this offset to all indices in the second slice (except the first one)\n",
    "                second_slice_shifted = slices2[key][1:] + offset\n",
    "                \n",
    "                # Combine the slices, keeping only one copy of the overlapping index\n",
    "                merged_slice = torch.cat([slices1[key], second_slice_shifted])\n",
    "                merged_slices[key] = merged_slice\n",
    "        \n",
    "        return merged_data, merged_slices\n",
    "\n",
    "def load_multi_datasets():\n",
    "    \"\"\"Load multiple datasets from different directories\"\"\"\n",
    "    datasets = []\n",
    "    \n",
    "    # First check all directories for processed/data.pt files (PyG default)\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        # Check for processed/data.pt (standard PyG dataset structure)\n",
    "        pyg_file_path = os.path.join(data_dir, 'processed', 'data.pt')\n",
    "        if os.path.exists(pyg_file_path):\n",
    "            logging.info(f\"Found PyG dataset file: {pyg_file_path}\")\n",
    "    \n",
    "    # Check for pattern-matched files within the directories\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if os.path.exists(data_dir):\n",
    "            # First check in the main directory\n",
    "            pattern = os.path.join(data_dir, FINETUNE_CONFIG['processed_file_pattern'])\n",
    "            main_files = glob.glob(pattern)\n",
    "            \n",
    "            # Then check in the processed subdirectory\n",
    "            processed_pattern = os.path.join(data_dir, 'processed', FINETUNE_CONFIG['processed_file_pattern'])\n",
    "            processed_files = glob.glob(processed_pattern)\n",
    "            \n",
    "            all_files = main_files + processed_files\n",
    "            logging.info(f\"Found {len(all_files)} files in {data_dir} matching the pattern\")\n",
    "            for file in all_files:\n",
    "                logging.info(f\"  - {file}\")\n",
    "    \n",
    "    # Attempt each loading method\n",
    "    # 1. Try loading as standard PyG SpinSystemDataset from each directory\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if not os.path.exists(data_dir):\n",
    "            logging.error(f\"Directory does not exist: {data_dir}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            logging.info(f\"Attempting to load PyG dataset from {data_dir}\")\n",
    "            dataset = CustomSpinSystemDataset(root=data_dir)\n",
    "            datasets.append(dataset)\n",
    "            logging.info(f\"Successfully loaded PyG dataset from {data_dir} with {len(dataset)} samples\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not load PyG dataset from {data_dir}: {str(e)}\")\n",
    "            \n",
    "            # Check for data.pt in the processed directory\n",
    "            processed_file = os.path.join(data_dir, 'processed', 'data.pt')\n",
    "            if os.path.exists(processed_file):\n",
    "                try:\n",
    "                    logging.info(f\"Attempting to load direct data from {processed_file}\")\n",
    "                    # Try to load this specific file directly\n",
    "                    direct_dataset = DirectPTFileDataset([processed_file])\n",
    "                    if len(direct_dataset) > 0:\n",
    "                        datasets.append(direct_dataset)\n",
    "                        logging.info(f\"Loaded {len(direct_dataset)} samples directly from {processed_file}\")\n",
    "                except Exception as direct_e:\n",
    "                    logging.error(f\"Failed to load direct file {processed_file}: {str(direct_e)}\")\n",
    "    \n",
    "    # 2. Try loading from additional specified PT files\n",
    "    if hasattr(FINETUNE_CONFIG, 'alternative_file_paths') and FINETUNE_CONFIG['alternative_file_paths']:\n",
    "        direct_dataset = DirectPTFileDataset(FINETUNE_CONFIG['alternative_file_paths'])\n",
    "        if len(direct_dataset) > 0:\n",
    "            datasets.append(direct_dataset)\n",
    "            logging.info(f\"Loaded {len(direct_dataset)} samples from specified PT files\")\n",
    "    \n",
    "    # 3. If all else fails, request the proper file path\n",
    "    if not datasets:\n",
    "        logging.error(\"\"\"\n",
    "        No datasets could be loaded from the specified directories.\n",
    "        \n",
    "        Please check the following:\n",
    "        1. Verify that your data directories exist\n",
    "        2. Check that PyG dataset files are in a 'processed/data.pt' path\n",
    "        3. Try specifying direct paths to PT files in 'alternative_file_paths'\n",
    "        \"\"\")\n",
    "        \n",
    "        # Get user input for data file path\n",
    "        print(\"\\nNo datasets could be loaded from the specified directories.\")\n",
    "        print(\"Please enter the path to a PyTorch Geometric dataset file (data.pt):\")\n",
    "        file_path = input(\"Path: \").strip()\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Try to load it as a direct PT file\n",
    "                direct_dataset = DirectPTFileDataset([file_path])\n",
    "                if len(direct_dataset) > 0:\n",
    "                    datasets.append(direct_dataset)\n",
    "                    logging.info(f\"Loaded {len(direct_dataset)} samples from user-specified {file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to load user-specified file: {str(e)}\")\n",
    "                \n",
    "                # Last resort - try to find parent directory and load as PyG dataset\n",
    "                parent_dir = os.path.dirname(os.path.dirname(file_path))\n",
    "                try:\n",
    "                    dataset = CustomSpinSystemDataset(root=parent_dir)\n",
    "                    datasets.append(dataset)\n",
    "                    logging.info(f\"Loaded PyG dataset from {parent_dir} with {len(dataset)} samples\")\n",
    "                except Exception as pe:\n",
    "                    logging.error(f\"Failed to load from parent directory {parent_dir}: {str(pe)}\")\n",
    "                    raise ValueError(\"No datasets could be loaded. Please check your data files.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Specified file does not exist: {file_path}\")\n",
    "    \n",
    "    # Combine all datasets\n",
    "    combined_dataset = ConcatDataset(datasets) if len(datasets) > 0 else None\n",
    "    if combined_dataset:\n",
    "        logging.info(f\"Combined dataset contains {len(combined_dataset)} samples total\")\n",
    "    else:\n",
    "        raise ValueError(\"No datasets could be loaded\")\n",
    "    \n",
    "    return combined_dataset\n",
    "\n",
    "def fine_tune_model():\n",
    "    setup_logging()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Print out current working directory and available files for debugging\n",
    "    logging.info(f\"Current working directory: {os.getcwd()}\")\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if os.path.exists(data_dir):\n",
    "            logging.info(f\"Directory {data_dir} exists\")\n",
    "            files = os.listdir(data_dir)\n",
    "            logging.info(f\"Files in {data_dir}: {files}\")\n",
    "            # Check if processed_dir exists\n",
    "            processed_dir = os.path.join(data_dir, 'processed')\n",
    "            if os.path.exists(processed_dir):\n",
    "                logging.info(f\"Processed directory exists: {processed_dir}\")\n",
    "                processed_files = os.listdir(processed_dir)\n",
    "                logging.info(f\"Files in processed dir: {processed_files}\")\n",
    "        else:\n",
    "            logging.error(f\"Directory {data_dir} does not exist!\")\n",
    "    \n",
    "    # Load the pretrained model\n",
    "    try:\n",
    "        model = ExperimentalGNN(\n",
    "            hidden_channels=512,\n",
    "            dropout_p=FINETUNE_CONFIG['dropout_p']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Check if pretrained model file exists\n",
    "        if not os.path.exists(FINETUNE_CONFIG['pretrained_model_path']):\n",
    "            logging.error(f\"Pretrained model file not found: {FINETUNE_CONFIG['pretrained_model_path']}\")\n",
    "            raise FileNotFoundError(f\"Pretrained model file not found: {FINETUNE_CONFIG['pretrained_model_path']}\")\n",
    "            \n",
    "        # Load pretrained weights\n",
    "        pretrained_state_dict = torch.load(FINETUNE_CONFIG['pretrained_model_path'], map_location=device)\n",
    "        model.load_state_dict(pretrained_state_dict)\n",
    "        logging.info(\"Loaded pretrained model successfully\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading model: {str(e)}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "    # Load datasets from multiple directories\n",
    "    combined_dataset = load_multi_datasets()\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(combined_dataset))\n",
    "    val_size = len(combined_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        combined_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(FINETUNE_CONFIG['random_seed'])\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "    # Initialize loss and optimizer\n",
    "    criterion = PhysicalScaleAwareLoss(physics_weight=0.5)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=FINETUNE_CONFIG['learning_rate'],\n",
    "        weight_decay=FINETUNE_CONFIG['weight_decay']\n",
    "    )\n",
    "\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=20,\n",
    "        T_mult=2,\n",
    "        eta_min=1e-7\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(FINETUNE_CONFIG['num_epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_mae = 0\n",
    "        total_train_samples = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            pred_s = model(data)\n",
    "            targets = data.y.squeeze().to(device)\n",
    "            system_size = data.system_size.squeeze(-1).to(device)\n",
    "            subsystem_size = data.nA.squeeze(-1).to(device)\n",
    "            \n",
    "            loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "            loss.backward()\n",
    "            \n",
    "            if FINETUNE_CONFIG['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), FINETUNE_CONFIG['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate MAE for this batch\n",
    "            mae = torch.abs(pred_s - targets).sum().item()\n",
    "            train_mae += mae\n",
    "            total_train_samples += data.num_graphs\n",
    "            total_train_loss += loss.item() * data.num_graphs\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataset)\n",
    "        avg_train_mae = train_mae / total_train_samples\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_mae = 0\n",
    "        total_val_samples = 0\n",
    "        all_val_preds = []\n",
    "        all_val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                pred_s = model(data)\n",
    "                targets = data.y.squeeze().to(device)\n",
    "                system_size = data.system_size.squeeze(-1).to(device)\n",
    "                subsystem_size = data.nA.squeeze(-1).to(device)\n",
    "                \n",
    "                loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "                total_val_loss += loss.item() * data.num_graphs\n",
    "                \n",
    "                # Calculate MAE for this batch\n",
    "                mae = torch.abs(pred_s - targets).sum().item()\n",
    "                val_mae += mae\n",
    "                total_val_samples += data.num_graphs\n",
    "                \n",
    "                # Store CPU tensors for numpy conversion\n",
    "                all_val_preds.extend(pred_s.cpu().numpy())\n",
    "                all_val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_dataset)\n",
    "        avg_val_mae = val_mae / total_val_samples\n",
    "        scheduler.step()\n",
    "\n",
    "        logging.info(f'Epoch {epoch+1}/{FINETUNE_CONFIG[\"num_epochs\"]}:')\n",
    "        logging.info(f'  Training Loss: {avg_train_loss:.6f}')\n",
    "        logging.info(f'  Training MAE: {avg_train_mae:.6f}')\n",
    "        logging.info(f'  Validation Loss: {avg_val_loss:.6f}')\n",
    "        logging.info(f'  Validation MAE: {avg_val_mae:.6f}')\n",
    "\n",
    "        # Save best model and early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), FINETUNE_CONFIG['finetuned_model_path'])\n",
    "            logging.info(f'  Saved new best model (val_loss={best_val_loss:.6f})')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= FINETUNE_CONFIG['patience']:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    logging.info('Fine-tuning completed')\n",
    "    logging.info(f'Best validation loss: {best_val_loss:.6f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fine_tune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a8c70f-f5b4-4ecc-9879-66cd650a498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amssa\\anaconda3\\envs\\env_name\\Lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "C:\\Users\\amssa\\anaconda3\\envs\\env_name\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Intel® Extension for PyTorch* needs to work with PyTorch 2.3.*, but PyTorch 2.5.1 is found. Please switch to the matching version and run again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amssa\\AppData\\Local\\Temp\\ipykernel_5512\\2245601938.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state_dict = torch.load(FINETUNE_CONFIG['pretrained_model_path'], map_location=device)\n",
      "2025-03-08 11:48:31 [INFO] Loaded pretrained model successfully\n",
      "2025-03-08 11:48:32 [INFO] Pretrained model performance:\n",
      "2025-03-08 11:48:32 [INFO]   Validation Loss: 0.006081\n",
      "2025-03-08 11:48:32 [INFO]   Validation MAE: 0.066555\n",
      "2025-03-08 11:48:33 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_pretrained.png\n",
      "2025-03-08 11:48:47 [INFO] Epoch 1/200:\n",
      "2025-03-08 11:48:47 [INFO]   Training Loss: 0.004260\n",
      "2025-03-08 11:48:47 [INFO]   Training MAE: 0.058869\n",
      "2025-03-08 11:48:47 [INFO]   Validation Loss: 0.002060\n",
      "2025-03-08 11:48:47 [INFO]   Validation MAE: 0.037451\n",
      "2025-03-08 11:48:48 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_1.png\n",
      "2025-03-08 11:48:48 [INFO]   Saved new best model (val_loss=0.002060)\n",
      "2025-03-08 11:48:48 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:49:02 [INFO] Epoch 2/200:\n",
      "2025-03-08 11:49:02 [INFO]   Training Loss: 0.002699\n",
      "2025-03-08 11:49:02 [INFO]   Training MAE: 0.047880\n",
      "2025-03-08 11:49:02 [INFO]   Validation Loss: 0.002026\n",
      "2025-03-08 11:49:02 [INFO]   Validation MAE: 0.036405\n",
      "2025-03-08 11:49:02 [INFO]   Saved new best model (val_loss=0.002026)\n",
      "2025-03-08 11:49:02 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:49:15 [INFO] Epoch 3/200:\n",
      "2025-03-08 11:49:15 [INFO]   Training Loss: 0.001830\n",
      "2025-03-08 11:49:15 [INFO]   Training MAE: 0.038097\n",
      "2025-03-08 11:49:15 [INFO]   Validation Loss: 0.002072\n",
      "2025-03-08 11:49:15 [INFO]   Validation MAE: 0.034975\n",
      "2025-03-08 11:49:30 [INFO] Epoch 4/200:\n",
      "2025-03-08 11:49:30 [INFO]   Training Loss: 0.001811\n",
      "2025-03-08 11:49:30 [INFO]   Training MAE: 0.037894\n",
      "2025-03-08 11:49:30 [INFO]   Validation Loss: 0.001915\n",
      "2025-03-08 11:49:30 [INFO]   Validation MAE: 0.033992\n",
      "2025-03-08 11:49:30 [INFO]   Saved new best model (val_loss=0.001915)\n",
      "2025-03-08 11:49:30 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:49:45 [INFO] Epoch 5/200:\n",
      "2025-03-08 11:49:45 [INFO]   Training Loss: 0.001532\n",
      "2025-03-08 11:49:45 [INFO]   Training MAE: 0.034506\n",
      "2025-03-08 11:49:45 [INFO]   Validation Loss: 0.001696\n",
      "2025-03-08 11:49:45 [INFO]   Validation MAE: 0.031627\n",
      "2025-03-08 11:49:45 [INFO]   Saved new best model (val_loss=0.001696)\n",
      "2025-03-08 11:49:46 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:50:01 [INFO] Epoch 6/200:\n",
      "2025-03-08 11:50:01 [INFO]   Training Loss: 0.001464\n",
      "2025-03-08 11:50:01 [INFO]   Training MAE: 0.034853\n",
      "2025-03-08 11:50:01 [INFO]   Validation Loss: 0.001840\n",
      "2025-03-08 11:50:01 [INFO]   Validation MAE: 0.032298\n",
      "2025-03-08 11:50:16 [INFO] Epoch 7/200:\n",
      "2025-03-08 11:50:16 [INFO]   Training Loss: 0.001222\n",
      "2025-03-08 11:50:16 [INFO]   Training MAE: 0.029560\n",
      "2025-03-08 11:50:16 [INFO]   Validation Loss: 0.001729\n",
      "2025-03-08 11:50:16 [INFO]   Validation MAE: 0.031189\n",
      "2025-03-08 11:50:30 [INFO] Epoch 8/200:\n",
      "2025-03-08 11:50:30 [INFO]   Training Loss: 0.001142\n",
      "2025-03-08 11:50:30 [INFO]   Training MAE: 0.029644\n",
      "2025-03-08 11:50:30 [INFO]   Validation Loss: 0.001644\n",
      "2025-03-08 11:50:30 [INFO]   Validation MAE: 0.030387\n",
      "2025-03-08 11:50:30 [INFO]   Saved new best model (val_loss=0.001644)\n",
      "2025-03-08 11:50:30 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:50:44 [INFO] Epoch 9/200:\n",
      "2025-03-08 11:50:44 [INFO]   Training Loss: 0.001140\n",
      "2025-03-08 11:50:44 [INFO]   Training MAE: 0.030371\n",
      "2025-03-08 11:50:44 [INFO]   Validation Loss: 0.001830\n",
      "2025-03-08 11:50:44 [INFO]   Validation MAE: 0.031958\n",
      "2025-03-08 11:50:58 [INFO] Epoch 10/200:\n",
      "2025-03-08 11:50:58 [INFO]   Training Loss: 0.001093\n",
      "2025-03-08 11:50:58 [INFO]   Training MAE: 0.029085\n",
      "2025-03-08 11:50:58 [INFO]   Validation Loss: 0.001647\n",
      "2025-03-08 11:50:58 [INFO]   Validation MAE: 0.029901\n",
      "2025-03-08 11:50:59 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_10.png\n",
      "2025-03-08 11:51:13 [INFO] Epoch 11/200:\n",
      "2025-03-08 11:51:13 [INFO]   Training Loss: 0.000994\n",
      "2025-03-08 11:51:13 [INFO]   Training MAE: 0.028189\n",
      "2025-03-08 11:51:13 [INFO]   Validation Loss: 0.001510\n",
      "2025-03-08 11:51:13 [INFO]   Validation MAE: 0.028778\n",
      "2025-03-08 11:51:13 [INFO]   Saved new best model (val_loss=0.001510)\n",
      "2025-03-08 11:51:14 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:51:27 [INFO] Epoch 12/200:\n",
      "2025-03-08 11:51:27 [INFO]   Training Loss: 0.001117\n",
      "2025-03-08 11:51:27 [INFO]   Training MAE: 0.029517\n",
      "2025-03-08 11:51:27 [INFO]   Validation Loss: 0.001507\n",
      "2025-03-08 11:51:27 [INFO]   Validation MAE: 0.028429\n",
      "2025-03-08 11:51:28 [INFO]   Saved new best model (val_loss=0.001507)\n",
      "2025-03-08 11:51:28 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:51:41 [INFO] Epoch 13/200:\n",
      "2025-03-08 11:51:41 [INFO]   Training Loss: 0.001229\n",
      "2025-03-08 11:51:41 [INFO]   Training MAE: 0.031541\n",
      "2025-03-08 11:51:41 [INFO]   Validation Loss: 0.001584\n",
      "2025-03-08 11:51:41 [INFO]   Validation MAE: 0.029016\n",
      "2025-03-08 11:51:55 [INFO] Epoch 14/200:\n",
      "2025-03-08 11:51:55 [INFO]   Training Loss: 0.000991\n",
      "2025-03-08 11:51:55 [INFO]   Training MAE: 0.027854\n",
      "2025-03-08 11:51:55 [INFO]   Validation Loss: 0.001570\n",
      "2025-03-08 11:51:55 [INFO]   Validation MAE: 0.028946\n",
      "2025-03-08 11:52:09 [INFO] Epoch 15/200:\n",
      "2025-03-08 11:52:09 [INFO]   Training Loss: 0.002012\n",
      "2025-03-08 11:52:09 [INFO]   Training MAE: 0.033767\n",
      "2025-03-08 11:52:09 [INFO]   Validation Loss: 0.001803\n",
      "2025-03-08 11:52:09 [INFO]   Validation MAE: 0.032948\n",
      "2025-03-08 11:52:22 [INFO] Epoch 16/200:\n",
      "2025-03-08 11:52:22 [INFO]   Training Loss: 0.000908\n",
      "2025-03-08 11:52:22 [INFO]   Training MAE: 0.027420\n",
      "2025-03-08 11:52:22 [INFO]   Validation Loss: 0.001486\n",
      "2025-03-08 11:52:22 [INFO]   Validation MAE: 0.028306\n",
      "2025-03-08 11:52:22 [INFO]   Saved new best model (val_loss=0.001486)\n",
      "2025-03-08 11:52:22 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:52:36 [INFO] Epoch 17/200:\n",
      "2025-03-08 11:52:36 [INFO]   Training Loss: 0.000902\n",
      "2025-03-08 11:52:36 [INFO]   Training MAE: 0.026351\n",
      "2025-03-08 11:52:36 [INFO]   Validation Loss: 0.001537\n",
      "2025-03-08 11:52:36 [INFO]   Validation MAE: 0.028323\n",
      "2025-03-08 11:52:49 [INFO] Epoch 18/200:\n",
      "2025-03-08 11:52:49 [INFO]   Training Loss: 0.000978\n",
      "2025-03-08 11:52:49 [INFO]   Training MAE: 0.027281\n",
      "2025-03-08 11:52:49 [INFO]   Validation Loss: 0.001647\n",
      "2025-03-08 11:52:49 [INFO]   Validation MAE: 0.029921\n",
      "2025-03-08 11:53:03 [INFO] Epoch 19/200:\n",
      "2025-03-08 11:53:03 [INFO]   Training Loss: 0.000758\n",
      "2025-03-08 11:53:03 [INFO]   Training MAE: 0.025038\n",
      "2025-03-08 11:53:03 [INFO]   Validation Loss: 0.001630\n",
      "2025-03-08 11:53:03 [INFO]   Validation MAE: 0.029591\n",
      "2025-03-08 11:53:16 [INFO] Epoch 20/200:\n",
      "2025-03-08 11:53:16 [INFO]   Training Loss: 0.001048\n",
      "2025-03-08 11:53:16 [INFO]   Training MAE: 0.027446\n",
      "2025-03-08 11:53:16 [INFO]   Validation Loss: 0.001528\n",
      "2025-03-08 11:53:16 [INFO]   Validation MAE: 0.028287\n",
      "2025-03-08 11:53:16 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_20.png\n",
      "2025-03-08 11:53:30 [INFO] Epoch 21/200:\n",
      "2025-03-08 11:53:30 [INFO]   Training Loss: 0.000977\n",
      "2025-03-08 11:53:30 [INFO]   Training MAE: 0.027349\n",
      "2025-03-08 11:53:30 [INFO]   Validation Loss: 0.001419\n",
      "2025-03-08 11:53:30 [INFO]   Validation MAE: 0.027961\n",
      "2025-03-08 11:53:30 [INFO]   Saved new best model (val_loss=0.001419)\n",
      "2025-03-08 11:53:30 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:53:44 [INFO] Epoch 22/200:\n",
      "2025-03-08 11:53:44 [INFO]   Training Loss: 0.000870\n",
      "2025-03-08 11:53:44 [INFO]   Training MAE: 0.025965\n",
      "2025-03-08 11:53:44 [INFO]   Validation Loss: 0.001615\n",
      "2025-03-08 11:53:44 [INFO]   Validation MAE: 0.030062\n",
      "2025-03-08 11:53:59 [INFO] Epoch 23/200:\n",
      "2025-03-08 11:53:59 [INFO]   Training Loss: 0.000813\n",
      "2025-03-08 11:53:59 [INFO]   Training MAE: 0.025799\n",
      "2025-03-08 11:53:59 [INFO]   Validation Loss: 0.001585\n",
      "2025-03-08 11:53:59 [INFO]   Validation MAE: 0.030206\n",
      "2025-03-08 11:54:13 [INFO] Epoch 24/200:\n",
      "2025-03-08 11:54:13 [INFO]   Training Loss: 0.000762\n",
      "2025-03-08 11:54:13 [INFO]   Training MAE: 0.024959\n",
      "2025-03-08 11:54:13 [INFO]   Validation Loss: 0.001406\n",
      "2025-03-08 11:54:13 [INFO]   Validation MAE: 0.027961\n",
      "2025-03-08 11:54:13 [INFO]   Saved new best model (val_loss=0.001406)\n",
      "2025-03-08 11:54:14 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:54:28 [INFO] Epoch 25/200:\n",
      "2025-03-08 11:54:28 [INFO]   Training Loss: 0.000867\n",
      "2025-03-08 11:54:28 [INFO]   Training MAE: 0.025689\n",
      "2025-03-08 11:54:28 [INFO]   Validation Loss: 0.001384\n",
      "2025-03-08 11:54:28 [INFO]   Validation MAE: 0.028191\n",
      "2025-03-08 11:54:28 [INFO]   Saved new best model (val_loss=0.001384)\n",
      "2025-03-08 11:54:28 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:54:43 [INFO] Epoch 26/200:\n",
      "2025-03-08 11:54:43 [INFO]   Training Loss: 0.000768\n",
      "2025-03-08 11:54:43 [INFO]   Training MAE: 0.025673\n",
      "2025-03-08 11:54:43 [INFO]   Validation Loss: 0.001349\n",
      "2025-03-08 11:54:43 [INFO]   Validation MAE: 0.028159\n",
      "2025-03-08 11:54:43 [INFO]   Saved new best model (val_loss=0.001349)\n",
      "2025-03-08 11:54:43 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:54:57 [INFO] Epoch 27/200:\n",
      "2025-03-08 11:54:57 [INFO]   Training Loss: 0.000771\n",
      "2025-03-08 11:54:57 [INFO]   Training MAE: 0.024968\n",
      "2025-03-08 11:54:57 [INFO]   Validation Loss: 0.001675\n",
      "2025-03-08 11:54:57 [INFO]   Validation MAE: 0.031053\n",
      "2025-03-08 11:55:11 [INFO] Epoch 28/200:\n",
      "2025-03-08 11:55:11 [INFO]   Training Loss: 0.000843\n",
      "2025-03-08 11:55:11 [INFO]   Training MAE: 0.025550\n",
      "2025-03-08 11:55:11 [INFO]   Validation Loss: 0.001408\n",
      "2025-03-08 11:55:11 [INFO]   Validation MAE: 0.028681\n",
      "2025-03-08 11:55:25 [INFO] Epoch 29/200:\n",
      "2025-03-08 11:55:25 [INFO]   Training Loss: 0.000949\n",
      "2025-03-08 11:55:25 [INFO]   Training MAE: 0.026400\n",
      "2025-03-08 11:55:25 [INFO]   Validation Loss: 0.001461\n",
      "2025-03-08 11:55:25 [INFO]   Validation MAE: 0.029148\n",
      "2025-03-08 11:55:40 [INFO] Epoch 30/200:\n",
      "2025-03-08 11:55:40 [INFO]   Training Loss: 0.000914\n",
      "2025-03-08 11:55:40 [INFO]   Training MAE: 0.026950\n",
      "2025-03-08 11:55:40 [INFO]   Validation Loss: 0.001371\n",
      "2025-03-08 11:55:40 [INFO]   Validation MAE: 0.028300\n",
      "2025-03-08 11:55:40 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_30.png\n",
      "2025-03-08 11:55:54 [INFO] Epoch 31/200:\n",
      "2025-03-08 11:55:54 [INFO]   Training Loss: 0.000696\n",
      "2025-03-08 11:55:54 [INFO]   Training MAE: 0.024088\n",
      "2025-03-08 11:55:54 [INFO]   Validation Loss: 0.001482\n",
      "2025-03-08 11:55:54 [INFO]   Validation MAE: 0.029736\n",
      "2025-03-08 11:56:09 [INFO] Epoch 32/200:\n",
      "2025-03-08 11:56:09 [INFO]   Training Loss: 0.000782\n",
      "2025-03-08 11:56:09 [INFO]   Training MAE: 0.024554\n",
      "2025-03-08 11:56:09 [INFO]   Validation Loss: 0.001383\n",
      "2025-03-08 11:56:09 [INFO]   Validation MAE: 0.029042\n",
      "2025-03-08 11:56:23 [INFO] Epoch 33/200:\n",
      "2025-03-08 11:56:23 [INFO]   Training Loss: 0.000728\n",
      "2025-03-08 11:56:23 [INFO]   Training MAE: 0.024585\n",
      "2025-03-08 11:56:23 [INFO]   Validation Loss: 0.001324\n",
      "2025-03-08 11:56:23 [INFO]   Validation MAE: 0.028302\n",
      "2025-03-08 11:56:23 [INFO]   Saved new best model (val_loss=0.001324)\n",
      "2025-03-08 11:56:23 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:56:38 [INFO] Epoch 34/200:\n",
      "2025-03-08 11:56:38 [INFO]   Training Loss: 0.000676\n",
      "2025-03-08 11:56:38 [INFO]   Training MAE: 0.023752\n",
      "2025-03-08 11:56:38 [INFO]   Validation Loss: 0.001302\n",
      "2025-03-08 11:56:38 [INFO]   Validation MAE: 0.027798\n",
      "2025-03-08 11:56:38 [INFO]   Saved new best model (val_loss=0.001302)\n",
      "2025-03-08 11:56:39 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 11:56:53 [INFO] Epoch 35/200:\n",
      "2025-03-08 11:56:53 [INFO]   Training Loss: 0.000614\n",
      "2025-03-08 11:56:53 [INFO]   Training MAE: 0.022916\n",
      "2025-03-08 11:56:53 [INFO]   Validation Loss: 0.001311\n",
      "2025-03-08 11:56:53 [INFO]   Validation MAE: 0.028477\n",
      "2025-03-08 11:57:09 [INFO] Epoch 36/200:\n",
      "2025-03-08 11:57:09 [INFO]   Training Loss: 0.000647\n",
      "2025-03-08 11:57:09 [INFO]   Training MAE: 0.023934\n",
      "2025-03-08 11:57:09 [INFO]   Validation Loss: 0.001386\n",
      "2025-03-08 11:57:09 [INFO]   Validation MAE: 0.029164\n",
      "2025-03-08 11:57:23 [INFO] Epoch 37/200:\n",
      "2025-03-08 11:57:23 [INFO]   Training Loss: 0.000653\n",
      "2025-03-08 11:57:23 [INFO]   Training MAE: 0.023883\n",
      "2025-03-08 11:57:23 [INFO]   Validation Loss: 0.001431\n",
      "2025-03-08 11:57:23 [INFO]   Validation MAE: 0.028615\n",
      "2025-03-08 11:57:38 [INFO] Epoch 38/200:\n",
      "2025-03-08 11:57:38 [INFO]   Training Loss: 0.000638\n",
      "2025-03-08 11:57:38 [INFO]   Training MAE: 0.023958\n",
      "2025-03-08 11:57:38 [INFO]   Validation Loss: 0.001452\n",
      "2025-03-08 11:57:38 [INFO]   Validation MAE: 0.029025\n",
      "2025-03-08 11:57:52 [INFO] Epoch 39/200:\n",
      "2025-03-08 11:57:52 [INFO]   Training Loss: 0.000619\n",
      "2025-03-08 11:57:52 [INFO]   Training MAE: 0.022887\n",
      "2025-03-08 11:57:52 [INFO]   Validation Loss: 0.001392\n",
      "2025-03-08 11:57:52 [INFO]   Validation MAE: 0.029367\n",
      "2025-03-08 11:58:10 [INFO] Epoch 40/200:\n",
      "2025-03-08 11:58:10 [INFO]   Training Loss: 0.000690\n",
      "2025-03-08 11:58:10 [INFO]   Training MAE: 0.024325\n",
      "2025-03-08 11:58:10 [INFO]   Validation Loss: 0.001483\n",
      "2025-03-08 11:58:10 [INFO]   Validation MAE: 0.029644\n",
      "2025-03-08 11:58:10 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_40.png\n",
      "2025-03-08 11:58:29 [INFO] Epoch 41/200:\n",
      "2025-03-08 11:58:29 [INFO]   Training Loss: 0.000772\n",
      "2025-03-08 11:58:29 [INFO]   Training MAE: 0.026228\n",
      "2025-03-08 11:58:29 [INFO]   Validation Loss: 0.001338\n",
      "2025-03-08 11:58:29 [INFO]   Validation MAE: 0.028445\n",
      "2025-03-08 11:58:48 [INFO] Epoch 42/200:\n",
      "2025-03-08 11:58:48 [INFO]   Training Loss: 0.000583\n",
      "2025-03-08 11:58:48 [INFO]   Training MAE: 0.022010\n",
      "2025-03-08 11:58:48 [INFO]   Validation Loss: 0.001373\n",
      "2025-03-08 11:58:48 [INFO]   Validation MAE: 0.028719\n",
      "2025-03-08 11:59:03 [INFO] Epoch 43/200:\n",
      "2025-03-08 11:59:03 [INFO]   Training Loss: 0.000635\n",
      "2025-03-08 11:59:03 [INFO]   Training MAE: 0.022196\n",
      "2025-03-08 11:59:03 [INFO]   Validation Loss: 0.001463\n",
      "2025-03-08 11:59:03 [INFO]   Validation MAE: 0.029482\n",
      "2025-03-08 11:59:17 [INFO] Epoch 44/200:\n",
      "2025-03-08 11:59:17 [INFO]   Training Loss: 0.000662\n",
      "2025-03-08 11:59:17 [INFO]   Training MAE: 0.023386\n",
      "2025-03-08 11:59:17 [INFO]   Validation Loss: 0.001521\n",
      "2025-03-08 11:59:17 [INFO]   Validation MAE: 0.029599\n",
      "2025-03-08 11:59:33 [INFO] Epoch 45/200:\n",
      "2025-03-08 11:59:33 [INFO]   Training Loss: 0.000744\n",
      "2025-03-08 11:59:33 [INFO]   Training MAE: 0.024195\n",
      "2025-03-08 11:59:33 [INFO]   Validation Loss: 0.001369\n",
      "2025-03-08 11:59:33 [INFO]   Validation MAE: 0.028446\n",
      "2025-03-08 11:59:46 [INFO] Epoch 46/200:\n",
      "2025-03-08 11:59:46 [INFO]   Training Loss: 0.000734\n",
      "2025-03-08 11:59:46 [INFO]   Training MAE: 0.022767\n",
      "2025-03-08 11:59:47 [INFO]   Validation Loss: 0.001420\n",
      "2025-03-08 11:59:47 [INFO]   Validation MAE: 0.028790\n",
      "2025-03-08 12:00:01 [INFO] Epoch 47/200:\n",
      "2025-03-08 12:00:01 [INFO]   Training Loss: 0.000595\n",
      "2025-03-08 12:00:01 [INFO]   Training MAE: 0.021968\n",
      "2025-03-08 12:00:01 [INFO]   Validation Loss: 0.001513\n",
      "2025-03-08 12:00:01 [INFO]   Validation MAE: 0.029744\n",
      "2025-03-08 12:00:14 [INFO] Epoch 48/200:\n",
      "2025-03-08 12:00:14 [INFO]   Training Loss: 0.000654\n",
      "2025-03-08 12:00:14 [INFO]   Training MAE: 0.023430\n",
      "2025-03-08 12:00:14 [INFO]   Validation Loss: 0.001465\n",
      "2025-03-08 12:00:14 [INFO]   Validation MAE: 0.029125\n",
      "2025-03-08 12:00:27 [INFO] Epoch 49/200:\n",
      "2025-03-08 12:00:27 [INFO]   Training Loss: 0.000627\n",
      "2025-03-08 12:00:27 [INFO]   Training MAE: 0.022609\n",
      "2025-03-08 12:00:27 [INFO]   Validation Loss: 0.001370\n",
      "2025-03-08 12:00:27 [INFO]   Validation MAE: 0.028239\n",
      "2025-03-08 12:00:46 [INFO] Epoch 50/200:\n",
      "2025-03-08 12:00:46 [INFO]   Training Loss: 0.000784\n",
      "2025-03-08 12:00:46 [INFO]   Training MAE: 0.023812\n",
      "2025-03-08 12:00:46 [INFO]   Validation Loss: 0.001347\n",
      "2025-03-08 12:00:46 [INFO]   Validation MAE: 0.028049\n",
      "2025-03-08 12:00:47 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_50.png\n",
      "2025-03-08 12:01:07 [INFO] Epoch 51/200:\n",
      "2025-03-08 12:01:07 [INFO]   Training Loss: 0.000608\n",
      "2025-03-08 12:01:07 [INFO]   Training MAE: 0.022353\n",
      "2025-03-08 12:01:07 [INFO]   Validation Loss: 0.001309\n",
      "2025-03-08 12:01:07 [INFO]   Validation MAE: 0.027451\n",
      "2025-03-08 12:01:32 [INFO] Epoch 52/200:\n",
      "2025-03-08 12:01:32 [INFO]   Training Loss: 0.000628\n",
      "2025-03-08 12:01:32 [INFO]   Training MAE: 0.023230\n",
      "2025-03-08 12:01:32 [INFO]   Validation Loss: 0.001410\n",
      "2025-03-08 12:01:32 [INFO]   Validation MAE: 0.028366\n",
      "2025-03-08 12:01:46 [INFO] Epoch 53/200:\n",
      "2025-03-08 12:01:46 [INFO]   Training Loss: 0.000618\n",
      "2025-03-08 12:01:46 [INFO]   Training MAE: 0.022822\n",
      "2025-03-08 12:01:46 [INFO]   Validation Loss: 0.001407\n",
      "2025-03-08 12:01:46 [INFO]   Validation MAE: 0.028258\n",
      "2025-03-08 12:02:01 [INFO] Epoch 54/200:\n",
      "2025-03-08 12:02:01 [INFO]   Training Loss: 0.000591\n",
      "2025-03-08 12:02:01 [INFO]   Training MAE: 0.021578\n",
      "2025-03-08 12:02:01 [INFO]   Validation Loss: 0.001401\n",
      "2025-03-08 12:02:01 [INFO]   Validation MAE: 0.028299\n",
      "2025-03-08 12:02:17 [INFO] Epoch 55/200:\n",
      "2025-03-08 12:02:17 [INFO]   Training Loss: 0.000656\n",
      "2025-03-08 12:02:17 [INFO]   Training MAE: 0.022609\n",
      "2025-03-08 12:02:17 [INFO]   Validation Loss: 0.001404\n",
      "2025-03-08 12:02:17 [INFO]   Validation MAE: 0.028175\n",
      "2025-03-08 12:02:31 [INFO] Epoch 56/200:\n",
      "2025-03-08 12:02:31 [INFO]   Training Loss: 0.000536\n",
      "2025-03-08 12:02:31 [INFO]   Training MAE: 0.021018\n",
      "2025-03-08 12:02:31 [INFO]   Validation Loss: 0.001317\n",
      "2025-03-08 12:02:31 [INFO]   Validation MAE: 0.027671\n",
      "2025-03-08 12:02:46 [INFO] Epoch 57/200:\n",
      "2025-03-08 12:02:46 [INFO]   Training Loss: 0.000616\n",
      "2025-03-08 12:02:46 [INFO]   Training MAE: 0.022742\n",
      "2025-03-08 12:02:46 [INFO]   Validation Loss: 0.001334\n",
      "2025-03-08 12:02:46 [INFO]   Validation MAE: 0.027912\n",
      "2025-03-08 12:03:02 [INFO] Epoch 58/200:\n",
      "2025-03-08 12:03:02 [INFO]   Training Loss: 0.000591\n",
      "2025-03-08 12:03:02 [INFO]   Training MAE: 0.021140\n",
      "2025-03-08 12:03:02 [INFO]   Validation Loss: 0.001325\n",
      "2025-03-08 12:03:02 [INFO]   Validation MAE: 0.027490\n",
      "2025-03-08 12:03:16 [INFO] Epoch 59/200:\n",
      "2025-03-08 12:03:16 [INFO]   Training Loss: 0.000475\n",
      "2025-03-08 12:03:16 [INFO]   Training MAE: 0.020342\n",
      "2025-03-08 12:03:16 [INFO]   Validation Loss: 0.001347\n",
      "2025-03-08 12:03:16 [INFO]   Validation MAE: 0.027749\n",
      "2025-03-08 12:03:30 [INFO] Epoch 60/200:\n",
      "2025-03-08 12:03:30 [INFO]   Training Loss: 0.000660\n",
      "2025-03-08 12:03:30 [INFO]   Training MAE: 0.023366\n",
      "2025-03-08 12:03:30 [INFO]   Validation Loss: 0.001387\n",
      "2025-03-08 12:03:30 [INFO]   Validation MAE: 0.028106\n",
      "2025-03-08 12:03:30 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_60.png\n",
      "2025-03-08 12:03:44 [INFO] Epoch 61/200:\n",
      "2025-03-08 12:03:44 [INFO]   Training Loss: 0.000646\n",
      "2025-03-08 12:03:44 [INFO]   Training MAE: 0.023023\n",
      "2025-03-08 12:03:44 [INFO]   Validation Loss: 0.001413\n",
      "2025-03-08 12:03:44 [INFO]   Validation MAE: 0.028241\n",
      "2025-03-08 12:03:57 [INFO] Epoch 62/200:\n",
      "2025-03-08 12:03:57 [INFO]   Training Loss: 0.000569\n",
      "2025-03-08 12:03:57 [INFO]   Training MAE: 0.022194\n",
      "2025-03-08 12:03:57 [INFO]   Validation Loss: 0.001331\n",
      "2025-03-08 12:03:57 [INFO]   Validation MAE: 0.027269\n",
      "2025-03-08 12:04:11 [INFO] Epoch 63/200:\n",
      "2025-03-08 12:04:11 [INFO]   Training Loss: 0.000559\n",
      "2025-03-08 12:04:11 [INFO]   Training MAE: 0.021060\n",
      "2025-03-08 12:04:11 [INFO]   Validation Loss: 0.001298\n",
      "2025-03-08 12:04:11 [INFO]   Validation MAE: 0.026771\n",
      "2025-03-08 12:04:11 [INFO]   Saved new best model (val_loss=0.001298)\n",
      "2025-03-08 12:04:11 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 12:04:25 [INFO] Epoch 64/200:\n",
      "2025-03-08 12:04:25 [INFO]   Training Loss: 0.000564\n",
      "2025-03-08 12:04:25 [INFO]   Training MAE: 0.022017\n",
      "2025-03-08 12:04:25 [INFO]   Validation Loss: 0.001302\n",
      "2025-03-08 12:04:25 [INFO]   Validation MAE: 0.027327\n",
      "2025-03-08 12:04:39 [INFO] Epoch 65/200:\n",
      "2025-03-08 12:04:39 [INFO]   Training Loss: 0.001312\n",
      "2025-03-08 12:04:39 [INFO]   Training MAE: 0.030806\n",
      "2025-03-08 12:04:39 [INFO]   Validation Loss: 0.001659\n",
      "2025-03-08 12:04:39 [INFO]   Validation MAE: 0.032499\n",
      "2025-03-08 12:04:54 [INFO] Epoch 66/200:\n",
      "2025-03-08 12:04:54 [INFO]   Training Loss: 0.000588\n",
      "2025-03-08 12:04:54 [INFO]   Training MAE: 0.022368\n",
      "2025-03-08 12:04:54 [INFO]   Validation Loss: 0.001472\n",
      "2025-03-08 12:04:54 [INFO]   Validation MAE: 0.029276\n",
      "2025-03-08 12:05:08 [INFO] Epoch 67/200:\n",
      "2025-03-08 12:05:08 [INFO]   Training Loss: 0.000641\n",
      "2025-03-08 12:05:08 [INFO]   Training MAE: 0.022783\n",
      "2025-03-08 12:05:08 [INFO]   Validation Loss: 0.001395\n",
      "2025-03-08 12:05:08 [INFO]   Validation MAE: 0.028424\n",
      "2025-03-08 12:05:22 [INFO] Epoch 68/200:\n",
      "2025-03-08 12:05:22 [INFO]   Training Loss: 0.000576\n",
      "2025-03-08 12:05:22 [INFO]   Training MAE: 0.021958\n",
      "2025-03-08 12:05:22 [INFO]   Validation Loss: 0.001327\n",
      "2025-03-08 12:05:22 [INFO]   Validation MAE: 0.027535\n",
      "2025-03-08 12:05:37 [INFO] Epoch 69/200:\n",
      "2025-03-08 12:05:37 [INFO]   Training Loss: 0.000601\n",
      "2025-03-08 12:05:37 [INFO]   Training MAE: 0.022485\n",
      "2025-03-08 12:05:37 [INFO]   Validation Loss: 0.001251\n",
      "2025-03-08 12:05:37 [INFO]   Validation MAE: 0.026914\n",
      "2025-03-08 12:05:37 [INFO]   Saved new best model (val_loss=0.001251)\n",
      "2025-03-08 12:05:37 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 12:05:51 [INFO] Epoch 70/200:\n",
      "2025-03-08 12:05:51 [INFO]   Training Loss: 0.000720\n",
      "2025-03-08 12:05:51 [INFO]   Training MAE: 0.024578\n",
      "2025-03-08 12:05:51 [INFO]   Validation Loss: 0.001227\n",
      "2025-03-08 12:05:51 [INFO]   Validation MAE: 0.026703\n",
      "2025-03-08 12:05:51 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_70.png\n",
      "2025-03-08 12:05:51 [INFO]   Saved new best model (val_loss=0.001227)\n",
      "2025-03-08 12:05:51 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 12:06:05 [INFO] Epoch 71/200:\n",
      "2025-03-08 12:06:05 [INFO]   Training Loss: 0.000619\n",
      "2025-03-08 12:06:05 [INFO]   Training MAE: 0.023028\n",
      "2025-03-08 12:06:05 [INFO]   Validation Loss: 0.001275\n",
      "2025-03-08 12:06:05 [INFO]   Validation MAE: 0.028035\n",
      "2025-03-08 12:06:20 [INFO] Epoch 72/200:\n",
      "2025-03-08 12:06:20 [INFO]   Training Loss: 0.000534\n",
      "2025-03-08 12:06:20 [INFO]   Training MAE: 0.020692\n",
      "2025-03-08 12:06:20 [INFO]   Validation Loss: 0.001280\n",
      "2025-03-08 12:06:20 [INFO]   Validation MAE: 0.027967\n",
      "2025-03-08 12:06:36 [INFO] Epoch 73/200:\n",
      "2025-03-08 12:06:36 [INFO]   Training Loss: 0.000692\n",
      "2025-03-08 12:06:36 [INFO]   Training MAE: 0.022919\n",
      "2025-03-08 12:06:36 [INFO]   Validation Loss: 0.001276\n",
      "2025-03-08 12:06:36 [INFO]   Validation MAE: 0.027474\n",
      "2025-03-08 12:06:52 [INFO] Epoch 74/200:\n",
      "2025-03-08 12:06:52 [INFO]   Training Loss: 0.000598\n",
      "2025-03-08 12:06:52 [INFO]   Training MAE: 0.023098\n",
      "2025-03-08 12:06:52 [INFO]   Validation Loss: 0.001413\n",
      "2025-03-08 12:06:52 [INFO]   Validation MAE: 0.029296\n",
      "2025-03-08 12:07:09 [INFO] Epoch 75/200:\n",
      "2025-03-08 12:07:09 [INFO]   Training Loss: 0.000748\n",
      "2025-03-08 12:07:09 [INFO]   Training MAE: 0.024193\n",
      "2025-03-08 12:07:09 [INFO]   Validation Loss: 0.001405\n",
      "2025-03-08 12:07:09 [INFO]   Validation MAE: 0.029912\n",
      "2025-03-08 12:07:26 [INFO] Epoch 76/200:\n",
      "2025-03-08 12:07:26 [INFO]   Training Loss: 0.000673\n",
      "2025-03-08 12:07:26 [INFO]   Training MAE: 0.024181\n",
      "2025-03-08 12:07:26 [INFO]   Validation Loss: 0.001325\n",
      "2025-03-08 12:07:26 [INFO]   Validation MAE: 0.029010\n",
      "2025-03-08 12:07:43 [INFO] Epoch 77/200:\n",
      "2025-03-08 12:07:43 [INFO]   Training Loss: 0.000711\n",
      "2025-03-08 12:07:43 [INFO]   Training MAE: 0.024770\n",
      "2025-03-08 12:07:43 [INFO]   Validation Loss: 0.001399\n",
      "2025-03-08 12:07:43 [INFO]   Validation MAE: 0.029296\n",
      "2025-03-08 12:08:01 [INFO] Epoch 78/200:\n",
      "2025-03-08 12:08:01 [INFO]   Training Loss: 0.000540\n",
      "2025-03-08 12:08:01 [INFO]   Training MAE: 0.021545\n",
      "2025-03-08 12:08:01 [INFO]   Validation Loss: 0.001485\n",
      "2025-03-08 12:08:01 [INFO]   Validation MAE: 0.030292\n",
      "2025-03-08 12:08:20 [INFO] Epoch 79/200:\n",
      "2025-03-08 12:08:20 [INFO]   Training Loss: 0.000573\n",
      "2025-03-08 12:08:20 [INFO]   Training MAE: 0.021906\n",
      "2025-03-08 12:08:20 [INFO]   Validation Loss: 0.001365\n",
      "2025-03-08 12:08:20 [INFO]   Validation MAE: 0.028721\n",
      "2025-03-08 12:08:38 [INFO] Epoch 80/200:\n",
      "2025-03-08 12:08:38 [INFO]   Training Loss: 0.000581\n",
      "2025-03-08 12:08:38 [INFO]   Training MAE: 0.023228\n",
      "2025-03-08 12:08:38 [INFO]   Validation Loss: 0.001301\n",
      "2025-03-08 12:08:38 [INFO]   Validation MAE: 0.028983\n",
      "2025-03-08 12:08:38 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_80.png\n",
      "2025-03-08 12:08:56 [INFO] Epoch 81/200:\n",
      "2025-03-08 12:08:56 [INFO]   Training Loss: 0.000637\n",
      "2025-03-08 12:08:56 [INFO]   Training MAE: 0.024250\n",
      "2025-03-08 12:08:56 [INFO]   Validation Loss: 0.001347\n",
      "2025-03-08 12:08:56 [INFO]   Validation MAE: 0.028299\n",
      "2025-03-08 12:09:13 [INFO] Epoch 82/200:\n",
      "2025-03-08 12:09:13 [INFO]   Training Loss: 0.000471\n",
      "2025-03-08 12:09:13 [INFO]   Training MAE: 0.020394\n",
      "2025-03-08 12:09:13 [INFO]   Validation Loss: 0.001294\n",
      "2025-03-08 12:09:13 [INFO]   Validation MAE: 0.027828\n",
      "2025-03-08 12:09:30 [INFO] Epoch 83/200:\n",
      "2025-03-08 12:09:30 [INFO]   Training Loss: 0.000552\n",
      "2025-03-08 12:09:30 [INFO]   Training MAE: 0.021551\n",
      "2025-03-08 12:09:30 [INFO]   Validation Loss: 0.001299\n",
      "2025-03-08 12:09:30 [INFO]   Validation MAE: 0.027683\n",
      "2025-03-08 12:09:46 [INFO] Epoch 84/200:\n",
      "2025-03-08 12:09:46 [INFO]   Training Loss: 0.000561\n",
      "2025-03-08 12:09:46 [INFO]   Training MAE: 0.020861\n",
      "2025-03-08 12:09:46 [INFO]   Validation Loss: 0.001246\n",
      "2025-03-08 12:09:46 [INFO]   Validation MAE: 0.027074\n",
      "2025-03-08 12:10:03 [INFO] Epoch 85/200:\n",
      "2025-03-08 12:10:03 [INFO]   Training Loss: 0.000592\n",
      "2025-03-08 12:10:03 [INFO]   Training MAE: 0.022673\n",
      "2025-03-08 12:10:03 [INFO]   Validation Loss: 0.001184\n",
      "2025-03-08 12:10:03 [INFO]   Validation MAE: 0.026612\n",
      "2025-03-08 12:10:03 [INFO]   Saved new best model (val_loss=0.001184)\n",
      "2025-03-08 12:10:03 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 12:10:19 [INFO] Epoch 86/200:\n",
      "2025-03-08 12:10:19 [INFO]   Training Loss: 0.000699\n",
      "2025-03-08 12:10:19 [INFO]   Training MAE: 0.023473\n",
      "2025-03-08 12:10:19 [INFO]   Validation Loss: 0.001184\n",
      "2025-03-08 12:10:19 [INFO]   Validation MAE: 0.026571\n",
      "2025-03-08 12:10:35 [INFO] Epoch 87/200:\n",
      "2025-03-08 12:10:35 [INFO]   Training Loss: 0.000660\n",
      "2025-03-08 12:10:35 [INFO]   Training MAE: 0.023863\n",
      "2025-03-08 12:10:35 [INFO]   Validation Loss: 0.001531\n",
      "2025-03-08 12:10:35 [INFO]   Validation MAE: 0.030237\n",
      "2025-03-08 12:10:52 [INFO] Epoch 88/200:\n",
      "2025-03-08 12:10:52 [INFO]   Training Loss: 0.000755\n",
      "2025-03-08 12:10:52 [INFO]   Training MAE: 0.024834\n",
      "2025-03-08 12:10:52 [INFO]   Validation Loss: 0.001243\n",
      "2025-03-08 12:10:52 [INFO]   Validation MAE: 0.027323\n",
      "2025-03-08 12:11:10 [INFO] Epoch 89/200:\n",
      "2025-03-08 12:11:10 [INFO]   Training Loss: 0.000770\n",
      "2025-03-08 12:11:10 [INFO]   Training MAE: 0.026363\n",
      "2025-03-08 12:11:10 [INFO]   Validation Loss: 0.001294\n",
      "2025-03-08 12:11:10 [INFO]   Validation MAE: 0.027384\n",
      "2025-03-08 12:11:28 [INFO] Epoch 90/200:\n",
      "2025-03-08 12:11:28 [INFO]   Training Loss: 0.000594\n",
      "2025-03-08 12:11:28 [INFO]   Training MAE: 0.022195\n",
      "2025-03-08 12:11:28 [INFO]   Validation Loss: 0.001177\n",
      "2025-03-08 12:11:28 [INFO]   Validation MAE: 0.026106\n",
      "2025-03-08 12:11:28 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_90.png\n",
      "2025-03-08 12:11:28 [INFO]   Saved new best model (val_loss=0.001177)\n",
      "2025-03-08 12:11:29 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 12:11:47 [INFO] Epoch 91/200:\n",
      "2025-03-08 12:11:47 [INFO]   Training Loss: 0.000701\n",
      "2025-03-08 12:11:47 [INFO]   Training MAE: 0.023039\n",
      "2025-03-08 12:11:47 [INFO]   Validation Loss: 0.001199\n",
      "2025-03-08 12:11:47 [INFO]   Validation MAE: 0.026986\n",
      "2025-03-08 12:12:05 [INFO] Epoch 92/200:\n",
      "2025-03-08 12:12:05 [INFO]   Training Loss: 0.000482\n",
      "2025-03-08 12:12:05 [INFO]   Training MAE: 0.020119\n",
      "2025-03-08 12:12:05 [INFO]   Validation Loss: 0.001253\n",
      "2025-03-08 12:12:05 [INFO]   Validation MAE: 0.027545\n",
      "2025-03-08 12:12:23 [INFO] Epoch 93/200:\n",
      "2025-03-08 12:12:23 [INFO]   Training Loss: 0.000554\n",
      "2025-03-08 12:12:23 [INFO]   Training MAE: 0.022017\n",
      "2025-03-08 12:12:23 [INFO]   Validation Loss: 0.001189\n",
      "2025-03-08 12:12:23 [INFO]   Validation MAE: 0.026902\n",
      "2025-03-08 12:12:40 [INFO] Epoch 94/200:\n",
      "2025-03-08 12:12:40 [INFO]   Training Loss: 0.000532\n",
      "2025-03-08 12:12:40 [INFO]   Training MAE: 0.021398\n",
      "2025-03-08 12:12:40 [INFO]   Validation Loss: 0.001285\n",
      "2025-03-08 12:12:40 [INFO]   Validation MAE: 0.028110\n",
      "2025-03-08 12:12:57 [INFO] Epoch 95/200:\n",
      "2025-03-08 12:12:57 [INFO]   Training Loss: 0.000499\n",
      "2025-03-08 12:12:57 [INFO]   Training MAE: 0.021157\n",
      "2025-03-08 12:12:57 [INFO]   Validation Loss: 0.001266\n",
      "2025-03-08 12:12:57 [INFO]   Validation MAE: 0.027225\n",
      "2025-03-08 12:13:13 [INFO] Epoch 96/200:\n",
      "2025-03-08 12:13:13 [INFO]   Training Loss: 0.000602\n",
      "2025-03-08 12:13:13 [INFO]   Training MAE: 0.022846\n",
      "2025-03-08 12:13:13 [INFO]   Validation Loss: 0.001177\n",
      "2025-03-08 12:13:13 [INFO]   Validation MAE: 0.026139\n",
      "2025-03-08 12:13:13 [INFO]   Saved new best model (val_loss=0.001177)\n",
      "2025-03-08 12:13:13 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 12:13:29 [INFO] Epoch 97/200:\n",
      "2025-03-08 12:13:29 [INFO]   Training Loss: 0.000646\n",
      "2025-03-08 12:13:29 [INFO]   Training MAE: 0.023356\n",
      "2025-03-08 12:13:29 [INFO]   Validation Loss: 0.001260\n",
      "2025-03-08 12:13:29 [INFO]   Validation MAE: 0.027666\n",
      "2025-03-08 12:13:45 [INFO] Epoch 98/200:\n",
      "2025-03-08 12:13:45 [INFO]   Training Loss: 0.000519\n",
      "2025-03-08 12:13:45 [INFO]   Training MAE: 0.021814\n",
      "2025-03-08 12:13:45 [INFO]   Validation Loss: 0.001239\n",
      "2025-03-08 12:13:45 [INFO]   Validation MAE: 0.028214\n",
      "2025-03-08 12:14:01 [INFO] Epoch 99/200:\n",
      "2025-03-08 12:14:01 [INFO]   Training Loss: 0.000418\n",
      "2025-03-08 12:14:01 [INFO]   Training MAE: 0.019956\n",
      "2025-03-08 12:14:01 [INFO]   Validation Loss: 0.001240\n",
      "2025-03-08 12:14:01 [INFO]   Validation MAE: 0.027318\n",
      "2025-03-08 12:14:18 [INFO] Epoch 100/200:\n",
      "2025-03-08 12:14:18 [INFO]   Training Loss: 0.000535\n",
      "2025-03-08 12:14:18 [INFO]   Training MAE: 0.021678\n",
      "2025-03-08 12:14:18 [INFO]   Validation Loss: 0.001227\n",
      "2025-03-08 12:14:18 [INFO]   Validation MAE: 0.026912\n",
      "2025-03-08 12:14:18 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_100.png\n",
      "2025-03-08 12:14:36 [INFO] Epoch 101/200:\n",
      "2025-03-08 12:14:36 [INFO]   Training Loss: 0.000527\n",
      "2025-03-08 12:14:36 [INFO]   Training MAE: 0.021086\n",
      "2025-03-08 12:14:36 [INFO]   Validation Loss: 0.001183\n",
      "2025-03-08 12:14:36 [INFO]   Validation MAE: 0.026718\n",
      "2025-03-08 12:14:54 [INFO] Epoch 102/200:\n",
      "2025-03-08 12:14:54 [INFO]   Training Loss: 0.000452\n",
      "2025-03-08 12:14:54 [INFO]   Training MAE: 0.019920\n",
      "2025-03-08 12:14:54 [INFO]   Validation Loss: 0.001139\n",
      "2025-03-08 12:14:54 [INFO]   Validation MAE: 0.025862\n",
      "2025-03-08 12:14:54 [INFO]   Saved new best model (val_loss=0.001139)\n",
      "2025-03-08 12:14:54 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_best_model.png\n",
      "2025-03-08 12:15:12 [INFO] Epoch 103/200:\n",
      "2025-03-08 12:15:12 [INFO]   Training Loss: 0.000549\n",
      "2025-03-08 12:15:12 [INFO]   Training MAE: 0.021156\n",
      "2025-03-08 12:15:12 [INFO]   Validation Loss: 0.001192\n",
      "2025-03-08 12:15:12 [INFO]   Validation MAE: 0.026176\n",
      "2025-03-08 12:15:29 [INFO] Epoch 104/200:\n",
      "2025-03-08 12:15:29 [INFO]   Training Loss: 0.000562\n",
      "2025-03-08 12:15:29 [INFO]   Training MAE: 0.021242\n",
      "2025-03-08 12:15:29 [INFO]   Validation Loss: 0.001166\n",
      "2025-03-08 12:15:29 [INFO]   Validation MAE: 0.026148\n",
      "2025-03-08 12:15:46 [INFO] Epoch 105/200:\n",
      "2025-03-08 12:15:46 [INFO]   Training Loss: 0.000539\n",
      "2025-03-08 12:15:46 [INFO]   Training MAE: 0.020898\n",
      "2025-03-08 12:15:46 [INFO]   Validation Loss: 0.001262\n",
      "2025-03-08 12:15:46 [INFO]   Validation MAE: 0.027246\n",
      "2025-03-08 12:16:04 [INFO] Epoch 106/200:\n",
      "2025-03-08 12:16:04 [INFO]   Training Loss: 0.000491\n",
      "2025-03-08 12:16:04 [INFO]   Training MAE: 0.019625\n",
      "2025-03-08 12:16:04 [INFO]   Validation Loss: 0.001224\n",
      "2025-03-08 12:16:04 [INFO]   Validation MAE: 0.027139\n",
      "2025-03-08 12:16:20 [INFO] Epoch 107/200:\n",
      "2025-03-08 12:16:20 [INFO]   Training Loss: 0.000479\n",
      "2025-03-08 12:16:20 [INFO]   Training MAE: 0.020090\n",
      "2025-03-08 12:16:20 [INFO]   Validation Loss: 0.001229\n",
      "2025-03-08 12:16:20 [INFO]   Validation MAE: 0.026711\n",
      "2025-03-08 12:16:36 [INFO] Epoch 108/200:\n",
      "2025-03-08 12:16:36 [INFO]   Training Loss: 0.000487\n",
      "2025-03-08 12:16:36 [INFO]   Training MAE: 0.019996\n",
      "2025-03-08 12:16:36 [INFO]   Validation Loss: 0.001235\n",
      "2025-03-08 12:16:36 [INFO]   Validation MAE: 0.026899\n",
      "2025-03-08 12:16:52 [INFO] Epoch 109/200:\n",
      "2025-03-08 12:16:52 [INFO]   Training Loss: 0.000426\n",
      "2025-03-08 12:16:52 [INFO]   Training MAE: 0.019162\n",
      "2025-03-08 12:16:52 [INFO]   Validation Loss: 0.001217\n",
      "2025-03-08 12:16:52 [INFO]   Validation MAE: 0.026631\n",
      "2025-03-08 12:17:09 [INFO] Epoch 110/200:\n",
      "2025-03-08 12:17:09 [INFO]   Training Loss: 0.000465\n",
      "2025-03-08 12:17:09 [INFO]   Training MAE: 0.020867\n",
      "2025-03-08 12:17:09 [INFO]   Validation Loss: 0.001260\n",
      "2025-03-08 12:17:09 [INFO]   Validation MAE: 0.026566\n",
      "2025-03-08 12:17:10 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_110.png\n",
      "2025-03-08 12:17:27 [INFO] Epoch 111/200:\n",
      "2025-03-08 12:17:27 [INFO]   Training Loss: 0.000541\n",
      "2025-03-08 12:17:27 [INFO]   Training MAE: 0.020336\n",
      "2025-03-08 12:17:27 [INFO]   Validation Loss: 0.001250\n",
      "2025-03-08 12:17:27 [INFO]   Validation MAE: 0.026744\n",
      "2025-03-08 12:17:46 [INFO] Epoch 112/200:\n",
      "2025-03-08 12:17:46 [INFO]   Training Loss: 0.000466\n",
      "2025-03-08 12:17:46 [INFO]   Training MAE: 0.019764\n",
      "2025-03-08 12:17:46 [INFO]   Validation Loss: 0.001191\n",
      "2025-03-08 12:17:46 [INFO]   Validation MAE: 0.026418\n",
      "2025-03-08 12:18:04 [INFO] Epoch 113/200:\n",
      "2025-03-08 12:18:04 [INFO]   Training Loss: 0.000487\n",
      "2025-03-08 12:18:04 [INFO]   Training MAE: 0.018890\n",
      "2025-03-08 12:18:04 [INFO]   Validation Loss: 0.001241\n",
      "2025-03-08 12:18:04 [INFO]   Validation MAE: 0.026433\n",
      "2025-03-08 12:18:21 [INFO] Epoch 114/200:\n",
      "2025-03-08 12:18:21 [INFO]   Training Loss: 0.000549\n",
      "2025-03-08 12:18:21 [INFO]   Training MAE: 0.020808\n",
      "2025-03-08 12:18:21 [INFO]   Validation Loss: 0.001165\n",
      "2025-03-08 12:18:21 [INFO]   Validation MAE: 0.026098\n",
      "2025-03-08 12:18:39 [INFO] Epoch 115/200:\n",
      "2025-03-08 12:18:39 [INFO]   Training Loss: 0.000543\n",
      "2025-03-08 12:18:39 [INFO]   Training MAE: 0.021233\n",
      "2025-03-08 12:18:39 [INFO]   Validation Loss: 0.001158\n",
      "2025-03-08 12:18:39 [INFO]   Validation MAE: 0.025688\n",
      "2025-03-08 12:18:56 [INFO] Epoch 116/200:\n",
      "2025-03-08 12:18:56 [INFO]   Training Loss: 0.000495\n",
      "2025-03-08 12:18:56 [INFO]   Training MAE: 0.020951\n",
      "2025-03-08 12:18:56 [INFO]   Validation Loss: 0.001272\n",
      "2025-03-08 12:18:56 [INFO]   Validation MAE: 0.026373\n",
      "2025-03-08 12:19:13 [INFO] Epoch 117/200:\n",
      "2025-03-08 12:19:13 [INFO]   Training Loss: 0.001116\n",
      "2025-03-08 12:19:13 [INFO]   Training MAE: 0.026172\n",
      "2025-03-08 12:19:13 [INFO]   Validation Loss: 0.001543\n",
      "2025-03-08 12:19:13 [INFO]   Validation MAE: 0.031600\n",
      "2025-03-08 12:19:29 [INFO] Epoch 118/200:\n",
      "2025-03-08 12:19:29 [INFO]   Training Loss: 0.000458\n",
      "2025-03-08 12:19:29 [INFO]   Training MAE: 0.020031\n",
      "2025-03-08 12:19:29 [INFO]   Validation Loss: 0.001260\n",
      "2025-03-08 12:19:29 [INFO]   Validation MAE: 0.026546\n",
      "2025-03-08 12:19:44 [INFO] Epoch 119/200:\n",
      "2025-03-08 12:19:44 [INFO]   Training Loss: 0.000476\n",
      "2025-03-08 12:19:44 [INFO]   Training MAE: 0.019956\n",
      "2025-03-08 12:19:44 [INFO]   Validation Loss: 0.001251\n",
      "2025-03-08 12:19:44 [INFO]   Validation MAE: 0.026732\n",
      "2025-03-08 12:20:02 [INFO] Epoch 120/200:\n",
      "2025-03-08 12:20:02 [INFO]   Training Loss: 0.000431\n",
      "2025-03-08 12:20:02 [INFO]   Training MAE: 0.019733\n",
      "2025-03-08 12:20:02 [INFO]   Validation Loss: 0.001260\n",
      "2025-03-08 12:20:02 [INFO]   Validation MAE: 0.026729\n",
      "2025-03-08 12:20:02 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_120.png\n",
      "2025-03-08 12:20:20 [INFO] Epoch 121/200:\n",
      "2025-03-08 12:20:20 [INFO]   Training Loss: 0.000567\n",
      "2025-03-08 12:20:20 [INFO]   Training MAE: 0.020572\n",
      "2025-03-08 12:20:20 [INFO]   Validation Loss: 0.001297\n",
      "2025-03-08 12:20:20 [INFO]   Validation MAE: 0.027297\n",
      "2025-03-08 12:20:37 [INFO] Epoch 122/200:\n",
      "2025-03-08 12:20:37 [INFO]   Training Loss: 0.000499\n",
      "2025-03-08 12:20:37 [INFO]   Training MAE: 0.020221\n",
      "2025-03-08 12:20:37 [INFO]   Validation Loss: 0.001229\n",
      "2025-03-08 12:20:37 [INFO]   Validation MAE: 0.026253\n",
      "2025-03-08 12:20:55 [INFO] Epoch 123/200:\n",
      "2025-03-08 12:20:55 [INFO]   Training Loss: 0.000476\n",
      "2025-03-08 12:20:55 [INFO]   Training MAE: 0.019600\n",
      "2025-03-08 12:20:55 [INFO]   Validation Loss: 0.001212\n",
      "2025-03-08 12:20:55 [INFO]   Validation MAE: 0.025859\n",
      "2025-03-08 12:21:14 [INFO] Epoch 124/200:\n",
      "2025-03-08 12:21:14 [INFO]   Training Loss: 0.000460\n",
      "2025-03-08 12:21:14 [INFO]   Training MAE: 0.019281\n",
      "2025-03-08 12:21:14 [INFO]   Validation Loss: 0.001207\n",
      "2025-03-08 12:21:14 [INFO]   Validation MAE: 0.025685\n",
      "2025-03-08 12:21:32 [INFO] Epoch 125/200:\n",
      "2025-03-08 12:21:32 [INFO]   Training Loss: 0.000556\n",
      "2025-03-08 12:21:32 [INFO]   Training MAE: 0.022060\n",
      "2025-03-08 12:21:32 [INFO]   Validation Loss: 0.001193\n",
      "2025-03-08 12:21:32 [INFO]   Validation MAE: 0.025645\n",
      "2025-03-08 12:21:48 [INFO] Epoch 126/200:\n",
      "2025-03-08 12:21:48 [INFO]   Training Loss: 0.000621\n",
      "2025-03-08 12:21:48 [INFO]   Training MAE: 0.022077\n",
      "2025-03-08 12:21:48 [INFO]   Validation Loss: 0.001279\n",
      "2025-03-08 12:21:48 [INFO]   Validation MAE: 0.026322\n",
      "2025-03-08 12:22:07 [INFO] Epoch 127/200:\n",
      "2025-03-08 12:22:07 [INFO]   Training Loss: 0.000464\n",
      "2025-03-08 12:22:07 [INFO]   Training MAE: 0.019305\n",
      "2025-03-08 12:22:07 [INFO]   Validation Loss: 0.001269\n",
      "2025-03-08 12:22:07 [INFO]   Validation MAE: 0.026451\n",
      "2025-03-08 12:22:22 [INFO] Epoch 128/200:\n",
      "2025-03-08 12:22:22 [INFO]   Training Loss: 0.000548\n",
      "2025-03-08 12:22:22 [INFO]   Training MAE: 0.021253\n",
      "2025-03-08 12:22:22 [INFO]   Validation Loss: 0.001260\n",
      "2025-03-08 12:22:22 [INFO]   Validation MAE: 0.026212\n",
      "2025-03-08 12:22:37 [INFO] Epoch 129/200:\n",
      "2025-03-08 12:22:37 [INFO]   Training Loss: 0.000522\n",
      "2025-03-08 12:22:37 [INFO]   Training MAE: 0.020773\n",
      "2025-03-08 12:22:37 [INFO]   Validation Loss: 0.001237\n",
      "2025-03-08 12:22:37 [INFO]   Validation MAE: 0.026218\n",
      "2025-03-08 12:22:52 [INFO] Epoch 130/200:\n",
      "2025-03-08 12:22:52 [INFO]   Training Loss: 0.000444\n",
      "2025-03-08 12:22:52 [INFO]   Training MAE: 0.019276\n",
      "2025-03-08 12:22:52 [INFO]   Validation Loss: 0.001276\n",
      "2025-03-08 12:22:52 [INFO]   Validation MAE: 0.026475\n",
      "2025-03-08 12:22:53 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_130.png\n",
      "2025-03-08 12:23:08 [INFO] Epoch 131/200:\n",
      "2025-03-08 12:23:08 [INFO]   Training Loss: 0.000519\n",
      "2025-03-08 12:23:08 [INFO]   Training MAE: 0.021260\n",
      "2025-03-08 12:23:08 [INFO]   Validation Loss: 0.001237\n",
      "2025-03-08 12:23:08 [INFO]   Validation MAE: 0.025958\n",
      "2025-03-08 12:23:23 [INFO] Epoch 132/200:\n",
      "2025-03-08 12:23:23 [INFO]   Training Loss: 0.000432\n",
      "2025-03-08 12:23:23 [INFO]   Training MAE: 0.019650\n",
      "2025-03-08 12:23:23 [INFO]   Validation Loss: 0.001212\n",
      "2025-03-08 12:23:23 [INFO]   Validation MAE: 0.025711\n",
      "2025-03-08 12:23:38 [INFO] Epoch 133/200:\n",
      "2025-03-08 12:23:38 [INFO]   Training Loss: 0.000468\n",
      "2025-03-08 12:23:38 [INFO]   Training MAE: 0.020279\n",
      "2025-03-08 12:23:38 [INFO]   Validation Loss: 0.001308\n",
      "2025-03-08 12:23:38 [INFO]   Validation MAE: 0.026649\n",
      "2025-03-08 12:23:54 [INFO] Epoch 134/200:\n",
      "2025-03-08 12:23:54 [INFO]   Training Loss: 0.000535\n",
      "2025-03-08 12:23:54 [INFO]   Training MAE: 0.019945\n",
      "2025-03-08 12:23:54 [INFO]   Validation Loss: 0.001302\n",
      "2025-03-08 12:23:54 [INFO]   Validation MAE: 0.026745\n",
      "2025-03-08 12:24:11 [INFO] Epoch 135/200:\n",
      "2025-03-08 12:24:11 [INFO]   Training Loss: 0.000563\n",
      "2025-03-08 12:24:11 [INFO]   Training MAE: 0.021523\n",
      "2025-03-08 12:24:11 [INFO]   Validation Loss: 0.001275\n",
      "2025-03-08 12:24:11 [INFO]   Validation MAE: 0.026486\n",
      "2025-03-08 12:24:29 [INFO] Epoch 136/200:\n",
      "2025-03-08 12:24:29 [INFO]   Training Loss: 0.000466\n",
      "2025-03-08 12:24:29 [INFO]   Training MAE: 0.019559\n",
      "2025-03-08 12:24:29 [INFO]   Validation Loss: 0.001344\n",
      "2025-03-08 12:24:29 [INFO]   Validation MAE: 0.027162\n",
      "2025-03-08 12:24:48 [INFO] Epoch 137/200:\n",
      "2025-03-08 12:24:48 [INFO]   Training Loss: 0.000464\n",
      "2025-03-08 12:24:48 [INFO]   Training MAE: 0.020111\n",
      "2025-03-08 12:24:48 [INFO]   Validation Loss: 0.001384\n",
      "2025-03-08 12:24:48 [INFO]   Validation MAE: 0.027720\n",
      "2025-03-08 12:25:07 [INFO] Epoch 138/200:\n",
      "2025-03-08 12:25:07 [INFO]   Training Loss: 0.000511\n",
      "2025-03-08 12:25:07 [INFO]   Training MAE: 0.020929\n",
      "2025-03-08 12:25:07 [INFO]   Validation Loss: 0.001379\n",
      "2025-03-08 12:25:07 [INFO]   Validation MAE: 0.027608\n",
      "2025-03-08 12:25:25 [INFO] Epoch 139/200:\n",
      "2025-03-08 12:25:25 [INFO]   Training Loss: 0.000470\n",
      "2025-03-08 12:25:25 [INFO]   Training MAE: 0.019257\n",
      "2025-03-08 12:25:25 [INFO]   Validation Loss: 0.001355\n",
      "2025-03-08 12:25:25 [INFO]   Validation MAE: 0.027315\n",
      "2025-03-08 12:25:43 [INFO] Epoch 140/200:\n",
      "2025-03-08 12:25:43 [INFO]   Training Loss: 0.000552\n",
      "2025-03-08 12:25:43 [INFO]   Training MAE: 0.020521\n",
      "2025-03-08 12:25:43 [INFO]   Validation Loss: 0.001249\n",
      "2025-03-08 12:25:43 [INFO]   Validation MAE: 0.026290\n",
      "2025-03-08 12:25:43 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_140.png\n",
      "2025-03-08 12:26:01 [INFO] Epoch 141/200:\n",
      "2025-03-08 12:26:01 [INFO]   Training Loss: 0.000532\n",
      "2025-03-08 12:26:01 [INFO]   Training MAE: 0.020898\n",
      "2025-03-08 12:26:01 [INFO]   Validation Loss: 0.001425\n",
      "2025-03-08 12:26:01 [INFO]   Validation MAE: 0.027899\n",
      "2025-03-08 12:26:18 [INFO] Epoch 142/200:\n",
      "2025-03-08 12:26:18 [INFO]   Training Loss: 0.000607\n",
      "2025-03-08 12:26:18 [INFO]   Training MAE: 0.021791\n",
      "2025-03-08 12:26:18 [INFO]   Validation Loss: 0.001249\n",
      "2025-03-08 12:26:18 [INFO]   Validation MAE: 0.027333\n",
      "2025-03-08 12:26:34 [INFO] Epoch 143/200:\n",
      "2025-03-08 12:26:34 [INFO]   Training Loss: 0.000489\n",
      "2025-03-08 12:26:34 [INFO]   Training MAE: 0.020300\n",
      "2025-03-08 12:26:34 [INFO]   Validation Loss: 0.001200\n",
      "2025-03-08 12:26:34 [INFO]   Validation MAE: 0.026831\n",
      "2025-03-08 12:26:50 [INFO] Epoch 144/200:\n",
      "2025-03-08 12:26:50 [INFO]   Training Loss: 0.000573\n",
      "2025-03-08 12:26:50 [INFO]   Training MAE: 0.022484\n",
      "2025-03-08 12:26:50 [INFO]   Validation Loss: 0.001304\n",
      "2025-03-08 12:26:50 [INFO]   Validation MAE: 0.027406\n",
      "2025-03-08 12:27:06 [INFO] Epoch 145/200:\n",
      "2025-03-08 12:27:06 [INFO]   Training Loss: 0.000566\n",
      "2025-03-08 12:27:06 [INFO]   Training MAE: 0.022627\n",
      "2025-03-08 12:27:06 [INFO]   Validation Loss: 0.001257\n",
      "2025-03-08 12:27:06 [INFO]   Validation MAE: 0.026917\n",
      "2025-03-08 12:27:22 [INFO] Epoch 146/200:\n",
      "2025-03-08 12:27:22 [INFO]   Training Loss: 0.000500\n",
      "2025-03-08 12:27:22 [INFO]   Training MAE: 0.020314\n",
      "2025-03-08 12:27:22 [INFO]   Validation Loss: 0.001229\n",
      "2025-03-08 12:27:22 [INFO]   Validation MAE: 0.026297\n",
      "2025-03-08 12:27:37 [INFO] Epoch 147/200:\n",
      "2025-03-08 12:27:37 [INFO]   Training Loss: 0.000524\n",
      "2025-03-08 12:27:37 [INFO]   Training MAE: 0.020526\n",
      "2025-03-08 12:27:37 [INFO]   Validation Loss: 0.001424\n",
      "2025-03-08 12:27:37 [INFO]   Validation MAE: 0.027903\n",
      "2025-03-08 12:27:53 [INFO] Epoch 148/200:\n",
      "2025-03-08 12:27:53 [INFO]   Training Loss: 0.000524\n",
      "2025-03-08 12:27:53 [INFO]   Training MAE: 0.020932\n",
      "2025-03-08 12:27:53 [INFO]   Validation Loss: 0.001376\n",
      "2025-03-08 12:27:53 [INFO]   Validation MAE: 0.027987\n",
      "2025-03-08 12:28:10 [INFO] Epoch 149/200:\n",
      "2025-03-08 12:28:10 [INFO]   Training Loss: 0.000463\n",
      "2025-03-08 12:28:10 [INFO]   Training MAE: 0.019423\n",
      "2025-03-08 12:28:10 [INFO]   Validation Loss: 0.001444\n",
      "2025-03-08 12:28:10 [INFO]   Validation MAE: 0.028527\n",
      "2025-03-08 12:28:28 [INFO] Epoch 150/200:\n",
      "2025-03-08 12:28:28 [INFO]   Training Loss: 0.000520\n",
      "2025-03-08 12:28:28 [INFO]   Training MAE: 0.020527\n",
      "2025-03-08 12:28:28 [INFO]   Validation Loss: 0.001249\n",
      "2025-03-08 12:28:28 [INFO]   Validation MAE: 0.026688\n",
      "2025-03-08 12:28:28 [INFO] Validation plot saved to ./validation_plots9-10_from7-8\\val_plot_epoch_150.png\n",
      "2025-03-08 12:28:47 [INFO] Epoch 151/200:\n",
      "2025-03-08 12:28:47 [INFO]   Training Loss: 0.000588\n",
      "2025-03-08 12:28:47 [INFO]   Training MAE: 0.022902\n",
      "2025-03-08 12:28:47 [INFO]   Validation Loss: 0.001338\n",
      "2025-03-08 12:28:47 [INFO]   Validation MAE: 0.026650\n",
      "2025-03-08 12:29:05 [INFO] Epoch 152/200:\n",
      "2025-03-08 12:29:05 [INFO]   Training Loss: 0.000485\n",
      "2025-03-08 12:29:05 [INFO]   Training MAE: 0.019603\n",
      "2025-03-08 12:29:05 [INFO]   Validation Loss: 0.001344\n",
      "2025-03-08 12:29:05 [INFO]   Validation MAE: 0.026611\n",
      "2025-03-08 12:29:05 [INFO] Early stopping triggered\n",
      "2025-03-08 12:29:05 [INFO] Fine-tuning completed\n",
      "2025-03-08 12:29:05 [INFO] Initial validation loss: 0.006081\n",
      "2025-03-08 12:29:05 [INFO] Initial validation MAE: 0.066555\n",
      "2025-03-08 12:29:05 [INFO] Best validation loss: 0.001139\n",
      "2025-03-08 12:29:05 [INFO] Improvement: 81.26%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Import your existing model and dataset classes\n",
    "from Train2_12 import ExperimentalGNN, SpinSystemDataset, PhysicalScaleAwareLoss\n",
    "\n",
    "# Fine-tuning configuration\n",
    "FINETUNE_CONFIG = {\n",
    "    'pretrained_model_path': 'best_model_rung1_6_pre.pth',\n",
    "    'data_dirs': [\n",
    "        './processed_experimentalrung7-8_10k_r6',\n",
    "        './processed_experimentalrung7-8_10k_r6_2'\n",
    "    ],  # List of directories containing .pt files\n",
    "    'processed_file_pattern': 'data*.pt',  # Pattern to match multiple files\n",
    "    'alternative_file_paths': [\n",
    "        # Add direct paths to specific .pt files if needed\n",
    "        # './processed_data/data_v1.pt',\n",
    "        # './processed_data/data_v2.pt'\n",
    "    ],\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.5e-4,\n",
    "    'weight_decay': 1.5e-4,\n",
    "    'num_epochs': 200,\n",
    "    'patience': 50,\n",
    "    'finetuned_model_path': 'finetuned_model.pth',\n",
    "    'dropout_p': 0.3,\n",
    "    'grad_clip': 0.5,\n",
    "    'random_seed': 42,\n",
    "    'verbose_logging': True  # Set to True for detailed debug information\n",
    "}\n",
    "\n",
    "def setup_logging():\n",
    "    level = logging.DEBUG if FINETUNE_CONFIG.get('verbose_logging', False) else logging.INFO\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "    # Create file handler\n",
    "    file_handler = logging.FileHandler('finetuning.log')\n",
    "    file_handler.setLevel(level)\n",
    "    file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))\n",
    "    \n",
    "    # Add file handler to root logger\n",
    "    logging.getLogger('').addHandler(file_handler)\n",
    "    \n",
    "    logging.info(\"Logging initialized\")\n",
    "\n",
    "class DirectPTFileDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset that loads directly from specified .pt files\"\"\"\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "        logging.info(f\"Attempting to load {len(file_paths)} PT files directly\")\n",
    "        \n",
    "        # Load all data from these files\n",
    "        self.data_list = []\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            if not os.path.exists(file_path):\n",
    "                logging.error(f\"File does not exist: {file_path}\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                logging.info(f\"Loading file: {file_path}\")\n",
    "                data_obj = torch.load(file_path)\n",
    "                \n",
    "                if isinstance(data_obj, list):\n",
    "                    logging.info(f\"Loaded list of {len(data_obj)} objects from {file_path}\")\n",
    "                    self.data_list.extend(data_obj)\n",
    "                elif hasattr(data_obj, 'x'):\n",
    "                    logging.info(f\"Loaded single data object from {file_path}\")\n",
    "                    self.data_list.append(data_obj)\n",
    "                else:\n",
    "                    logging.warning(f\"Unrecognized data format in {file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {file_path}: {str(e)}\", exc_info=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "class CustomSpinSystemDataset(SpinSystemDataset):\n",
    "    \"\"\"Extended version of SpinSystemDataset with better error handling\"\"\"\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        try:\n",
    "            # Check if the path exists\n",
    "            if not os.path.exists(root):\n",
    "                logging.error(f\"Directory does not exist: {root}\")\n",
    "                raise FileNotFoundError(f\"Directory does not exist: {root}\")\n",
    "                \n",
    "            # Try to initialize with original SpinSystemDataset\n",
    "            super(CustomSpinSystemDataset, self).__init__(root=root, transform=transform, pre_transform=pre_transform)\n",
    "            \n",
    "            # Look for processed directory and check its contents\n",
    "            processed_dir = os.path.join(root, 'processed')\n",
    "            if os.path.exists(processed_dir):\n",
    "                logging.info(f\"Processed directory exists: {processed_dir}\")\n",
    "                processed_files = os.listdir(processed_dir)\n",
    "                logging.info(f\"Files in processed directory: {processed_files}\")\n",
    "            else:\n",
    "                logging.warning(f\"No 'processed' directory found in {root}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error initializing CustomSpinSystemDataset: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "\n",
    "    def download(self):\n",
    "        # Override to avoid download attempts\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        # Override to avoid processing attempts if files already exist\n",
    "        processed_file_path = os.path.join(self.processed_dir, 'data.pt')\n",
    "        if os.path.exists(processed_file_path):\n",
    "            logging.info(f\"Processed file already exists: {processed_file_path}\")\n",
    "        else:\n",
    "            logging.warning(f\"Processed file does not exist: {processed_file_path}\")\n",
    "            # We would need to implement the processing logic here if needed\n",
    "            raise FileNotFoundError(f\"Required processed file not found: {processed_file_path}\")\n",
    "            \n",
    "    def _download(self):\n",
    "        # Override internal method\n",
    "        pass\n",
    "        \n",
    "    def _process(self):\n",
    "        # Override internal method if files exist\n",
    "        if not os.path.exists(os.path.join(self.processed_dir, 'data.pt')):\n",
    "            logging.error(f\"Processed file not found at {os.path.join(self.processed_dir, 'data.pt')}\")\n",
    "            raise FileNotFoundError(f\"Required processed file not found\")\n",
    "\n",
    "    \n",
    "    def _merge_data(self, data1, slices1, data2, slices2):\n",
    "        \"\"\"Merge two datasets together\"\"\"\n",
    "        # Create new data object with combined attributes\n",
    "        merged_data = data1.__class__()\n",
    "        \n",
    "        # Combine all attributes from both data objects\n",
    "        for key in data1.keys:\n",
    "            # Get the attribute from both datasets\n",
    "            item1, item2 = getattr(data1, key), getattr(data2, key)\n",
    "            \n",
    "            # Concatenate the attributes\n",
    "            if torch.is_tensor(item1) and torch.is_tensor(item2):\n",
    "                merged_attr = torch.cat([item1, item2], dim=data1.__cat_dim__(key, item1))\n",
    "            else:\n",
    "                merged_attr = item1 + item2  # For non-tensor attributes like edge_index\n",
    "                \n",
    "            setattr(merged_data, key, merged_attr)\n",
    "            \n",
    "        # Update the slices for the merged data\n",
    "        merged_slices = {}\n",
    "        for key in slices1.keys():\n",
    "            if key in slices2:\n",
    "                # Get the current maximum index from the first slice\n",
    "                offset = slices1[key][-1]\n",
    "                \n",
    "                # Add this offset to all indices in the second slice (except the first one)\n",
    "                second_slice_shifted = slices2[key][1:] + offset\n",
    "                \n",
    "                # Combine the slices, keeping only one copy of the overlapping index\n",
    "                merged_slice = torch.cat([slices1[key], second_slice_shifted])\n",
    "                merged_slices[key] = merged_slice\n",
    "        \n",
    "        return merged_data, merged_slices\n",
    "\n",
    "def load_multi_datasets():\n",
    "    \"\"\"Load multiple datasets from different directories\"\"\"\n",
    "    datasets = []\n",
    "    \n",
    "    # First check all directories for processed/data.pt files (PyG default)\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        # Check for processed/data.pt (standard PyG dataset structure)\n",
    "        pyg_file_path = os.path.join(data_dir, 'processed', 'data.pt')\n",
    "        if os.path.exists(pyg_file_path):\n",
    "            logging.info(f\"Found PyG dataset file: {pyg_file_path}\")\n",
    "    \n",
    "    # Check for pattern-matched files within the directories\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if os.path.exists(data_dir):\n",
    "            # First check in the main directory\n",
    "            pattern = os.path.join(data_dir, FINETUNE_CONFIG['processed_file_pattern'])\n",
    "            main_files = glob.glob(pattern)\n",
    "            \n",
    "            # Then check in the processed subdirectory\n",
    "            processed_pattern = os.path.join(data_dir, 'processed', FINETUNE_CONFIG['processed_file_pattern'])\n",
    "            processed_files = glob.glob(processed_pattern)\n",
    "            \n",
    "            all_files = main_files + processed_files\n",
    "            logging.info(f\"Found {len(all_files)} files in {data_dir} matching the pattern\")\n",
    "            for file in all_files:\n",
    "                logging.info(f\"  - {file}\")\n",
    "    \n",
    "    # Attempt each loading method\n",
    "    # 1. Try loading as standard PyG SpinSystemDataset from each directory\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if not os.path.exists(data_dir):\n",
    "            logging.error(f\"Directory does not exist: {data_dir}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            logging.info(f\"Attempting to load PyG dataset from {data_dir}\")\n",
    "            dataset = CustomSpinSystemDataset(root=data_dir)\n",
    "            datasets.append(dataset)\n",
    "            logging.info(f\"Successfully loaded PyG dataset from {data_dir} with {len(dataset)} samples\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not load PyG dataset from {data_dir}: {str(e)}\")\n",
    "            \n",
    "            # Check for data.pt in the processed directory\n",
    "            processed_file = os.path.join(data_dir, 'processed', 'data.pt')\n",
    "            if os.path.exists(processed_file):\n",
    "                try:\n",
    "                    logging.info(f\"Attempting to load direct data from {processed_file}\")\n",
    "                    # Try to load this specific file directly\n",
    "                    direct_dataset = DirectPTFileDataset([processed_file])\n",
    "                    if len(direct_dataset) > 0:\n",
    "                        datasets.append(direct_dataset)\n",
    "                        logging.info(f\"Loaded {len(direct_dataset)} samples directly from {processed_file}\")\n",
    "                except Exception as direct_e:\n",
    "                    logging.error(f\"Failed to load direct file {processed_file}: {str(direct_e)}\")\n",
    "    \n",
    "    # 2. Try loading from additional specified PT files\n",
    "    if hasattr(FINETUNE_CONFIG, 'alternative_file_paths') and FINETUNE_CONFIG['alternative_file_paths']:\n",
    "        direct_dataset = DirectPTFileDataset(FINETUNE_CONFIG['alternative_file_paths'])\n",
    "        if len(direct_dataset) > 0:\n",
    "            datasets.append(direct_dataset)\n",
    "            logging.info(f\"Loaded {len(direct_dataset)} samples from specified PT files\")\n",
    "    \n",
    "    # 3. If all else fails, request the proper file path\n",
    "    if not datasets:\n",
    "        logging.error(\"\"\"\n",
    "        No datasets could be loaded from the specified directories.\n",
    "        \n",
    "        Please check the following:\n",
    "        1. Verify that your data directories exist\n",
    "        2. Check that PyG dataset files are in a 'processed/data.pt' path\n",
    "        3. Try specifying direct paths to PT files in 'alternative_file_paths'\n",
    "        \"\"\")\n",
    "        \n",
    "        # Get user input for data file path\n",
    "        print(\"\\nNo datasets could be loaded from the specified directories.\")\n",
    "        print(\"Please enter the path to a PyTorch Geometric dataset file (data.pt):\")\n",
    "        file_path = input(\"Path: \").strip()\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Try to load it as a direct PT file\n",
    "                direct_dataset = DirectPTFileDataset([file_path])\n",
    "                if len(direct_dataset) > 0:\n",
    "                    datasets.append(direct_dataset)\n",
    "                    logging.info(f\"Loaded {len(direct_dataset)} samples from user-specified {file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to load user-specified file: {str(e)}\")\n",
    "                \n",
    "                # Last resort - try to find parent directory and load as PyG dataset\n",
    "                parent_dir = os.path.dirname(os.path.dirname(file_path))\n",
    "                try:\n",
    "                    dataset = CustomSpinSystemDataset(root=parent_dir)\n",
    "                    datasets.append(dataset)\n",
    "                    logging.info(f\"Loaded PyG dataset from {parent_dir} with {len(dataset)} samples\")\n",
    "                except Exception as pe:\n",
    "                    logging.error(f\"Failed to load from parent directory {parent_dir}: {str(pe)}\")\n",
    "                    raise ValueError(\"No datasets could be loaded. Please check your data files.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Specified file does not exist: {file_path}\")\n",
    "    \n",
    "    # Combine all datasets\n",
    "    combined_dataset = ConcatDataset(datasets) if len(datasets) > 0 else None\n",
    "    if combined_dataset:\n",
    "        logging.info(f\"Combined dataset contains {len(combined_dataset)} samples total\")\n",
    "    else:\n",
    "        raise ValueError(\"No datasets could be loaded\")\n",
    "    \n",
    "    return combined_dataset\n",
    "\n",
    "def fine_tune_model():\n",
    "    setup_logging()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Print out current working directory and available files for debugging\n",
    "    logging.info(f\"Current working directory: {os.getcwd()}\")\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if os.path.exists(data_dir):\n",
    "            logging.info(f\"Directory {data_dir} exists\")\n",
    "            files = os.listdir(data_dir)\n",
    "            logging.info(f\"Files in {data_dir}: {files}\")\n",
    "            # Check if processed_dir exists\n",
    "            processed_dir = os.path.join(data_dir, 'processed')\n",
    "            if os.path.exists(processed_dir):\n",
    "                logging.info(f\"Processed directory exists: {processed_dir}\")\n",
    "                processed_files = os.listdir(processed_dir)\n",
    "                logging.info(f\"Files in processed dir: {processed_files}\")\n",
    "        else:\n",
    "            logging.error(f\"Directory {data_dir} does not exist!\")\n",
    "    \n",
    "    # Load the pretrained model\n",
    "    try:\n",
    "        model = ExperimentalGNN(\n",
    "            hidden_channels=512,\n",
    "            dropout_p=FINETUNE_CONFIG['dropout_p']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Check if pretrained model file exists\n",
    "        if not os.path.exists(FINETUNE_CONFIG['pretrained_model_path']):\n",
    "            logging.error(f\"Pretrained model file not found: {FINETUNE_CONFIG['pretrained_model_path']}\")\n",
    "            raise FileNotFoundError(f\"Pretrained model file not found: {FINETUNE_CONFIG['pretrained_model_path']}\")\n",
    "            \n",
    "        # Load pretrained weights\n",
    "        pretrained_state_dict = torch.load(FINETUNE_CONFIG['pretrained_model_path'], map_location=device)\n",
    "        model.load_state_dict(pretrained_state_dict)\n",
    "        logging.info(\"Loaded pretrained model successfully\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading model: {str(e)}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "    # Load datasets from multiple directories\n",
    "    combined_dataset = load_multi_datasets()\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(combined_dataset))\n",
    "    val_size = len(combined_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        combined_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(FINETUNE_CONFIG['random_seed'])\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "    # Initialize loss and optimizer\n",
    "    criterion = PhysicalScaleAwareLoss(physics_weight=0.5)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=FINETUNE_CONFIG['learning_rate'],\n",
    "        weight_decay=FINETUNE_CONFIG['weight_decay']\n",
    "    )\n",
    "\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=20,\n",
    "        T_mult=2,\n",
    "        eta_min=1e-7\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(FINETUNE_CONFIG['num_epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_mae = 0\n",
    "        total_train_samples = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            pred_s = model(data)\n",
    "            targets = data.y.squeeze().to(device)\n",
    "            system_size = data.system_size.squeeze(-1).to(device)\n",
    "            subsystem_size = data.nA.squeeze(-1).to(device)\n",
    "            \n",
    "            loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "            loss.backward()\n",
    "            \n",
    "            if FINETUNE_CONFIG['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), FINETUNE_CONFIG['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate MAE for this batch\n",
    "            mae = torch.abs(pred_s - targets).sum().item()\n",
    "            train_mae += mae\n",
    "            total_train_samples += data.num_graphs\n",
    "            total_train_loss += loss.item() * data.num_graphs\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataset)\n",
    "        avg_train_mae = train_mae / total_train_samples\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_mae = 0\n",
    "        total_val_samples = 0\n",
    "        all_val_preds = []\n",
    "        all_val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                pred_s = model(data)\n",
    "                targets = data.y.squeeze().to(device)\n",
    "                system_size = data.system_size.squeeze(-1).to(device)\n",
    "                subsystem_size = data.nA.squeeze(-1).to(device)\n",
    "                \n",
    "                loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "                total_val_loss += loss.item() * data.num_graphs\n",
    "                \n",
    "                # Calculate MAE for this batch\n",
    "                mae = torch.abs(pred_s - targets).sum().item()\n",
    "                val_mae += mae\n",
    "                total_val_samples += data.num_graphs\n",
    "                \n",
    "                # Store CPU tensors for numpy conversion\n",
    "                all_val_preds.extend(pred_s.cpu().numpy())\n",
    "                all_val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_dataset)\n",
    "        avg_val_mae = val_mae / total_val_samples\n",
    "        scheduler.step()\n",
    "\n",
    "        logging.info(f'Epoch {epoch+1}/{FINETUNE_CONFIG[\"num_epochs\"]}:')\n",
    "        logging.info(f'  Training Loss: {avg_train_loss:.6f}')\n",
    "        logging.info(f'  Training MAE: {avg_train_mae:.6f}')\n",
    "        logging.info(f'  Validation Loss: {avg_val_loss:.6f}')\n",
    "        logging.info(f'  Validation MAE: {avg_val_mae:.6f}')\n",
    "\n",
    "        # Save best model and early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), FINETUNE_CONFIG['finetuned_model_path'])\n",
    "            logging.info(f'  Saved new best model (val_loss={best_val_loss:.6f})')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= FINETUNE_CONFIG['patience']:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    logging.info('Fine-tuning completed')\n",
    "    logging.info(f'Best validation loss: {best_val_loss:.6f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fine_tune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07de1a09-a64c-4f5c-b3b4-8707b2ffc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 22:38:54 [INFO] Logging initialized\n",
      "2025-03-10 22:38:54 [INFO] Using device: cuda\n",
      "2025-03-10 22:38:54 [INFO] Current working directory: C:\\Users\\amssa\\Documents\\Codes\\New\\Von-Neumann-Entropy-GNN\\Size14\n",
      "2025-03-10 22:38:54 [INFO] Directory ./processed_9-10_times5_r6 exists\n",
      "2025-03-10 22:38:54 [INFO] Files in ./processed_9-10_times5_r6: ['processed', 'raw']\n",
      "2025-03-10 22:38:54 [INFO] Processed directory exists: ./processed_9-10_times5_r6\\processed\n",
      "2025-03-10 22:38:54 [INFO] Files in processed dir: ['data.pt', 'pre_filter.pt', 'pre_transform.pt']\n",
      "2025-03-10 22:38:55 [INFO] Loaded pretrained model successfully\n",
      "2025-03-10 22:38:55 [INFO] Found PyG dataset file: ./processed_9-10_times5_r6\\processed\\data.pt\n",
      "2025-03-10 22:38:55 [INFO] Found 1 files in ./processed_9-10_times5_r6 matching the pattern\n",
      "2025-03-10 22:38:55 [INFO]   - ./processed_9-10_times5_r6\\processed\\data.pt\n",
      "2025-03-10 22:38:55 [INFO] Attempting to load PyG dataset from ./processed_9-10_times5_r6\n",
      "2025-03-10 22:38:55 [INFO] Processed directory exists: ./processed_9-10_times5_r6\\processed\n",
      "2025-03-10 22:38:55 [INFO] Files in processed directory: ['data.pt', 'pre_filter.pt', 'pre_transform.pt']\n",
      "2025-03-10 22:38:55 [INFO] Successfully loaded PyG dataset from ./processed_9-10_times5_r6 with 5000 samples\n",
      "2025-03-10 22:38:55 [INFO] Combined dataset contains 5000 samples total\n",
      "2025-03-10 22:39:04 [INFO] Epoch 1/200:\n",
      "2025-03-10 22:39:04 [INFO]   Training Loss: 0.042899\n",
      "2025-03-10 22:39:04 [INFO]   Training MAE: 0.197448\n",
      "2025-03-10 22:39:04 [INFO]   Validation Loss: 0.020175\n",
      "2025-03-10 22:39:04 [INFO]   Validation MAE: 0.129498\n",
      "2025-03-10 22:39:05 [INFO]   Saved new best model (val_loss=0.020175)\n",
      "2025-03-10 22:39:11 [INFO] Epoch 2/200:\n",
      "2025-03-10 22:39:11 [INFO]   Training Loss: 0.015215\n",
      "2025-03-10 22:39:11 [INFO]   Training MAE: 0.108819\n",
      "2025-03-10 22:39:11 [INFO]   Validation Loss: 0.009277\n",
      "2025-03-10 22:39:11 [INFO]   Validation MAE: 0.083908\n",
      "2025-03-10 22:39:11 [INFO]   Saved new best model (val_loss=0.009277)\n",
      "2025-03-10 22:39:18 [INFO] Epoch 3/200:\n",
      "2025-03-10 22:39:18 [INFO]   Training Loss: 0.010209\n",
      "2025-03-10 22:39:18 [INFO]   Training MAE: 0.090926\n",
      "2025-03-10 22:39:18 [INFO]   Validation Loss: 0.006069\n",
      "2025-03-10 22:39:18 [INFO]   Validation MAE: 0.072790\n",
      "2025-03-10 22:39:18 [INFO]   Saved new best model (val_loss=0.006069)\n",
      "2025-03-10 22:39:24 [INFO] Epoch 4/200:\n",
      "2025-03-10 22:39:24 [INFO]   Training Loss: 0.008653\n",
      "2025-03-10 22:39:24 [INFO]   Training MAE: 0.079210\n",
      "2025-03-10 22:39:24 [INFO]   Validation Loss: 0.004430\n",
      "2025-03-10 22:39:24 [INFO]   Validation MAE: 0.058222\n",
      "2025-03-10 22:39:24 [INFO]   Saved new best model (val_loss=0.004430)\n",
      "2025-03-10 22:39:32 [INFO] Epoch 5/200:\n",
      "2025-03-10 22:39:32 [INFO]   Training Loss: 0.006394\n",
      "2025-03-10 22:39:32 [INFO]   Training MAE: 0.070149\n",
      "2025-03-10 22:39:32 [INFO]   Validation Loss: 0.004140\n",
      "2025-03-10 22:39:32 [INFO]   Validation MAE: 0.057918\n",
      "2025-03-10 22:39:32 [INFO]   Saved new best model (val_loss=0.004140)\n",
      "2025-03-10 22:39:39 [INFO] Epoch 6/200:\n",
      "2025-03-10 22:39:39 [INFO]   Training Loss: 0.006039\n",
      "2025-03-10 22:39:39 [INFO]   Training MAE: 0.069055\n",
      "2025-03-10 22:39:39 [INFO]   Validation Loss: 0.003460\n",
      "2025-03-10 22:39:39 [INFO]   Validation MAE: 0.049975\n",
      "2025-03-10 22:39:39 [INFO]   Saved new best model (val_loss=0.003460)\n",
      "2025-03-10 22:39:47 [INFO] Epoch 7/200:\n",
      "2025-03-10 22:39:47 [INFO]   Training Loss: 0.006141\n",
      "2025-03-10 22:39:47 [INFO]   Training MAE: 0.067886\n",
      "2025-03-10 22:39:47 [INFO]   Validation Loss: 0.003594\n",
      "2025-03-10 22:39:47 [INFO]   Validation MAE: 0.055021\n",
      "2025-03-10 22:39:54 [INFO] Epoch 8/200:\n",
      "2025-03-10 22:39:54 [INFO]   Training Loss: 0.005216\n",
      "2025-03-10 22:39:54 [INFO]   Training MAE: 0.062635\n",
      "2025-03-10 22:39:54 [INFO]   Validation Loss: 0.003708\n",
      "2025-03-10 22:39:54 [INFO]   Validation MAE: 0.057691\n",
      "2025-03-10 22:40:01 [INFO] Epoch 9/200:\n",
      "2025-03-10 22:40:01 [INFO]   Training Loss: 0.004657\n",
      "2025-03-10 22:40:01 [INFO]   Training MAE: 0.058980\n",
      "2025-03-10 22:40:01 [INFO]   Validation Loss: 0.002957\n",
      "2025-03-10 22:40:01 [INFO]   Validation MAE: 0.045037\n",
      "2025-03-10 22:40:01 [INFO]   Saved new best model (val_loss=0.002957)\n",
      "2025-03-10 22:40:08 [INFO] Epoch 10/200:\n",
      "2025-03-10 22:40:08 [INFO]   Training Loss: 0.003983\n",
      "2025-03-10 22:40:08 [INFO]   Training MAE: 0.053995\n",
      "2025-03-10 22:40:08 [INFO]   Validation Loss: 0.002803\n",
      "2025-03-10 22:40:08 [INFO]   Validation MAE: 0.043631\n",
      "2025-03-10 22:40:08 [INFO]   Saved new best model (val_loss=0.002803)\n",
      "2025-03-10 22:40:15 [INFO] Epoch 11/200:\n",
      "2025-03-10 22:40:15 [INFO]   Training Loss: 0.004215\n",
      "2025-03-10 22:40:15 [INFO]   Training MAE: 0.056662\n",
      "2025-03-10 22:40:15 [INFO]   Validation Loss: 0.003040\n",
      "2025-03-10 22:40:15 [INFO]   Validation MAE: 0.047158\n",
      "2025-03-10 22:40:22 [INFO] Epoch 12/200:\n",
      "2025-03-10 22:40:22 [INFO]   Training Loss: 0.004479\n",
      "2025-03-10 22:40:22 [INFO]   Training MAE: 0.058092\n",
      "2025-03-10 22:40:22 [INFO]   Validation Loss: 0.002874\n",
      "2025-03-10 22:40:22 [INFO]   Validation MAE: 0.044449\n",
      "2025-03-10 22:40:30 [INFO] Epoch 13/200:\n",
      "2025-03-10 22:40:30 [INFO]   Training Loss: 0.004095\n",
      "2025-03-10 22:40:30 [INFO]   Training MAE: 0.054488\n",
      "2025-03-10 22:40:30 [INFO]   Validation Loss: 0.002817\n",
      "2025-03-10 22:40:30 [INFO]   Validation MAE: 0.045143\n",
      "2025-03-10 22:40:38 [INFO] Epoch 14/200:\n",
      "2025-03-10 22:40:38 [INFO]   Training Loss: 0.004156\n",
      "2025-03-10 22:40:38 [INFO]   Training MAE: 0.055858\n",
      "2025-03-10 22:40:38 [INFO]   Validation Loss: 0.003385\n",
      "2025-03-10 22:40:38 [INFO]   Validation MAE: 0.054192\n",
      "2025-03-10 22:40:44 [INFO] Epoch 15/200:\n",
      "2025-03-10 22:40:44 [INFO]   Training Loss: 0.003755\n",
      "2025-03-10 22:40:44 [INFO]   Training MAE: 0.052046\n",
      "2025-03-10 22:40:44 [INFO]   Validation Loss: 0.002669\n",
      "2025-03-10 22:40:44 [INFO]   Validation MAE: 0.042114\n",
      "2025-03-10 22:40:44 [INFO]   Saved new best model (val_loss=0.002669)\n",
      "2025-03-10 22:40:51 [INFO] Epoch 16/200:\n",
      "2025-03-10 22:40:51 [INFO]   Training Loss: 0.003778\n",
      "2025-03-10 22:40:51 [INFO]   Training MAE: 0.053613\n",
      "2025-03-10 22:40:51 [INFO]   Validation Loss: 0.002575\n",
      "2025-03-10 22:40:51 [INFO]   Validation MAE: 0.040575\n",
      "2025-03-10 22:40:51 [INFO]   Saved new best model (val_loss=0.002575)\n",
      "2025-03-10 22:40:57 [INFO] Epoch 17/200:\n",
      "2025-03-10 22:40:57 [INFO]   Training Loss: 0.003807\n",
      "2025-03-10 22:40:57 [INFO]   Training MAE: 0.054137\n",
      "2025-03-10 22:40:57 [INFO]   Validation Loss: 0.002680\n",
      "2025-03-10 22:40:57 [INFO]   Validation MAE: 0.042830\n",
      "2025-03-10 22:41:04 [INFO] Epoch 18/200:\n",
      "2025-03-10 22:41:04 [INFO]   Training Loss: 0.003784\n",
      "2025-03-10 22:41:04 [INFO]   Training MAE: 0.053415\n",
      "2025-03-10 22:41:04 [INFO]   Validation Loss: 0.002582\n",
      "2025-03-10 22:41:04 [INFO]   Validation MAE: 0.041501\n",
      "2025-03-10 22:41:12 [INFO] Epoch 19/200:\n",
      "2025-03-10 22:41:12 [INFO]   Training Loss: 0.003854\n",
      "2025-03-10 22:41:12 [INFO]   Training MAE: 0.053004\n",
      "2025-03-10 22:41:12 [INFO]   Validation Loss: 0.002793\n",
      "2025-03-10 22:41:12 [INFO]   Validation MAE: 0.045106\n",
      "2025-03-10 22:41:18 [INFO] Epoch 20/200:\n",
      "2025-03-10 22:41:18 [INFO]   Training Loss: 0.004080\n",
      "2025-03-10 22:41:18 [INFO]   Training MAE: 0.055808\n",
      "2025-03-10 22:41:18 [INFO]   Validation Loss: 0.002898\n",
      "2025-03-10 22:41:18 [INFO]   Validation MAE: 0.046435\n",
      "2025-03-10 22:41:25 [INFO] Epoch 21/200:\n",
      "2025-03-10 22:41:25 [INFO]   Training Loss: 0.004226\n",
      "2025-03-10 22:41:25 [INFO]   Training MAE: 0.056786\n",
      "2025-03-10 22:41:25 [INFO]   Validation Loss: 0.002763\n",
      "2025-03-10 22:41:25 [INFO]   Validation MAE: 0.043914\n",
      "2025-03-10 22:41:31 [INFO] Epoch 22/200:\n",
      "2025-03-10 22:41:31 [INFO]   Training Loss: 0.004021\n",
      "2025-03-10 22:41:31 [INFO]   Training MAE: 0.055476\n",
      "2025-03-10 22:41:31 [INFO]   Validation Loss: 0.002607\n",
      "2025-03-10 22:41:31 [INFO]   Validation MAE: 0.043520\n",
      "2025-03-10 22:41:38 [INFO] Epoch 23/200:\n",
      "2025-03-10 22:41:38 [INFO]   Training Loss: 0.003610\n",
      "2025-03-10 22:41:38 [INFO]   Training MAE: 0.051857\n",
      "2025-03-10 22:41:38 [INFO]   Validation Loss: 0.002741\n",
      "2025-03-10 22:41:38 [INFO]   Validation MAE: 0.045620\n",
      "2025-03-10 22:41:44 [INFO] Epoch 24/200:\n",
      "2025-03-10 22:41:44 [INFO]   Training Loss: 0.003583\n",
      "2025-03-10 22:41:44 [INFO]   Training MAE: 0.051832\n",
      "2025-03-10 22:41:44 [INFO]   Validation Loss: 0.002425\n",
      "2025-03-10 22:41:44 [INFO]   Validation MAE: 0.040502\n",
      "2025-03-10 22:41:45 [INFO]   Saved new best model (val_loss=0.002425)\n",
      "2025-03-10 22:41:51 [INFO] Epoch 25/200:\n",
      "2025-03-10 22:41:51 [INFO]   Training Loss: 0.003334\n",
      "2025-03-10 22:41:51 [INFO]   Training MAE: 0.050018\n",
      "2025-03-10 22:41:51 [INFO]   Validation Loss: 0.002973\n",
      "2025-03-10 22:41:51 [INFO]   Validation MAE: 0.048520\n",
      "2025-03-10 22:41:59 [INFO] Epoch 26/200:\n",
      "2025-03-10 22:41:59 [INFO]   Training Loss: 0.003691\n",
      "2025-03-10 22:41:59 [INFO]   Training MAE: 0.052671\n",
      "2025-03-10 22:41:59 [INFO]   Validation Loss: 0.002743\n",
      "2025-03-10 22:41:59 [INFO]   Validation MAE: 0.046096\n",
      "2025-03-10 22:42:06 [INFO] Epoch 27/200:\n",
      "2025-03-10 22:42:06 [INFO]   Training Loss: 0.003311\n",
      "2025-03-10 22:42:06 [INFO]   Training MAE: 0.050362\n",
      "2025-03-10 22:42:06 [INFO]   Validation Loss: 0.002276\n",
      "2025-03-10 22:42:06 [INFO]   Validation MAE: 0.037493\n",
      "2025-03-10 22:42:07 [INFO]   Saved new best model (val_loss=0.002276)\n",
      "2025-03-10 22:42:15 [INFO] Epoch 28/200:\n",
      "2025-03-10 22:42:15 [INFO]   Training Loss: 0.003437\n",
      "2025-03-10 22:42:15 [INFO]   Training MAE: 0.049819\n",
      "2025-03-10 22:42:15 [INFO]   Validation Loss: 0.002415\n",
      "2025-03-10 22:42:15 [INFO]   Validation MAE: 0.040067\n",
      "2025-03-10 22:42:22 [INFO] Epoch 29/200:\n",
      "2025-03-10 22:42:22 [INFO]   Training Loss: 0.003153\n",
      "2025-03-10 22:42:22 [INFO]   Training MAE: 0.048469\n",
      "2025-03-10 22:42:22 [INFO]   Validation Loss: 0.002452\n",
      "2025-03-10 22:42:22 [INFO]   Validation MAE: 0.040371\n",
      "2025-03-10 22:42:28 [INFO] Epoch 30/200:\n",
      "2025-03-10 22:42:28 [INFO]   Training Loss: 0.003086\n",
      "2025-03-10 22:42:28 [INFO]   Training MAE: 0.047986\n",
      "2025-03-10 22:42:28 [INFO]   Validation Loss: 0.002305\n",
      "2025-03-10 22:42:28 [INFO]   Validation MAE: 0.038686\n",
      "2025-03-10 22:42:36 [INFO] Epoch 31/200:\n",
      "2025-03-10 22:42:36 [INFO]   Training Loss: 0.003598\n",
      "2025-03-10 22:42:36 [INFO]   Training MAE: 0.052995\n",
      "2025-03-10 22:42:36 [INFO]   Validation Loss: 0.002803\n",
      "2025-03-10 22:42:36 [INFO]   Validation MAE: 0.048408\n",
      "2025-03-10 22:42:43 [INFO] Epoch 32/200:\n",
      "2025-03-10 22:42:43 [INFO]   Training Loss: 0.003834\n",
      "2025-03-10 22:42:43 [INFO]   Training MAE: 0.053690\n",
      "2025-03-10 22:42:43 [INFO]   Validation Loss: 0.002500\n",
      "2025-03-10 22:42:43 [INFO]   Validation MAE: 0.043600\n",
      "2025-03-10 22:42:50 [INFO] Epoch 33/200:\n",
      "2025-03-10 22:42:50 [INFO]   Training Loss: 0.003095\n",
      "2025-03-10 22:42:50 [INFO]   Training MAE: 0.048431\n",
      "2025-03-10 22:42:50 [INFO]   Validation Loss: 0.002204\n",
      "2025-03-10 22:42:50 [INFO]   Validation MAE: 0.037195\n",
      "2025-03-10 22:42:50 [INFO]   Saved new best model (val_loss=0.002204)\n",
      "2025-03-10 22:42:58 [INFO] Epoch 34/200:\n",
      "2025-03-10 22:42:58 [INFO]   Training Loss: 0.003329\n",
      "2025-03-10 22:42:58 [INFO]   Training MAE: 0.050729\n",
      "2025-03-10 22:42:58 [INFO]   Validation Loss: 0.002572\n",
      "2025-03-10 22:42:58 [INFO]   Validation MAE: 0.044350\n",
      "2025-03-10 22:43:04 [INFO] Epoch 35/200:\n",
      "2025-03-10 22:43:04 [INFO]   Training Loss: 0.002904\n",
      "2025-03-10 22:43:04 [INFO]   Training MAE: 0.045175\n",
      "2025-03-10 22:43:04 [INFO]   Validation Loss: 0.002194\n",
      "2025-03-10 22:43:04 [INFO]   Validation MAE: 0.037475\n",
      "2025-03-10 22:43:04 [INFO]   Saved new best model (val_loss=0.002194)\n",
      "2025-03-10 22:43:11 [INFO] Epoch 36/200:\n",
      "2025-03-10 22:43:11 [INFO]   Training Loss: 0.003151\n",
      "2025-03-10 22:43:11 [INFO]   Training MAE: 0.047155\n",
      "2025-03-10 22:43:11 [INFO]   Validation Loss: 0.002246\n",
      "2025-03-10 22:43:11 [INFO]   Validation MAE: 0.039379\n",
      "2025-03-10 22:43:18 [INFO] Epoch 37/200:\n",
      "2025-03-10 22:43:18 [INFO]   Training Loss: 0.002968\n",
      "2025-03-10 22:43:18 [INFO]   Training MAE: 0.046823\n",
      "2025-03-10 22:43:18 [INFO]   Validation Loss: 0.002456\n",
      "2025-03-10 22:43:18 [INFO]   Validation MAE: 0.042126\n",
      "2025-03-10 22:43:27 [INFO] Epoch 38/200:\n",
      "2025-03-10 22:43:27 [INFO]   Training Loss: 0.002872\n",
      "2025-03-10 22:43:27 [INFO]   Training MAE: 0.045638\n",
      "2025-03-10 22:43:27 [INFO]   Validation Loss: 0.002186\n",
      "2025-03-10 22:43:27 [INFO]   Validation MAE: 0.037715\n",
      "2025-03-10 22:43:27 [INFO]   Saved new best model (val_loss=0.002186)\n",
      "2025-03-10 22:43:36 [INFO] Epoch 39/200:\n",
      "2025-03-10 22:43:36 [INFO]   Training Loss: 0.002755\n",
      "2025-03-10 22:43:36 [INFO]   Training MAE: 0.045212\n",
      "2025-03-10 22:43:36 [INFO]   Validation Loss: 0.002001\n",
      "2025-03-10 22:43:36 [INFO]   Validation MAE: 0.035616\n",
      "2025-03-10 22:43:36 [INFO]   Saved new best model (val_loss=0.002001)\n",
      "2025-03-10 22:43:43 [INFO] Epoch 40/200:\n",
      "2025-03-10 22:43:43 [INFO]   Training Loss: 0.002693\n",
      "2025-03-10 22:43:43 [INFO]   Training MAE: 0.045198\n",
      "2025-03-10 22:43:43 [INFO]   Validation Loss: 0.002275\n",
      "2025-03-10 22:43:43 [INFO]   Validation MAE: 0.039941\n",
      "2025-03-10 22:43:50 [INFO] Epoch 41/200:\n",
      "2025-03-10 22:43:50 [INFO]   Training Loss: 0.002504\n",
      "2025-03-10 22:43:50 [INFO]   Training MAE: 0.042748\n",
      "2025-03-10 22:43:50 [INFO]   Validation Loss: 0.002171\n",
      "2025-03-10 22:43:50 [INFO]   Validation MAE: 0.037672\n",
      "2025-03-10 22:43:58 [INFO] Epoch 42/200:\n",
      "2025-03-10 22:43:58 [INFO]   Training Loss: 0.002701\n",
      "2025-03-10 22:43:58 [INFO]   Training MAE: 0.044725\n",
      "2025-03-10 22:43:58 [INFO]   Validation Loss: 0.002085\n",
      "2025-03-10 22:43:58 [INFO]   Validation MAE: 0.036136\n",
      "2025-03-10 22:44:05 [INFO] Epoch 43/200:\n",
      "2025-03-10 22:44:05 [INFO]   Training Loss: 0.002767\n",
      "2025-03-10 22:44:05 [INFO]   Training MAE: 0.044916\n",
      "2025-03-10 22:44:05 [INFO]   Validation Loss: 0.002486\n",
      "2025-03-10 22:44:05 [INFO]   Validation MAE: 0.043737\n",
      "2025-03-10 22:44:12 [INFO] Epoch 44/200:\n",
      "2025-03-10 22:44:12 [INFO]   Training Loss: 0.002733\n",
      "2025-03-10 22:44:12 [INFO]   Training MAE: 0.045189\n",
      "2025-03-10 22:44:12 [INFO]   Validation Loss: 0.002086\n",
      "2025-03-10 22:44:12 [INFO]   Validation MAE: 0.036549\n",
      "2025-03-10 22:44:18 [INFO] Epoch 45/200:\n",
      "2025-03-10 22:44:18 [INFO]   Training Loss: 0.002910\n",
      "2025-03-10 22:44:18 [INFO]   Training MAE: 0.046991\n",
      "2025-03-10 22:44:18 [INFO]   Validation Loss: 0.002239\n",
      "2025-03-10 22:44:18 [INFO]   Validation MAE: 0.039736\n",
      "2025-03-10 22:44:26 [INFO] Epoch 46/200:\n",
      "2025-03-10 22:44:26 [INFO]   Training Loss: 0.002669\n",
      "2025-03-10 22:44:26 [INFO]   Training MAE: 0.044302\n",
      "2025-03-10 22:44:26 [INFO]   Validation Loss: 0.002044\n",
      "2025-03-10 22:44:26 [INFO]   Validation MAE: 0.036015\n",
      "2025-03-10 22:44:32 [INFO] Epoch 47/200:\n",
      "2025-03-10 22:44:32 [INFO]   Training Loss: 0.002528\n",
      "2025-03-10 22:44:32 [INFO]   Training MAE: 0.042986\n",
      "2025-03-10 22:44:32 [INFO]   Validation Loss: 0.002157\n",
      "2025-03-10 22:44:32 [INFO]   Validation MAE: 0.038418\n",
      "2025-03-10 22:44:42 [INFO] Epoch 48/200:\n",
      "2025-03-10 22:44:42 [INFO]   Training Loss: 0.002611\n",
      "2025-03-10 22:44:42 [INFO]   Training MAE: 0.043558\n",
      "2025-03-10 22:44:42 [INFO]   Validation Loss: 0.002141\n",
      "2025-03-10 22:44:42 [INFO]   Validation MAE: 0.037607\n",
      "2025-03-10 22:44:49 [INFO] Epoch 49/200:\n",
      "2025-03-10 22:44:49 [INFO]   Training Loss: 0.002565\n",
      "2025-03-10 22:44:49 [INFO]   Training MAE: 0.043135\n",
      "2025-03-10 22:44:49 [INFO]   Validation Loss: 0.002132\n",
      "2025-03-10 22:44:49 [INFO]   Validation MAE: 0.037493\n",
      "2025-03-10 22:44:56 [INFO] Epoch 50/200:\n",
      "2025-03-10 22:44:56 [INFO]   Training Loss: 0.002597\n",
      "2025-03-10 22:44:56 [INFO]   Training MAE: 0.042459\n",
      "2025-03-10 22:44:56 [INFO]   Validation Loss: 0.002382\n",
      "2025-03-10 22:44:56 [INFO]   Validation MAE: 0.041587\n",
      "2025-03-10 22:45:03 [INFO] Epoch 51/200:\n",
      "2025-03-10 22:45:03 [INFO]   Training Loss: 0.002449\n",
      "2025-03-10 22:45:03 [INFO]   Training MAE: 0.042256\n",
      "2025-03-10 22:45:03 [INFO]   Validation Loss: 0.002058\n",
      "2025-03-10 22:45:03 [INFO]   Validation MAE: 0.036171\n",
      "2025-03-10 22:45:09 [INFO] Epoch 52/200:\n",
      "2025-03-10 22:45:09 [INFO]   Training Loss: 0.002581\n",
      "2025-03-10 22:45:09 [INFO]   Training MAE: 0.043102\n",
      "2025-03-10 22:45:09 [INFO]   Validation Loss: 0.002011\n",
      "2025-03-10 22:45:09 [INFO]   Validation MAE: 0.034999\n",
      "2025-03-10 22:45:16 [INFO] Epoch 53/200:\n",
      "2025-03-10 22:45:16 [INFO]   Training Loss: 0.002488\n",
      "2025-03-10 22:45:16 [INFO]   Training MAE: 0.042809\n",
      "2025-03-10 22:45:16 [INFO]   Validation Loss: 0.002087\n",
      "2025-03-10 22:45:16 [INFO]   Validation MAE: 0.036458\n",
      "2025-03-10 22:45:23 [INFO] Epoch 54/200:\n",
      "2025-03-10 22:45:23 [INFO]   Training Loss: 0.002773\n",
      "2025-03-10 22:45:23 [INFO]   Training MAE: 0.044218\n",
      "2025-03-10 22:45:23 [INFO]   Validation Loss: 0.002283\n",
      "2025-03-10 22:45:23 [INFO]   Validation MAE: 0.040653\n",
      "2025-03-10 22:45:30 [INFO] Epoch 55/200:\n",
      "2025-03-10 22:45:30 [INFO]   Training Loss: 0.002659\n",
      "2025-03-10 22:45:30 [INFO]   Training MAE: 0.043852\n",
      "2025-03-10 22:45:30 [INFO]   Validation Loss: 0.002189\n",
      "2025-03-10 22:45:30 [INFO]   Validation MAE: 0.038330\n",
      "2025-03-10 22:45:36 [INFO] Epoch 56/200:\n",
      "2025-03-10 22:45:36 [INFO]   Training Loss: 0.002421\n",
      "2025-03-10 22:45:36 [INFO]   Training MAE: 0.041936\n",
      "2025-03-10 22:45:36 [INFO]   Validation Loss: 0.002142\n",
      "2025-03-10 22:45:36 [INFO]   Validation MAE: 0.038058\n",
      "2025-03-10 22:45:43 [INFO] Epoch 57/200:\n",
      "2025-03-10 22:45:43 [INFO]   Training Loss: 0.002634\n",
      "2025-03-10 22:45:43 [INFO]   Training MAE: 0.044396\n",
      "2025-03-10 22:45:43 [INFO]   Validation Loss: 0.002031\n",
      "2025-03-10 22:45:43 [INFO]   Validation MAE: 0.034989\n",
      "2025-03-10 22:45:50 [INFO] Epoch 58/200:\n",
      "2025-03-10 22:45:50 [INFO]   Training Loss: 0.002507\n",
      "2025-03-10 22:45:50 [INFO]   Training MAE: 0.042874\n",
      "2025-03-10 22:45:50 [INFO]   Validation Loss: 0.002025\n",
      "2025-03-10 22:45:50 [INFO]   Validation MAE: 0.034941\n",
      "2025-03-10 22:45:57 [INFO] Epoch 59/200:\n",
      "2025-03-10 22:45:57 [INFO]   Training Loss: 0.002543\n",
      "2025-03-10 22:45:57 [INFO]   Training MAE: 0.042707\n",
      "2025-03-10 22:45:57 [INFO]   Validation Loss: 0.002281\n",
      "2025-03-10 22:45:57 [INFO]   Validation MAE: 0.040822\n",
      "2025-03-10 22:46:04 [INFO] Epoch 60/200:\n",
      "2025-03-10 22:46:04 [INFO]   Training Loss: 0.002611\n",
      "2025-03-10 22:46:04 [INFO]   Training MAE: 0.043693\n",
      "2025-03-10 22:46:04 [INFO]   Validation Loss: 0.002012\n",
      "2025-03-10 22:46:04 [INFO]   Validation MAE: 0.034591\n",
      "2025-03-10 22:46:11 [INFO] Epoch 61/200:\n",
      "2025-03-10 22:46:11 [INFO]   Training Loss: 0.002909\n",
      "2025-03-10 22:46:11 [INFO]   Training MAE: 0.046604\n",
      "2025-03-10 22:46:11 [INFO]   Validation Loss: 0.002276\n",
      "2025-03-10 22:46:11 [INFO]   Validation MAE: 0.040024\n",
      "2025-03-10 22:46:18 [INFO] Epoch 62/200:\n",
      "2025-03-10 22:46:18 [INFO]   Training Loss: 0.002624\n",
      "2025-03-10 22:46:18 [INFO]   Training MAE: 0.043445\n",
      "2025-03-10 22:46:18 [INFO]   Validation Loss: 0.002201\n",
      "2025-03-10 22:46:18 [INFO]   Validation MAE: 0.037750\n",
      "2025-03-10 22:46:24 [INFO] Epoch 63/200:\n",
      "2025-03-10 22:46:24 [INFO]   Training Loss: 0.002769\n",
      "2025-03-10 22:46:24 [INFO]   Training MAE: 0.045151\n",
      "2025-03-10 22:46:24 [INFO]   Validation Loss: 0.002189\n",
      "2025-03-10 22:46:24 [INFO]   Validation MAE: 0.038308\n",
      "2025-03-10 22:46:31 [INFO] Epoch 64/200:\n",
      "2025-03-10 22:46:31 [INFO]   Training Loss: 0.003078\n",
      "2025-03-10 22:46:31 [INFO]   Training MAE: 0.047222\n",
      "2025-03-10 22:46:31 [INFO]   Validation Loss: 0.002726\n",
      "2025-03-10 22:46:31 [INFO]   Validation MAE: 0.047606\n",
      "2025-03-10 22:46:38 [INFO] Epoch 65/200:\n",
      "2025-03-10 22:46:38 [INFO]   Training Loss: 0.002980\n",
      "2025-03-10 22:46:38 [INFO]   Training MAE: 0.046738\n",
      "2025-03-10 22:46:38 [INFO]   Validation Loss: 0.002704\n",
      "2025-03-10 22:46:38 [INFO]   Validation MAE: 0.046306\n",
      "2025-03-10 22:46:44 [INFO] Epoch 66/200:\n",
      "2025-03-10 22:46:44 [INFO]   Training Loss: 0.002726\n",
      "2025-03-10 22:46:44 [INFO]   Training MAE: 0.045055\n",
      "2025-03-10 22:46:44 [INFO]   Validation Loss: 0.002182\n",
      "2025-03-10 22:46:44 [INFO]   Validation MAE: 0.039110\n",
      "2025-03-10 22:46:51 [INFO] Epoch 67/200:\n",
      "2025-03-10 22:46:51 [INFO]   Training Loss: 0.002712\n",
      "2025-03-10 22:46:51 [INFO]   Training MAE: 0.045007\n",
      "2025-03-10 22:46:51 [INFO]   Validation Loss: 0.002179\n",
      "2025-03-10 22:46:51 [INFO]   Validation MAE: 0.038553\n",
      "2025-03-10 22:46:58 [INFO] Epoch 68/200:\n",
      "2025-03-10 22:46:58 [INFO]   Training Loss: 0.002781\n",
      "2025-03-10 22:46:58 [INFO]   Training MAE: 0.045777\n",
      "2025-03-10 22:46:58 [INFO]   Validation Loss: 0.002054\n",
      "2025-03-10 22:46:58 [INFO]   Validation MAE: 0.036970\n",
      "2025-03-10 22:47:05 [INFO] Epoch 69/200:\n",
      "2025-03-10 22:47:05 [INFO]   Training Loss: 0.003025\n",
      "2025-03-10 22:47:05 [INFO]   Training MAE: 0.048129\n",
      "2025-03-10 22:47:05 [INFO]   Validation Loss: 0.002354\n",
      "2025-03-10 22:47:05 [INFO]   Validation MAE: 0.041838\n",
      "2025-03-10 22:47:11 [INFO] Epoch 70/200:\n",
      "2025-03-10 22:47:11 [INFO]   Training Loss: 0.002703\n",
      "2025-03-10 22:47:11 [INFO]   Training MAE: 0.044905\n",
      "2025-03-10 22:47:11 [INFO]   Validation Loss: 0.002153\n",
      "2025-03-10 22:47:11 [INFO]   Validation MAE: 0.037916\n",
      "2025-03-10 22:47:18 [INFO] Epoch 71/200:\n",
      "2025-03-10 22:47:18 [INFO]   Training Loss: 0.002577\n",
      "2025-03-10 22:47:18 [INFO]   Training MAE: 0.043492\n",
      "2025-03-10 22:47:18 [INFO]   Validation Loss: 0.002176\n",
      "2025-03-10 22:47:18 [INFO]   Validation MAE: 0.039002\n",
      "2025-03-10 22:47:25 [INFO] Epoch 72/200:\n",
      "2025-03-10 22:47:25 [INFO]   Training Loss: 0.002442\n",
      "2025-03-10 22:47:25 [INFO]   Training MAE: 0.042733\n",
      "2025-03-10 22:47:25 [INFO]   Validation Loss: 0.001997\n",
      "2025-03-10 22:47:25 [INFO]   Validation MAE: 0.034893\n",
      "2025-03-10 22:47:25 [INFO]   Saved new best model (val_loss=0.001997)\n",
      "2025-03-10 22:47:32 [INFO] Epoch 73/200:\n",
      "2025-03-10 22:47:32 [INFO]   Training Loss: 0.002500\n",
      "2025-03-10 22:47:32 [INFO]   Training MAE: 0.042584\n",
      "2025-03-10 22:47:32 [INFO]   Validation Loss: 0.002203\n",
      "2025-03-10 22:47:32 [INFO]   Validation MAE: 0.039397\n",
      "2025-03-10 22:47:39 [INFO] Epoch 74/200:\n",
      "2025-03-10 22:47:39 [INFO]   Training Loss: 0.002720\n",
      "2025-03-10 22:47:39 [INFO]   Training MAE: 0.044146\n",
      "2025-03-10 22:47:39 [INFO]   Validation Loss: 0.002387\n",
      "2025-03-10 22:47:39 [INFO]   Validation MAE: 0.040603\n",
      "2025-03-10 22:47:46 [INFO] Epoch 75/200:\n",
      "2025-03-10 22:47:46 [INFO]   Training Loss: 0.002548\n",
      "2025-03-10 22:47:46 [INFO]   Training MAE: 0.042345\n",
      "2025-03-10 22:47:46 [INFO]   Validation Loss: 0.002004\n",
      "2025-03-10 22:47:46 [INFO]   Validation MAE: 0.036406\n",
      "2025-03-10 22:47:53 [INFO] Epoch 76/200:\n",
      "2025-03-10 22:47:53 [INFO]   Training Loss: 0.002552\n",
      "2025-03-10 22:47:53 [INFO]   Training MAE: 0.043485\n",
      "2025-03-10 22:47:53 [INFO]   Validation Loss: 0.002003\n",
      "2025-03-10 22:47:53 [INFO]   Validation MAE: 0.035102\n",
      "2025-03-10 22:47:59 [INFO] Epoch 77/200:\n",
      "2025-03-10 22:47:59 [INFO]   Training Loss: 0.002566\n",
      "2025-03-10 22:47:59 [INFO]   Training MAE: 0.042862\n",
      "2025-03-10 22:47:59 [INFO]   Validation Loss: 0.001982\n",
      "2025-03-10 22:47:59 [INFO]   Validation MAE: 0.035419\n",
      "2025-03-10 22:47:59 [INFO]   Saved new best model (val_loss=0.001982)\n",
      "2025-03-10 22:48:06 [INFO] Epoch 78/200:\n",
      "2025-03-10 22:48:06 [INFO]   Training Loss: 0.002558\n",
      "2025-03-10 22:48:06 [INFO]   Training MAE: 0.043355\n",
      "2025-03-10 22:48:06 [INFO]   Validation Loss: 0.002051\n",
      "2025-03-10 22:48:06 [INFO]   Validation MAE: 0.037796\n",
      "2025-03-10 22:48:13 [INFO] Epoch 79/200:\n",
      "2025-03-10 22:48:13 [INFO]   Training Loss: 0.002625\n",
      "2025-03-10 22:48:13 [INFO]   Training MAE: 0.044587\n",
      "2025-03-10 22:48:13 [INFO]   Validation Loss: 0.001999\n",
      "2025-03-10 22:48:13 [INFO]   Validation MAE: 0.035581\n",
      "2025-03-10 22:48:20 [INFO] Epoch 80/200:\n",
      "2025-03-10 22:48:20 [INFO]   Training Loss: 0.002462\n",
      "2025-03-10 22:48:20 [INFO]   Training MAE: 0.043004\n",
      "2025-03-10 22:48:20 [INFO]   Validation Loss: 0.002135\n",
      "2025-03-10 22:48:20 [INFO]   Validation MAE: 0.038517\n",
      "2025-03-10 22:48:26 [INFO] Epoch 81/200:\n",
      "2025-03-10 22:48:26 [INFO]   Training Loss: 0.002703\n",
      "2025-03-10 22:48:26 [INFO]   Training MAE: 0.044253\n",
      "2025-03-10 22:48:26 [INFO]   Validation Loss: 0.002116\n",
      "2025-03-10 22:48:26 [INFO]   Validation MAE: 0.037254\n",
      "2025-03-10 22:48:33 [INFO] Epoch 82/200:\n",
      "2025-03-10 22:48:33 [INFO]   Training Loss: 0.002319\n",
      "2025-03-10 22:48:33 [INFO]   Training MAE: 0.040725\n",
      "2025-03-10 22:48:33 [INFO]   Validation Loss: 0.001980\n",
      "2025-03-10 22:48:33 [INFO]   Validation MAE: 0.034703\n",
      "2025-03-10 22:48:33 [INFO]   Saved new best model (val_loss=0.001980)\n",
      "2025-03-10 22:48:40 [INFO] Epoch 83/200:\n",
      "2025-03-10 22:48:40 [INFO]   Training Loss: 0.002299\n",
      "2025-03-10 22:48:40 [INFO]   Training MAE: 0.040579\n",
      "2025-03-10 22:48:40 [INFO]   Validation Loss: 0.001956\n",
      "2025-03-10 22:48:40 [INFO]   Validation MAE: 0.035724\n",
      "2025-03-10 22:48:40 [INFO]   Saved new best model (val_loss=0.001956)\n",
      "2025-03-10 22:48:47 [INFO] Epoch 84/200:\n",
      "2025-03-10 22:48:47 [INFO]   Training Loss: 0.002344\n",
      "2025-03-10 22:48:47 [INFO]   Training MAE: 0.041389\n",
      "2025-03-10 22:48:47 [INFO]   Validation Loss: 0.001983\n",
      "2025-03-10 22:48:47 [INFO]   Validation MAE: 0.034841\n",
      "2025-03-10 22:48:53 [INFO] Epoch 85/200:\n",
      "2025-03-10 22:48:53 [INFO]   Training Loss: 0.002613\n",
      "2025-03-10 22:48:53 [INFO]   Training MAE: 0.043345\n",
      "2025-03-10 22:48:53 [INFO]   Validation Loss: 0.002036\n",
      "2025-03-10 22:48:53 [INFO]   Validation MAE: 0.034836\n",
      "2025-03-10 22:49:00 [INFO] Epoch 86/200:\n",
      "2025-03-10 22:49:00 [INFO]   Training Loss: 0.002862\n",
      "2025-03-10 22:49:00 [INFO]   Training MAE: 0.045323\n",
      "2025-03-10 22:49:00 [INFO]   Validation Loss: 0.002014\n",
      "2025-03-10 22:49:00 [INFO]   Validation MAE: 0.035508\n",
      "2025-03-10 22:49:07 [INFO] Epoch 87/200:\n",
      "2025-03-10 22:49:07 [INFO]   Training Loss: 0.002428\n",
      "2025-03-10 22:49:07 [INFO]   Training MAE: 0.042023\n",
      "2025-03-10 22:49:07 [INFO]   Validation Loss: 0.002054\n",
      "2025-03-10 22:49:07 [INFO]   Validation MAE: 0.037519\n",
      "2025-03-10 22:49:14 [INFO] Epoch 88/200:\n",
      "2025-03-10 22:49:14 [INFO]   Training Loss: 0.002353\n",
      "2025-03-10 22:49:14 [INFO]   Training MAE: 0.041157\n",
      "2025-03-10 22:49:14 [INFO]   Validation Loss: 0.001958\n",
      "2025-03-10 22:49:14 [INFO]   Validation MAE: 0.035808\n",
      "2025-03-10 22:49:20 [INFO] Epoch 89/200:\n",
      "2025-03-10 22:49:20 [INFO]   Training Loss: 0.002384\n",
      "2025-03-10 22:49:20 [INFO]   Training MAE: 0.041974\n",
      "2025-03-10 22:49:20 [INFO]   Validation Loss: 0.001943\n",
      "2025-03-10 22:49:20 [INFO]   Validation MAE: 0.034184\n",
      "2025-03-10 22:49:20 [INFO]   Saved new best model (val_loss=0.001943)\n",
      "2025-03-10 22:49:27 [INFO] Epoch 90/200:\n",
      "2025-03-10 22:49:27 [INFO]   Training Loss: 0.002301\n",
      "2025-03-10 22:49:27 [INFO]   Training MAE: 0.040816\n",
      "2025-03-10 22:49:27 [INFO]   Validation Loss: 0.001902\n",
      "2025-03-10 22:49:27 [INFO]   Validation MAE: 0.033708\n",
      "2025-03-10 22:49:27 [INFO]   Saved new best model (val_loss=0.001902)\n",
      "2025-03-10 22:49:34 [INFO] Epoch 91/200:\n",
      "2025-03-10 22:49:34 [INFO]   Training Loss: 0.002448\n",
      "2025-03-10 22:49:34 [INFO]   Training MAE: 0.042166\n",
      "2025-03-10 22:49:34 [INFO]   Validation Loss: 0.002347\n",
      "2025-03-10 22:49:34 [INFO]   Validation MAE: 0.040307\n",
      "2025-03-10 22:49:41 [INFO] Epoch 92/200:\n",
      "2025-03-10 22:49:41 [INFO]   Training Loss: 0.002476\n",
      "2025-03-10 22:49:41 [INFO]   Training MAE: 0.042769\n",
      "2025-03-10 22:49:41 [INFO]   Validation Loss: 0.002065\n",
      "2025-03-10 22:49:41 [INFO]   Validation MAE: 0.036885\n",
      "2025-03-10 22:49:48 [INFO] Epoch 93/200:\n",
      "2025-03-10 22:49:48 [INFO]   Training Loss: 0.002374\n",
      "2025-03-10 22:49:48 [INFO]   Training MAE: 0.041243\n",
      "2025-03-10 22:49:48 [INFO]   Validation Loss: 0.001918\n",
      "2025-03-10 22:49:48 [INFO]   Validation MAE: 0.035492\n",
      "2025-03-10 22:49:54 [INFO] Epoch 94/200:\n",
      "2025-03-10 22:49:54 [INFO]   Training Loss: 0.002703\n",
      "2025-03-10 22:49:54 [INFO]   Training MAE: 0.042356\n",
      "2025-03-10 22:49:54 [INFO]   Validation Loss: 0.002317\n",
      "2025-03-10 22:49:54 [INFO]   Validation MAE: 0.044035\n",
      "2025-03-10 22:50:01 [INFO] Epoch 95/200:\n",
      "2025-03-10 22:50:01 [INFO]   Training Loss: 0.002240\n",
      "2025-03-10 22:50:01 [INFO]   Training MAE: 0.039879\n",
      "2025-03-10 22:50:01 [INFO]   Validation Loss: 0.002068\n",
      "2025-03-10 22:50:01 [INFO]   Validation MAE: 0.037532\n",
      "2025-03-10 22:50:08 [INFO] Epoch 96/200:\n",
      "2025-03-10 22:50:08 [INFO]   Training Loss: 0.002171\n",
      "2025-03-10 22:50:08 [INFO]   Training MAE: 0.039948\n",
      "2025-03-10 22:50:08 [INFO]   Validation Loss: 0.001994\n",
      "2025-03-10 22:50:08 [INFO]   Validation MAE: 0.036670\n",
      "2025-03-10 22:50:15 [INFO] Epoch 97/200:\n",
      "2025-03-10 22:50:15 [INFO]   Training Loss: 0.002312\n",
      "2025-03-10 22:50:15 [INFO]   Training MAE: 0.040694\n",
      "2025-03-10 22:50:15 [INFO]   Validation Loss: 0.001965\n",
      "2025-03-10 22:50:15 [INFO]   Validation MAE: 0.035970\n",
      "2025-03-10 22:50:21 [INFO] Epoch 98/200:\n",
      "2025-03-10 22:50:21 [INFO]   Training Loss: 0.002994\n",
      "2025-03-10 22:50:21 [INFO]   Training MAE: 0.045391\n",
      "2025-03-10 22:50:21 [INFO]   Validation Loss: 0.002964\n",
      "2025-03-10 22:50:21 [INFO]   Validation MAE: 0.053201\n",
      "2025-03-10 22:50:28 [INFO] Epoch 99/200:\n",
      "2025-03-10 22:50:28 [INFO]   Training Loss: 0.002515\n",
      "2025-03-10 22:50:28 [INFO]   Training MAE: 0.044327\n",
      "2025-03-10 22:50:28 [INFO]   Validation Loss: 0.001900\n",
      "2025-03-10 22:50:28 [INFO]   Validation MAE: 0.035676\n",
      "2025-03-10 22:50:28 [INFO]   Saved new best model (val_loss=0.001900)\n",
      "2025-03-10 22:50:35 [INFO] Epoch 100/200:\n",
      "2025-03-10 22:50:35 [INFO]   Training Loss: 0.002352\n",
      "2025-03-10 22:50:35 [INFO]   Training MAE: 0.041174\n",
      "2025-03-10 22:50:35 [INFO]   Validation Loss: 0.001927\n",
      "2025-03-10 22:50:35 [INFO]   Validation MAE: 0.035361\n",
      "2025-03-10 22:50:42 [INFO] Epoch 101/200:\n",
      "2025-03-10 22:50:42 [INFO]   Training Loss: 0.002394\n",
      "2025-03-10 22:50:42 [INFO]   Training MAE: 0.040783\n",
      "2025-03-10 22:50:42 [INFO]   Validation Loss: 0.001969\n",
      "2025-03-10 22:50:42 [INFO]   Validation MAE: 0.036049\n",
      "2025-03-10 22:50:48 [INFO] Epoch 102/200:\n",
      "2025-03-10 22:50:48 [INFO]   Training Loss: 0.002328\n",
      "2025-03-10 22:50:48 [INFO]   Training MAE: 0.040469\n",
      "2025-03-10 22:50:48 [INFO]   Validation Loss: 0.001828\n",
      "2025-03-10 22:50:48 [INFO]   Validation MAE: 0.032580\n",
      "2025-03-10 22:50:49 [INFO]   Saved new best model (val_loss=0.001828)\n",
      "2025-03-10 22:50:55 [INFO] Epoch 103/200:\n",
      "2025-03-10 22:50:55 [INFO]   Training Loss: 0.002252\n",
      "2025-03-10 22:50:55 [INFO]   Training MAE: 0.040369\n",
      "2025-03-10 22:50:55 [INFO]   Validation Loss: 0.002066\n",
      "2025-03-10 22:50:55 [INFO]   Validation MAE: 0.037892\n",
      "2025-03-10 22:51:02 [INFO] Epoch 104/200:\n",
      "2025-03-10 22:51:02 [INFO]   Training Loss: 0.002376\n",
      "2025-03-10 22:51:02 [INFO]   Training MAE: 0.041651\n",
      "2025-03-10 22:51:02 [INFO]   Validation Loss: 0.001897\n",
      "2025-03-10 22:51:02 [INFO]   Validation MAE: 0.034359\n",
      "2025-03-10 22:51:09 [INFO] Epoch 105/200:\n",
      "2025-03-10 22:51:09 [INFO]   Training Loss: 0.002197\n",
      "2025-03-10 22:51:09 [INFO]   Training MAE: 0.039283\n",
      "2025-03-10 22:51:09 [INFO]   Validation Loss: 0.002026\n",
      "2025-03-10 22:51:09 [INFO]   Validation MAE: 0.038502\n",
      "2025-03-10 22:51:15 [INFO] Epoch 106/200:\n",
      "2025-03-10 22:51:15 [INFO]   Training Loss: 0.002034\n",
      "2025-03-10 22:51:15 [INFO]   Training MAE: 0.038682\n",
      "2025-03-10 22:51:15 [INFO]   Validation Loss: 0.001882\n",
      "2025-03-10 22:51:15 [INFO]   Validation MAE: 0.034517\n",
      "2025-03-10 22:51:22 [INFO] Epoch 107/200:\n",
      "2025-03-10 22:51:22 [INFO]   Training Loss: 0.002220\n",
      "2025-03-10 22:51:22 [INFO]   Training MAE: 0.039936\n",
      "2025-03-10 22:51:22 [INFO]   Validation Loss: 0.001928\n",
      "2025-03-10 22:51:22 [INFO]   Validation MAE: 0.036146\n",
      "2025-03-10 22:51:29 [INFO] Epoch 108/200:\n",
      "2025-03-10 22:51:29 [INFO]   Training Loss: 0.002094\n",
      "2025-03-10 22:51:29 [INFO]   Training MAE: 0.039174\n",
      "2025-03-10 22:51:29 [INFO]   Validation Loss: 0.001836\n",
      "2025-03-10 22:51:29 [INFO]   Validation MAE: 0.033855\n",
      "2025-03-10 22:51:35 [INFO] Epoch 109/200:\n",
      "2025-03-10 22:51:35 [INFO]   Training Loss: 0.002193\n",
      "2025-03-10 22:51:35 [INFO]   Training MAE: 0.040043\n",
      "2025-03-10 22:51:35 [INFO]   Validation Loss: 0.001799\n",
      "2025-03-10 22:51:35 [INFO]   Validation MAE: 0.032276\n",
      "2025-03-10 22:51:36 [INFO]   Saved new best model (val_loss=0.001799)\n",
      "2025-03-10 22:51:42 [INFO] Epoch 110/200:\n",
      "2025-03-10 22:51:42 [INFO]   Training Loss: 0.002167\n",
      "2025-03-10 22:51:42 [INFO]   Training MAE: 0.039810\n",
      "2025-03-10 22:51:42 [INFO]   Validation Loss: 0.001895\n",
      "2025-03-10 22:51:42 [INFO]   Validation MAE: 0.033813\n",
      "2025-03-10 22:51:49 [INFO] Epoch 111/200:\n",
      "2025-03-10 22:51:49 [INFO]   Training Loss: 0.002063\n",
      "2025-03-10 22:51:49 [INFO]   Training MAE: 0.038453\n",
      "2025-03-10 22:51:49 [INFO]   Validation Loss: 0.002101\n",
      "2025-03-10 22:51:49 [INFO]   Validation MAE: 0.038025\n",
      "2025-03-10 22:51:56 [INFO] Epoch 112/200:\n",
      "2025-03-10 22:51:56 [INFO]   Training Loss: 0.002085\n",
      "2025-03-10 22:51:56 [INFO]   Training MAE: 0.038721\n",
      "2025-03-10 22:51:56 [INFO]   Validation Loss: 0.001913\n",
      "2025-03-10 22:51:56 [INFO]   Validation MAE: 0.034414\n",
      "2025-03-10 22:52:03 [INFO] Epoch 113/200:\n",
      "2025-03-10 22:52:03 [INFO]   Training Loss: 0.002113\n",
      "2025-03-10 22:52:03 [INFO]   Training MAE: 0.039214\n",
      "2025-03-10 22:52:03 [INFO]   Validation Loss: 0.001867\n",
      "2025-03-10 22:52:03 [INFO]   Validation MAE: 0.033990\n",
      "2025-03-10 22:52:09 [INFO] Epoch 114/200:\n",
      "2025-03-10 22:52:09 [INFO]   Training Loss: 0.002155\n",
      "2025-03-10 22:52:09 [INFO]   Training MAE: 0.039601\n",
      "2025-03-10 22:52:09 [INFO]   Validation Loss: 0.002246\n",
      "2025-03-10 22:52:09 [INFO]   Validation MAE: 0.040948\n",
      "2025-03-10 22:52:16 [INFO] Epoch 115/200:\n",
      "2025-03-10 22:52:16 [INFO]   Training Loss: 0.002174\n",
      "2025-03-10 22:52:16 [INFO]   Training MAE: 0.039508\n",
      "2025-03-10 22:52:16 [INFO]   Validation Loss: 0.001996\n",
      "2025-03-10 22:52:16 [INFO]   Validation MAE: 0.036709\n",
      "2025-03-10 22:52:23 [INFO] Epoch 116/200:\n",
      "2025-03-10 22:52:23 [INFO]   Training Loss: 0.002057\n",
      "2025-03-10 22:52:23 [INFO]   Training MAE: 0.038513\n",
      "2025-03-10 22:52:23 [INFO]   Validation Loss: 0.002361\n",
      "2025-03-10 22:52:23 [INFO]   Validation MAE: 0.042236\n",
      "2025-03-10 22:52:29 [INFO] Epoch 117/200:\n",
      "2025-03-10 22:52:29 [INFO]   Training Loss: 0.002190\n",
      "2025-03-10 22:52:29 [INFO]   Training MAE: 0.038309\n",
      "2025-03-10 22:52:29 [INFO]   Validation Loss: 0.002221\n",
      "2025-03-10 22:52:29 [INFO]   Validation MAE: 0.041039\n",
      "2025-03-10 22:52:36 [INFO] Epoch 118/200:\n",
      "2025-03-10 22:52:36 [INFO]   Training Loss: 0.002115\n",
      "2025-03-10 22:52:36 [INFO]   Training MAE: 0.038831\n",
      "2025-03-10 22:52:36 [INFO]   Validation Loss: 0.001836\n",
      "2025-03-10 22:52:36 [INFO]   Validation MAE: 0.033253\n",
      "2025-03-10 22:52:43 [INFO] Epoch 119/200:\n",
      "2025-03-10 22:52:43 [INFO]   Training Loss: 0.002197\n",
      "2025-03-10 22:52:43 [INFO]   Training MAE: 0.039736\n",
      "2025-03-10 22:52:43 [INFO]   Validation Loss: 0.001895\n",
      "2025-03-10 22:52:43 [INFO]   Validation MAE: 0.034493\n",
      "2025-03-10 22:52:49 [INFO] Epoch 120/200:\n",
      "2025-03-10 22:52:49 [INFO]   Training Loss: 0.002134\n",
      "2025-03-10 22:52:49 [INFO]   Training MAE: 0.037896\n",
      "2025-03-10 22:52:49 [INFO]   Validation Loss: 0.001840\n",
      "2025-03-10 22:52:49 [INFO]   Validation MAE: 0.033427\n",
      "2025-03-10 22:52:56 [INFO] Epoch 121/200:\n",
      "2025-03-10 22:52:56 [INFO]   Training Loss: 0.002064\n",
      "2025-03-10 22:52:56 [INFO]   Training MAE: 0.038485\n",
      "2025-03-10 22:52:56 [INFO]   Validation Loss: 0.001891\n",
      "2025-03-10 22:52:56 [INFO]   Validation MAE: 0.034415\n",
      "2025-03-10 22:53:03 [INFO] Epoch 122/200:\n",
      "2025-03-10 22:53:03 [INFO]   Training Loss: 0.002068\n",
      "2025-03-10 22:53:03 [INFO]   Training MAE: 0.038550\n",
      "2025-03-10 22:53:03 [INFO]   Validation Loss: 0.001939\n",
      "2025-03-10 22:53:03 [INFO]   Validation MAE: 0.036083\n",
      "2025-03-10 22:53:09 [INFO] Epoch 123/200:\n",
      "2025-03-10 22:53:09 [INFO]   Training Loss: 0.002257\n",
      "2025-03-10 22:53:09 [INFO]   Training MAE: 0.039338\n",
      "2025-03-10 22:53:09 [INFO]   Validation Loss: 0.001802\n",
      "2025-03-10 22:53:09 [INFO]   Validation MAE: 0.032831\n",
      "2025-03-10 22:53:16 [INFO] Epoch 124/200:\n",
      "2025-03-10 22:53:16 [INFO]   Training Loss: 0.002148\n",
      "2025-03-10 22:53:16 [INFO]   Training MAE: 0.039025\n",
      "2025-03-10 22:53:16 [INFO]   Validation Loss: 0.001778\n",
      "2025-03-10 22:53:16 [INFO]   Validation MAE: 0.033079\n",
      "2025-03-10 22:53:16 [INFO]   Saved new best model (val_loss=0.001778)\n",
      "2025-03-10 22:53:23 [INFO] Epoch 125/200:\n",
      "2025-03-10 22:53:23 [INFO]   Training Loss: 0.002060\n",
      "2025-03-10 22:53:23 [INFO]   Training MAE: 0.038076\n",
      "2025-03-10 22:53:23 [INFO]   Validation Loss: 0.001971\n",
      "2025-03-10 22:53:23 [INFO]   Validation MAE: 0.036875\n",
      "2025-03-10 22:53:29 [INFO] Epoch 126/200:\n",
      "2025-03-10 22:53:29 [INFO]   Training Loss: 0.002071\n",
      "2025-03-10 22:53:29 [INFO]   Training MAE: 0.038104\n",
      "2025-03-10 22:53:29 [INFO]   Validation Loss: 0.001838\n",
      "2025-03-10 22:53:29 [INFO]   Validation MAE: 0.034580\n",
      "2025-03-10 22:53:36 [INFO] Epoch 127/200:\n",
      "2025-03-10 22:53:36 [INFO]   Training Loss: 0.002089\n",
      "2025-03-10 22:53:36 [INFO]   Training MAE: 0.038550\n",
      "2025-03-10 22:53:36 [INFO]   Validation Loss: 0.001870\n",
      "2025-03-10 22:53:36 [INFO]   Validation MAE: 0.035007\n",
      "2025-03-10 22:53:43 [INFO] Epoch 128/200:\n",
      "2025-03-10 22:53:43 [INFO]   Training Loss: 0.002028\n",
      "2025-03-10 22:53:43 [INFO]   Training MAE: 0.037341\n",
      "2025-03-10 22:53:43 [INFO]   Validation Loss: 0.001957\n",
      "2025-03-10 22:53:43 [INFO]   Validation MAE: 0.036366\n",
      "2025-03-10 22:53:49 [INFO] Epoch 129/200:\n",
      "2025-03-10 22:53:49 [INFO]   Training Loss: 0.002021\n",
      "2025-03-10 22:53:49 [INFO]   Training MAE: 0.037625\n",
      "2025-03-10 22:53:49 [INFO]   Validation Loss: 0.001865\n",
      "2025-03-10 22:53:49 [INFO]   Validation MAE: 0.034603\n",
      "2025-03-10 22:53:56 [INFO] Epoch 130/200:\n",
      "2025-03-10 22:53:56 [INFO]   Training Loss: 0.002078\n",
      "2025-03-10 22:53:56 [INFO]   Training MAE: 0.038528\n",
      "2025-03-10 22:53:56 [INFO]   Validation Loss: 0.001885\n",
      "2025-03-10 22:53:56 [INFO]   Validation MAE: 0.034679\n",
      "2025-03-10 22:54:03 [INFO] Epoch 131/200:\n",
      "2025-03-10 22:54:03 [INFO]   Training Loss: 0.001988\n",
      "2025-03-10 22:54:03 [INFO]   Training MAE: 0.037367\n",
      "2025-03-10 22:54:03 [INFO]   Validation Loss: 0.001810\n",
      "2025-03-10 22:54:03 [INFO]   Validation MAE: 0.033628\n",
      "2025-03-10 22:54:09 [INFO] Epoch 132/200:\n",
      "2025-03-10 22:54:09 [INFO]   Training Loss: 0.001990\n",
      "2025-03-10 22:54:09 [INFO]   Training MAE: 0.037535\n",
      "2025-03-10 22:54:09 [INFO]   Validation Loss: 0.001756\n",
      "2025-03-10 22:54:09 [INFO]   Validation MAE: 0.032240\n",
      "2025-03-10 22:54:09 [INFO]   Saved new best model (val_loss=0.001756)\n",
      "2025-03-10 22:54:16 [INFO] Epoch 133/200:\n",
      "2025-03-10 22:54:16 [INFO]   Training Loss: 0.002097\n",
      "2025-03-10 22:54:16 [INFO]   Training MAE: 0.038850\n",
      "2025-03-10 22:54:16 [INFO]   Validation Loss: 0.001948\n",
      "2025-03-10 22:54:16 [INFO]   Validation MAE: 0.036466\n",
      "2025-03-10 22:54:23 [INFO] Epoch 134/200:\n",
      "2025-03-10 22:54:23 [INFO]   Training Loss: 0.002078\n",
      "2025-03-10 22:54:23 [INFO]   Training MAE: 0.038191\n",
      "2025-03-10 22:54:23 [INFO]   Validation Loss: 0.002004\n",
      "2025-03-10 22:54:23 [INFO]   Validation MAE: 0.037025\n",
      "2025-03-10 22:54:30 [INFO] Epoch 135/200:\n",
      "2025-03-10 22:54:30 [INFO]   Training Loss: 0.002095\n",
      "2025-03-10 22:54:30 [INFO]   Training MAE: 0.038932\n",
      "2025-03-10 22:54:30 [INFO]   Validation Loss: 0.001763\n",
      "2025-03-10 22:54:30 [INFO]   Validation MAE: 0.032025\n",
      "2025-03-10 22:54:36 [INFO] Epoch 136/200:\n",
      "2025-03-10 22:54:36 [INFO]   Training Loss: 0.002006\n",
      "2025-03-10 22:54:36 [INFO]   Training MAE: 0.037540\n",
      "2025-03-10 22:54:36 [INFO]   Validation Loss: 0.001836\n",
      "2025-03-10 22:54:36 [INFO]   Validation MAE: 0.034304\n",
      "2025-03-10 22:54:43 [INFO] Epoch 137/200:\n",
      "2025-03-10 22:54:43 [INFO]   Training Loss: 0.002084\n",
      "2025-03-10 22:54:43 [INFO]   Training MAE: 0.038866\n",
      "2025-03-10 22:54:43 [INFO]   Validation Loss: 0.001918\n",
      "2025-03-10 22:54:43 [INFO]   Validation MAE: 0.035664\n",
      "2025-03-10 22:54:50 [INFO] Epoch 138/200:\n",
      "2025-03-10 22:54:50 [INFO]   Training Loss: 0.002045\n",
      "2025-03-10 22:54:50 [INFO]   Training MAE: 0.037580\n",
      "2025-03-10 22:54:50 [INFO]   Validation Loss: 0.001803\n",
      "2025-03-10 22:54:50 [INFO]   Validation MAE: 0.033457\n",
      "2025-03-10 22:54:56 [INFO] Epoch 139/200:\n",
      "2025-03-10 22:54:56 [INFO]   Training Loss: 0.002002\n",
      "2025-03-10 22:54:56 [INFO]   Training MAE: 0.036655\n",
      "2025-03-10 22:54:56 [INFO]   Validation Loss: 0.001989\n",
      "2025-03-10 22:54:56 [INFO]   Validation MAE: 0.036832\n",
      "2025-03-10 22:55:03 [INFO] Epoch 140/200:\n",
      "2025-03-10 22:55:03 [INFO]   Training Loss: 0.002063\n",
      "2025-03-10 22:55:03 [INFO]   Training MAE: 0.037901\n",
      "2025-03-10 22:55:03 [INFO]   Validation Loss: 0.001798\n",
      "2025-03-10 22:55:03 [INFO]   Validation MAE: 0.033313\n",
      "2025-03-10 22:55:10 [INFO] Epoch 141/200:\n",
      "2025-03-10 22:55:10 [INFO]   Training Loss: 0.002219\n",
      "2025-03-10 22:55:10 [INFO]   Training MAE: 0.039144\n",
      "2025-03-10 22:55:10 [INFO]   Validation Loss: 0.002195\n",
      "2025-03-10 22:55:10 [INFO]   Validation MAE: 0.040054\n",
      "2025-03-10 22:55:17 [INFO] Epoch 142/200:\n",
      "2025-03-10 22:55:17 [INFO]   Training Loss: 0.002405\n",
      "2025-03-10 22:55:17 [INFO]   Training MAE: 0.041845\n",
      "2025-03-10 22:55:17 [INFO]   Validation Loss: 0.002433\n",
      "2025-03-10 22:55:17 [INFO]   Validation MAE: 0.041156\n",
      "2025-03-10 22:55:23 [INFO] Epoch 143/200:\n",
      "2025-03-10 22:55:23 [INFO]   Training Loss: 0.002374\n",
      "2025-03-10 22:55:23 [INFO]   Training MAE: 0.040906\n",
      "2025-03-10 22:55:23 [INFO]   Validation Loss: 0.001958\n",
      "2025-03-10 22:55:23 [INFO]   Validation MAE: 0.034055\n",
      "2025-03-10 22:55:30 [INFO] Epoch 144/200:\n",
      "2025-03-10 22:55:30 [INFO]   Training Loss: 0.002126\n",
      "2025-03-10 22:55:30 [INFO]   Training MAE: 0.038723\n",
      "2025-03-10 22:55:30 [INFO]   Validation Loss: 0.001919\n",
      "2025-03-10 22:55:30 [INFO]   Validation MAE: 0.033800\n",
      "2025-03-10 22:55:37 [INFO] Epoch 145/200:\n",
      "2025-03-10 22:55:37 [INFO]   Training Loss: 0.002377\n",
      "2025-03-10 22:55:37 [INFO]   Training MAE: 0.041613\n",
      "2025-03-10 22:55:37 [INFO]   Validation Loss: 0.002027\n",
      "2025-03-10 22:55:37 [INFO]   Validation MAE: 0.035989\n",
      "2025-03-10 22:55:43 [INFO] Epoch 146/200:\n",
      "2025-03-10 22:55:43 [INFO]   Training Loss: 0.002099\n",
      "2025-03-10 22:55:43 [INFO]   Training MAE: 0.038770\n",
      "2025-03-10 22:55:43 [INFO]   Validation Loss: 0.001841\n",
      "2025-03-10 22:55:43 [INFO]   Validation MAE: 0.033548\n",
      "2025-03-10 22:55:50 [INFO] Epoch 147/200:\n",
      "2025-03-10 22:55:50 [INFO]   Training Loss: 0.002162\n",
      "2025-03-10 22:55:50 [INFO]   Training MAE: 0.039187\n",
      "2025-03-10 22:55:50 [INFO]   Validation Loss: 0.001859\n",
      "2025-03-10 22:55:50 [INFO]   Validation MAE: 0.033932\n",
      "2025-03-10 22:55:57 [INFO] Epoch 148/200:\n",
      "2025-03-10 22:55:57 [INFO]   Training Loss: 0.002364\n",
      "2025-03-10 22:55:57 [INFO]   Training MAE: 0.041376\n",
      "2025-03-10 22:55:57 [INFO]   Validation Loss: 0.002323\n",
      "2025-03-10 22:55:57 [INFO]   Validation MAE: 0.040489\n",
      "2025-03-10 22:56:03 [INFO] Epoch 149/200:\n",
      "2025-03-10 22:56:03 [INFO]   Training Loss: 0.002434\n",
      "2025-03-10 22:56:03 [INFO]   Training MAE: 0.041698\n",
      "2025-03-10 22:56:03 [INFO]   Validation Loss: 0.001941\n",
      "2025-03-10 22:56:03 [INFO]   Validation MAE: 0.032560\n",
      "2025-03-10 22:56:10 [INFO] Epoch 150/200:\n",
      "2025-03-10 22:56:10 [INFO]   Training Loss: 0.002368\n",
      "2025-03-10 22:56:10 [INFO]   Training MAE: 0.040938\n",
      "2025-03-10 22:56:10 [INFO]   Validation Loss: 0.002190\n",
      "2025-03-10 22:56:10 [INFO]   Validation MAE: 0.037082\n",
      "2025-03-10 22:56:17 [INFO] Epoch 151/200:\n",
      "2025-03-10 22:56:17 [INFO]   Training Loss: 0.002161\n",
      "2025-03-10 22:56:17 [INFO]   Training MAE: 0.038695\n",
      "2025-03-10 22:56:17 [INFO]   Validation Loss: 0.001928\n",
      "2025-03-10 22:56:17 [INFO]   Validation MAE: 0.035911\n",
      "2025-03-10 22:56:23 [INFO] Epoch 152/200:\n",
      "2025-03-10 22:56:23 [INFO]   Training Loss: 0.002263\n",
      "2025-03-10 22:56:23 [INFO]   Training MAE: 0.040598\n",
      "2025-03-10 22:56:23 [INFO]   Validation Loss: 0.001909\n",
      "2025-03-10 22:56:23 [INFO]   Validation MAE: 0.035043\n",
      "2025-03-10 22:56:30 [INFO] Epoch 153/200:\n",
      "2025-03-10 22:56:30 [INFO]   Training Loss: 0.002301\n",
      "2025-03-10 22:56:30 [INFO]   Training MAE: 0.040082\n",
      "2025-03-10 22:56:30 [INFO]   Validation Loss: 0.002108\n",
      "2025-03-10 22:56:30 [INFO]   Validation MAE: 0.037159\n",
      "2025-03-10 22:56:37 [INFO] Epoch 154/200:\n",
      "2025-03-10 22:56:37 [INFO]   Training Loss: 0.002317\n",
      "2025-03-10 22:56:37 [INFO]   Training MAE: 0.040807\n",
      "2025-03-10 22:56:37 [INFO]   Validation Loss: 0.002023\n",
      "2025-03-10 22:56:37 [INFO]   Validation MAE: 0.035572\n",
      "2025-03-10 22:56:43 [INFO] Epoch 155/200:\n",
      "2025-03-10 22:56:43 [INFO]   Training Loss: 0.002511\n",
      "2025-03-10 22:56:43 [INFO]   Training MAE: 0.044001\n",
      "2025-03-10 22:56:43 [INFO]   Validation Loss: 0.001854\n",
      "2025-03-10 22:56:43 [INFO]   Validation MAE: 0.032174\n",
      "2025-03-10 22:56:50 [INFO] Epoch 156/200:\n",
      "2025-03-10 22:56:50 [INFO]   Training Loss: 0.002312\n",
      "2025-03-10 22:56:50 [INFO]   Training MAE: 0.040668\n",
      "2025-03-10 22:56:50 [INFO]   Validation Loss: 0.002077\n",
      "2025-03-10 22:56:50 [INFO]   Validation MAE: 0.036262\n",
      "2025-03-10 22:56:57 [INFO] Epoch 157/200:\n",
      "2025-03-10 22:56:57 [INFO]   Training Loss: 0.002314\n",
      "2025-03-10 22:56:57 [INFO]   Training MAE: 0.040964\n",
      "2025-03-10 22:56:57 [INFO]   Validation Loss: 0.001930\n",
      "2025-03-10 22:56:57 [INFO]   Validation MAE: 0.033377\n",
      "2025-03-10 22:57:04 [INFO] Epoch 158/200:\n",
      "2025-03-10 22:57:04 [INFO]   Training Loss: 0.002608\n",
      "2025-03-10 22:57:04 [INFO]   Training MAE: 0.044005\n",
      "2025-03-10 22:57:04 [INFO]   Validation Loss: 0.001873\n",
      "2025-03-10 22:57:04 [INFO]   Validation MAE: 0.031808\n",
      "2025-03-10 22:57:10 [INFO] Epoch 159/200:\n",
      "2025-03-10 22:57:10 [INFO]   Training Loss: 0.002318\n",
      "2025-03-10 22:57:10 [INFO]   Training MAE: 0.040627\n",
      "2025-03-10 22:57:10 [INFO]   Validation Loss: 0.002023\n",
      "2025-03-10 22:57:10 [INFO]   Validation MAE: 0.035381\n",
      "2025-03-10 22:57:17 [INFO] Epoch 160/200:\n",
      "2025-03-10 22:57:17 [INFO]   Training Loss: 0.002355\n",
      "2025-03-10 22:57:17 [INFO]   Training MAE: 0.040286\n",
      "2025-03-10 22:57:17 [INFO]   Validation Loss: 0.002245\n",
      "2025-03-10 22:57:17 [INFO]   Validation MAE: 0.041138\n",
      "2025-03-10 22:57:24 [INFO] Epoch 161/200:\n",
      "2025-03-10 22:57:24 [INFO]   Training Loss: 0.002374\n",
      "2025-03-10 22:57:24 [INFO]   Training MAE: 0.042220\n",
      "2025-03-10 22:57:24 [INFO]   Validation Loss: 0.002556\n",
      "2025-03-10 22:57:24 [INFO]   Validation MAE: 0.043687\n",
      "2025-03-10 22:57:31 [INFO] Epoch 162/200:\n",
      "2025-03-10 22:57:31 [INFO]   Training Loss: 0.002443\n",
      "2025-03-10 22:57:31 [INFO]   Training MAE: 0.042197\n",
      "2025-03-10 22:57:31 [INFO]   Validation Loss: 0.001930\n",
      "2025-03-10 22:57:31 [INFO]   Validation MAE: 0.033204\n",
      "2025-03-10 22:57:37 [INFO] Epoch 163/200:\n",
      "2025-03-10 22:57:37 [INFO]   Training Loss: 0.002318\n",
      "2025-03-10 22:57:37 [INFO]   Training MAE: 0.041428\n",
      "2025-03-10 22:57:37 [INFO]   Validation Loss: 0.001866\n",
      "2025-03-10 22:57:37 [INFO]   Validation MAE: 0.032880\n",
      "2025-03-10 22:57:44 [INFO] Epoch 164/200:\n",
      "2025-03-10 22:57:44 [INFO]   Training Loss: 0.002337\n",
      "2025-03-10 22:57:44 [INFO]   Training MAE: 0.040626\n",
      "2025-03-10 22:57:44 [INFO]   Validation Loss: 0.002231\n",
      "2025-03-10 22:57:44 [INFO]   Validation MAE: 0.039737\n",
      "2025-03-10 22:57:51 [INFO] Epoch 165/200:\n",
      "2025-03-10 22:57:51 [INFO]   Training Loss: 0.002432\n",
      "2025-03-10 22:57:51 [INFO]   Training MAE: 0.042021\n",
      "2025-03-10 22:57:51 [INFO]   Validation Loss: 0.002020\n",
      "2025-03-10 22:57:51 [INFO]   Validation MAE: 0.036294\n",
      "2025-03-10 22:57:57 [INFO] Epoch 166/200:\n",
      "2025-03-10 22:57:57 [INFO]   Training Loss: 0.002524\n",
      "2025-03-10 22:57:57 [INFO]   Training MAE: 0.043383\n",
      "2025-03-10 22:57:57 [INFO]   Validation Loss: 0.001904\n",
      "2025-03-10 22:57:57 [INFO]   Validation MAE: 0.032603\n",
      "2025-03-10 22:58:04 [INFO] Epoch 167/200:\n",
      "2025-03-10 22:58:04 [INFO]   Training Loss: 0.002313\n",
      "2025-03-10 22:58:04 [INFO]   Training MAE: 0.041618\n",
      "2025-03-10 22:58:04 [INFO]   Validation Loss: 0.002129\n",
      "2025-03-10 22:58:04 [INFO]   Validation MAE: 0.037631\n",
      "2025-03-10 22:58:11 [INFO] Epoch 168/200:\n",
      "2025-03-10 22:58:11 [INFO]   Training Loss: 0.002098\n",
      "2025-03-10 22:58:11 [INFO]   Training MAE: 0.039651\n",
      "2025-03-10 22:58:11 [INFO]   Validation Loss: 0.001995\n",
      "2025-03-10 22:58:11 [INFO]   Validation MAE: 0.034894\n",
      "2025-03-10 22:58:17 [INFO] Epoch 169/200:\n",
      "2025-03-10 22:58:17 [INFO]   Training Loss: 0.002263\n",
      "2025-03-10 22:58:17 [INFO]   Training MAE: 0.039873\n",
      "2025-03-10 22:58:17 [INFO]   Validation Loss: 0.001941\n",
      "2025-03-10 22:58:17 [INFO]   Validation MAE: 0.035383\n",
      "2025-03-10 22:58:24 [INFO] Epoch 170/200:\n",
      "2025-03-10 22:58:24 [INFO]   Training Loss: 0.002144\n",
      "2025-03-10 22:58:24 [INFO]   Training MAE: 0.039333\n",
      "2025-03-10 22:58:24 [INFO]   Validation Loss: 0.001998\n",
      "2025-03-10 22:58:24 [INFO]   Validation MAE: 0.036284\n",
      "2025-03-10 22:58:31 [INFO] Epoch 171/200:\n",
      "2025-03-10 22:58:31 [INFO]   Training Loss: 0.002179\n",
      "2025-03-10 22:58:31 [INFO]   Training MAE: 0.039189\n",
      "2025-03-10 22:58:31 [INFO]   Validation Loss: 0.002033\n",
      "2025-03-10 22:58:31 [INFO]   Validation MAE: 0.036105\n",
      "2025-03-10 22:58:37 [INFO] Epoch 172/200:\n",
      "2025-03-10 22:58:37 [INFO]   Training Loss: 0.002084\n",
      "2025-03-10 22:58:37 [INFO]   Training MAE: 0.037756\n",
      "2025-03-10 22:58:37 [INFO]   Validation Loss: 0.001876\n",
      "2025-03-10 22:58:37 [INFO]   Validation MAE: 0.032645\n",
      "2025-03-10 22:58:44 [INFO] Epoch 173/200:\n",
      "2025-03-10 22:58:44 [INFO]   Training Loss: 0.002044\n",
      "2025-03-10 22:58:44 [INFO]   Training MAE: 0.037400\n",
      "2025-03-10 22:58:44 [INFO]   Validation Loss: 0.002049\n",
      "2025-03-10 22:58:44 [INFO]   Validation MAE: 0.036160\n",
      "2025-03-10 22:58:51 [INFO] Epoch 174/200:\n",
      "2025-03-10 22:58:51 [INFO]   Training Loss: 0.002287\n",
      "2025-03-10 22:58:51 [INFO]   Training MAE: 0.040897\n",
      "2025-03-10 22:58:51 [INFO]   Validation Loss: 0.001867\n",
      "2025-03-10 22:58:51 [INFO]   Validation MAE: 0.032971\n",
      "2025-03-10 22:58:58 [INFO] Epoch 175/200:\n",
      "2025-03-10 22:58:58 [INFO]   Training Loss: 0.002192\n",
      "2025-03-10 22:58:58 [INFO]   Training MAE: 0.038989\n",
      "2025-03-10 22:58:58 [INFO]   Validation Loss: 0.002099\n",
      "2025-03-10 22:58:58 [INFO]   Validation MAE: 0.037704\n",
      "2025-03-10 22:59:04 [INFO] Epoch 176/200:\n",
      "2025-03-10 22:59:04 [INFO]   Training Loss: 0.001956\n",
      "2025-03-10 22:59:04 [INFO]   Training MAE: 0.037099\n",
      "2025-03-10 22:59:04 [INFO]   Validation Loss: 0.001915\n",
      "2025-03-10 22:59:04 [INFO]   Validation MAE: 0.034690\n",
      "2025-03-10 22:59:11 [INFO] Epoch 177/200:\n",
      "2025-03-10 22:59:11 [INFO]   Training Loss: 0.002088\n",
      "2025-03-10 22:59:11 [INFO]   Training MAE: 0.038815\n",
      "2025-03-10 22:59:11 [INFO]   Validation Loss: 0.002105\n",
      "2025-03-10 22:59:11 [INFO]   Validation MAE: 0.038622\n",
      "2025-03-10 22:59:18 [INFO] Epoch 178/200:\n",
      "2025-03-10 22:59:18 [INFO]   Training Loss: 0.002255\n",
      "2025-03-10 22:59:18 [INFO]   Training MAE: 0.040544\n",
      "2025-03-10 22:59:18 [INFO]   Validation Loss: 0.002146\n",
      "2025-03-10 22:59:18 [INFO]   Validation MAE: 0.038355\n",
      "2025-03-10 22:59:24 [INFO] Epoch 179/200:\n",
      "2025-03-10 22:59:24 [INFO]   Training Loss: 0.002260\n",
      "2025-03-10 22:59:24 [INFO]   Training MAE: 0.040613\n",
      "2025-03-10 22:59:24 [INFO]   Validation Loss: 0.001917\n",
      "2025-03-10 22:59:24 [INFO]   Validation MAE: 0.034528\n",
      "2025-03-10 22:59:31 [INFO] Epoch 180/200:\n",
      "2025-03-10 22:59:31 [INFO]   Training Loss: 0.002046\n",
      "2025-03-10 22:59:31 [INFO]   Training MAE: 0.037926\n",
      "2025-03-10 22:59:31 [INFO]   Validation Loss: 0.001920\n",
      "2025-03-10 22:59:31 [INFO]   Validation MAE: 0.034867\n",
      "2025-03-10 22:59:38 [INFO] Epoch 181/200:\n",
      "2025-03-10 22:59:38 [INFO]   Training Loss: 0.002114\n",
      "2025-03-10 22:59:38 [INFO]   Training MAE: 0.039184\n",
      "2025-03-10 22:59:38 [INFO]   Validation Loss: 0.001864\n",
      "2025-03-10 22:59:38 [INFO]   Validation MAE: 0.034014\n",
      "2025-03-10 22:59:45 [INFO] Epoch 182/200:\n",
      "2025-03-10 22:59:45 [INFO]   Training Loss: 0.002183\n",
      "2025-03-10 22:59:45 [INFO]   Training MAE: 0.039168\n",
      "2025-03-10 22:59:45 [INFO]   Validation Loss: 0.001917\n",
      "2025-03-10 22:59:45 [INFO]   Validation MAE: 0.033499\n",
      "2025-03-10 22:59:45 [INFO] Early stopping triggered\n",
      "2025-03-10 22:59:45 [INFO] Fine-tuning completed\n",
      "2025-03-10 22:59:45 [INFO] Best validation loss: 0.001756\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Import your existing model and dataset classes\n",
    "from Train2_12 import ExperimentalGNN, SpinSystemDataset, PhysicalScaleAwareLoss\n",
    "\n",
    "# Fine-tuning configuration\n",
    "FINETUNE_CONFIG = {\n",
    "    'pretrained_model_path': 'finetuned_model_0.5lr_1.5wd.pth',\n",
    "    'data_dirs': [\n",
    "        './processed_9-10_times5_r6'\n",
    "    ],  # List of directories containing .pt files\n",
    "    'processed_file_pattern': 'data*.pt',  # Pattern to match multiple files\n",
    "    'alternative_file_paths': [\n",
    "        # Add direct paths to specific .pt files if needed\n",
    "        # './processed_data/data_v1.pt',\n",
    "        # './processed_data/data_v2.pt'\n",
    "    ],\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.5e-4,\n",
    "    'weight_decay': 1.5e-4,\n",
    "    'num_epochs': 200,\n",
    "    'patience': 50,\n",
    "    'finetuned_model_path': 'finetuned_model_9-10_1.5k.pth',\n",
    "    'dropout_p': 0.3,\n",
    "    'grad_clip': 0.5,\n",
    "    'random_seed': 42,\n",
    "    'verbose_logging': True  # Set to True for detailed debug information\n",
    "}\n",
    "\n",
    "def setup_logging():\n",
    "    level = logging.DEBUG if FINETUNE_CONFIG.get('verbose_logging', False) else logging.INFO\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "    # Create file handler\n",
    "    file_handler = logging.FileHandler('finetuning.log')\n",
    "    file_handler.setLevel(level)\n",
    "    file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))\n",
    "    \n",
    "    # Add file handler to root logger\n",
    "    logging.getLogger('').addHandler(file_handler)\n",
    "    \n",
    "    logging.info(\"Logging initialized\")\n",
    "\n",
    "class DirectPTFileDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset that loads directly from specified .pt files\"\"\"\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "        logging.info(f\"Attempting to load {len(file_paths)} PT files directly\")\n",
    "        \n",
    "        # Load all data from these files\n",
    "        self.data_list = []\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            if not os.path.exists(file_path):\n",
    "                logging.error(f\"File does not exist: {file_path}\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                logging.info(f\"Loading file: {file_path}\")\n",
    "                data_obj = torch.load(file_path)\n",
    "                \n",
    "                if isinstance(data_obj, list):\n",
    "                    logging.info(f\"Loaded list of {len(data_obj)} objects from {file_path}\")\n",
    "                    self.data_list.extend(data_obj)\n",
    "                elif hasattr(data_obj, 'x'):\n",
    "                    logging.info(f\"Loaded single data object from {file_path}\")\n",
    "                    self.data_list.append(data_obj)\n",
    "                else:\n",
    "                    logging.warning(f\"Unrecognized data format in {file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {file_path}: {str(e)}\", exc_info=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "class CustomSpinSystemDataset(SpinSystemDataset):\n",
    "    \"\"\"Extended version of SpinSystemDataset with better error handling\"\"\"\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        try:\n",
    "            # Check if the path exists\n",
    "            if not os.path.exists(root):\n",
    "                logging.error(f\"Directory does not exist: {root}\")\n",
    "                raise FileNotFoundError(f\"Directory does not exist: {root}\")\n",
    "                \n",
    "            # Try to initialize with original SpinSystemDataset\n",
    "            super(CustomSpinSystemDataset, self).__init__(root=root, transform=transform, pre_transform=pre_transform)\n",
    "            \n",
    "            # Look for processed directory and check its contents\n",
    "            processed_dir = os.path.join(root, 'processed')\n",
    "            if os.path.exists(processed_dir):\n",
    "                logging.info(f\"Processed directory exists: {processed_dir}\")\n",
    "                processed_files = os.listdir(processed_dir)\n",
    "                logging.info(f\"Files in processed directory: {processed_files}\")\n",
    "            else:\n",
    "                logging.warning(f\"No 'processed' directory found in {root}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error initializing CustomSpinSystemDataset: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "\n",
    "    def download(self):\n",
    "        # Override to avoid download attempts\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        # Override to avoid processing attempts if files already exist\n",
    "        processed_file_path = os.path.join(self.processed_dir, 'data.pt')\n",
    "        if os.path.exists(processed_file_path):\n",
    "            logging.info(f\"Processed file already exists: {processed_file_path}\")\n",
    "        else:\n",
    "            logging.warning(f\"Processed file does not exist: {processed_file_path}\")\n",
    "            # We would need to implement the processing logic here if needed\n",
    "            raise FileNotFoundError(f\"Required processed file not found: {processed_file_path}\")\n",
    "            \n",
    "    def _download(self):\n",
    "        # Override internal method\n",
    "        pass\n",
    "        \n",
    "    def _process(self):\n",
    "        # Override internal method if files exist\n",
    "        if not os.path.exists(os.path.join(self.processed_dir, 'data.pt')):\n",
    "            logging.error(f\"Processed file not found at {os.path.join(self.processed_dir, 'data.pt')}\")\n",
    "            raise FileNotFoundError(f\"Required processed file not found\")\n",
    "\n",
    "    \n",
    "    def _merge_data(self, data1, slices1, data2, slices2):\n",
    "        \"\"\"Merge two datasets together\"\"\"\n",
    "        # Create new data object with combined attributes\n",
    "        merged_data = data1.__class__()\n",
    "        \n",
    "        # Combine all attributes from both data objects\n",
    "        for key in data1.keys:\n",
    "            # Get the attribute from both datasets\n",
    "            item1, item2 = getattr(data1, key), getattr(data2, key)\n",
    "            \n",
    "            # Concatenate the attributes\n",
    "            if torch.is_tensor(item1) and torch.is_tensor(item2):\n",
    "                merged_attr = torch.cat([item1, item2], dim=data1.__cat_dim__(key, item1))\n",
    "            else:\n",
    "                merged_attr = item1 + item2  # For non-tensor attributes like edge_index\n",
    "                \n",
    "            setattr(merged_data, key, merged_attr)\n",
    "            \n",
    "        # Update the slices for the merged data\n",
    "        merged_slices = {}\n",
    "        for key in slices1.keys():\n",
    "            if key in slices2:\n",
    "                # Get the current maximum index from the first slice\n",
    "                offset = slices1[key][-1]\n",
    "                \n",
    "                # Add this offset to all indices in the second slice (except the first one)\n",
    "                second_slice_shifted = slices2[key][1:] + offset\n",
    "                \n",
    "                # Combine the slices, keeping only one copy of the overlapping index\n",
    "                merged_slice = torch.cat([slices1[key], second_slice_shifted])\n",
    "                merged_slices[key] = merged_slice\n",
    "        \n",
    "        return merged_data, merged_slices\n",
    "\n",
    "def load_multi_datasets():\n",
    "    \"\"\"Load multiple datasets from different directories\"\"\"\n",
    "    datasets = []\n",
    "    \n",
    "    # First check all directories for processed/data.pt files (PyG default)\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        # Check for processed/data.pt (standard PyG dataset structure)\n",
    "        pyg_file_path = os.path.join(data_dir, 'processed', 'data.pt')\n",
    "        if os.path.exists(pyg_file_path):\n",
    "            logging.info(f\"Found PyG dataset file: {pyg_file_path}\")\n",
    "    \n",
    "    # Check for pattern-matched files within the directories\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if os.path.exists(data_dir):\n",
    "            # First check in the main directory\n",
    "            pattern = os.path.join(data_dir, FINETUNE_CONFIG['processed_file_pattern'])\n",
    "            main_files = glob.glob(pattern)\n",
    "            \n",
    "            # Then check in the processed subdirectory\n",
    "            processed_pattern = os.path.join(data_dir, 'processed', FINETUNE_CONFIG['processed_file_pattern'])\n",
    "            processed_files = glob.glob(processed_pattern)\n",
    "            \n",
    "            all_files = main_files + processed_files\n",
    "            logging.info(f\"Found {len(all_files)} files in {data_dir} matching the pattern\")\n",
    "            for file in all_files:\n",
    "                logging.info(f\"  - {file}\")\n",
    "    \n",
    "    # Attempt each loading method\n",
    "    # 1. Try loading as standard PyG SpinSystemDataset from each directory\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if not os.path.exists(data_dir):\n",
    "            logging.error(f\"Directory does not exist: {data_dir}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            logging.info(f\"Attempting to load PyG dataset from {data_dir}\")\n",
    "            dataset = CustomSpinSystemDataset(root=data_dir)\n",
    "            datasets.append(dataset)\n",
    "            logging.info(f\"Successfully loaded PyG dataset from {data_dir} with {len(dataset)} samples\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not load PyG dataset from {data_dir}: {str(e)}\")\n",
    "            \n",
    "            # Check for data.pt in the processed directory\n",
    "            processed_file = os.path.join(data_dir, 'processed', 'data.pt')\n",
    "            if os.path.exists(processed_file):\n",
    "                try:\n",
    "                    logging.info(f\"Attempting to load direct data from {processed_file}\")\n",
    "                    # Try to load this specific file directly\n",
    "                    direct_dataset = DirectPTFileDataset([processed_file])\n",
    "                    if len(direct_dataset) > 0:\n",
    "                        datasets.append(direct_dataset)\n",
    "                        logging.info(f\"Loaded {len(direct_dataset)} samples directly from {processed_file}\")\n",
    "                except Exception as direct_e:\n",
    "                    logging.error(f\"Failed to load direct file {processed_file}: {str(direct_e)}\")\n",
    "    \n",
    "    # 2. Try loading from additional specified PT files\n",
    "    if hasattr(FINETUNE_CONFIG, 'alternative_file_paths') and FINETUNE_CONFIG['alternative_file_paths']:\n",
    "        direct_dataset = DirectPTFileDataset(FINETUNE_CONFIG['alternative_file_paths'])\n",
    "        if len(direct_dataset) > 0:\n",
    "            datasets.append(direct_dataset)\n",
    "            logging.info(f\"Loaded {len(direct_dataset)} samples from specified PT files\")\n",
    "    \n",
    "    # 3. If all else fails, request the proper file path\n",
    "    if not datasets:\n",
    "        logging.error(\"\"\"\n",
    "        No datasets could be loaded from the specified directories.\n",
    "        \n",
    "        Please check the following:\n",
    "        1. Verify that your data directories exist\n",
    "        2. Check that PyG dataset files are in a 'processed/data.pt' path\n",
    "        3. Try specifying direct paths to PT files in 'alternative_file_paths'\n",
    "        \"\"\")\n",
    "        \n",
    "        # Get user input for data file path\n",
    "        print(\"\\nNo datasets could be loaded from the specified directories.\")\n",
    "        print(\"Please enter the path to a PyTorch Geometric dataset file (data.pt):\")\n",
    "        file_path = input(\"Path: \").strip()\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Try to load it as a direct PT file\n",
    "                direct_dataset = DirectPTFileDataset([file_path])\n",
    "                if len(direct_dataset) > 0:\n",
    "                    datasets.append(direct_dataset)\n",
    "                    logging.info(f\"Loaded {len(direct_dataset)} samples from user-specified {file_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to load user-specified file: {str(e)}\")\n",
    "                \n",
    "                # Last resort - try to find parent directory and load as PyG dataset\n",
    "                parent_dir = os.path.dirname(os.path.dirname(file_path))\n",
    "                try:\n",
    "                    dataset = CustomSpinSystemDataset(root=parent_dir)\n",
    "                    datasets.append(dataset)\n",
    "                    logging.info(f\"Loaded PyG dataset from {parent_dir} with {len(dataset)} samples\")\n",
    "                except Exception as pe:\n",
    "                    logging.error(f\"Failed to load from parent directory {parent_dir}: {str(pe)}\")\n",
    "                    raise ValueError(\"No datasets could be loaded. Please check your data files.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Specified file does not exist: {file_path}\")\n",
    "    \n",
    "    # Combine all datasets\n",
    "    combined_dataset = ConcatDataset(datasets) if len(datasets) > 0 else None\n",
    "    if combined_dataset:\n",
    "        logging.info(f\"Combined dataset contains {len(combined_dataset)} samples total\")\n",
    "    else:\n",
    "        raise ValueError(\"No datasets could be loaded\")\n",
    "    \n",
    "    return combined_dataset\n",
    "\n",
    "def fine_tune_model():\n",
    "    setup_logging()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Print out current working directory and available files for debugging\n",
    "    logging.info(f\"Current working directory: {os.getcwd()}\")\n",
    "    for data_dir in FINETUNE_CONFIG['data_dirs']:\n",
    "        if os.path.exists(data_dir):\n",
    "            logging.info(f\"Directory {data_dir} exists\")\n",
    "            files = os.listdir(data_dir)\n",
    "            logging.info(f\"Files in {data_dir}: {files}\")\n",
    "            # Check if processed_dir exists\n",
    "            processed_dir = os.path.join(data_dir, 'processed')\n",
    "            if os.path.exists(processed_dir):\n",
    "                logging.info(f\"Processed directory exists: {processed_dir}\")\n",
    "                processed_files = os.listdir(processed_dir)\n",
    "                logging.info(f\"Files in processed dir: {processed_files}\")\n",
    "        else:\n",
    "            logging.error(f\"Directory {data_dir} does not exist!\")\n",
    "    \n",
    "    # Load the pretrained model\n",
    "    try:\n",
    "        model = ExperimentalGNN(\n",
    "            hidden_channels=512,\n",
    "            dropout_p=FINETUNE_CONFIG['dropout_p']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Check if pretrained model file exists\n",
    "        if not os.path.exists(FINETUNE_CONFIG['pretrained_model_path']):\n",
    "            logging.error(f\"Pretrained model file not found: {FINETUNE_CONFIG['pretrained_model_path']}\")\n",
    "            raise FileNotFoundError(f\"Pretrained model file not found: {FINETUNE_CONFIG['pretrained_model_path']}\")\n",
    "            \n",
    "        # Load pretrained weights\n",
    "        pretrained_state_dict = torch.load(FINETUNE_CONFIG['pretrained_model_path'], map_location=device)\n",
    "        model.load_state_dict(pretrained_state_dict)\n",
    "        logging.info(\"Loaded pretrained model successfully\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading model: {str(e)}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "    # Load datasets from multiple directories\n",
    "    combined_dataset = load_multi_datasets()\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(combined_dataset))\n",
    "    val_size = len(combined_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        combined_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(FINETUNE_CONFIG['random_seed'])\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=FINETUNE_CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "    # Initialize loss and optimizer\n",
    "    criterion = PhysicalScaleAwareLoss(physics_weight=0.5)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=FINETUNE_CONFIG['learning_rate'],\n",
    "        weight_decay=FINETUNE_CONFIG['weight_decay']\n",
    "    )\n",
    "\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=20,\n",
    "        T_mult=2,\n",
    "        eta_min=1e-7\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(FINETUNE_CONFIG['num_epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_mae = 0\n",
    "        total_train_samples = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            pred_s = model(data)\n",
    "            targets = data.y.squeeze().to(device)\n",
    "            system_size = data.system_size.squeeze(-1).to(device)\n",
    "            subsystem_size = data.nA.squeeze(-1).to(device)\n",
    "            \n",
    "            loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "            loss.backward()\n",
    "            \n",
    "            if FINETUNE_CONFIG['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), FINETUNE_CONFIG['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate MAE for this batch\n",
    "            mae = torch.abs(pred_s - targets).sum().item()\n",
    "            train_mae += mae\n",
    "            total_train_samples += data.num_graphs\n",
    "            total_train_loss += loss.item() * data.num_graphs\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataset)\n",
    "        avg_train_mae = train_mae / total_train_samples\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_mae = 0\n",
    "        total_val_samples = 0\n",
    "        all_val_preds = []\n",
    "        all_val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                pred_s = model(data)\n",
    "                targets = data.y.squeeze().to(device)\n",
    "                system_size = data.system_size.squeeze(-1).to(device)\n",
    "                subsystem_size = data.nA.squeeze(-1).to(device)\n",
    "                \n",
    "                loss = criterion(pred_s, targets, system_size, subsystem_size)\n",
    "                total_val_loss += loss.item() * data.num_graphs\n",
    "                \n",
    "                # Calculate MAE for this batch\n",
    "                mae = torch.abs(pred_s - targets).sum().item()\n",
    "                val_mae += mae\n",
    "                total_val_samples += data.num_graphs\n",
    "                \n",
    "                # Store CPU tensors for numpy conversion\n",
    "                all_val_preds.extend(pred_s.cpu().numpy())\n",
    "                all_val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_dataset)\n",
    "        avg_val_mae = val_mae / total_val_samples\n",
    "        scheduler.step()\n",
    "\n",
    "        logging.info(f'Epoch {epoch+1}/{FINETUNE_CONFIG[\"num_epochs\"]}:')\n",
    "        logging.info(f'  Training Loss: {avg_train_loss:.6f}')\n",
    "        logging.info(f'  Training MAE: {avg_train_mae:.6f}')\n",
    "        logging.info(f'  Validation Loss: {avg_val_loss:.6f}')\n",
    "        logging.info(f'  Validation MAE: {avg_val_mae:.6f}')\n",
    "\n",
    "        # Save best model and early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), FINETUNE_CONFIG['finetuned_model_path'])\n",
    "            logging.info(f'  Saved new best model (val_loss={best_val_loss:.6f})')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= FINETUNE_CONFIG['patience']:\n",
    "                logging.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    logging.info('Fine-tuning completed')\n",
    "    logging.info(f'Best validation loss: {best_val_loss:.6f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fine_tune_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
