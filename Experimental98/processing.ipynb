{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c34303-84a2-4935-88a0-6fc112ed2c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amssa\\AppData\\Local\\Temp\\ipykernel_28532\\438414421.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(data_path)\n",
      "2025-01-19 03:13:39,732 [INFO] Loaded dataset with 5000 samples\n",
      "2025-01-19 03:13:39,732 [INFO] Verifying Mutual Information bounds...\n",
      "2025-01-19 03:13:40,257 [INFO] \n",
      "Mutual Information Bound Analysis:\n",
      "2025-01-19 03:13:40,258 [INFO] Total samples analyzed: 5000\n",
      "2025-01-19 03:13:40,258 [INFO] Number of violations: 518\n",
      "2025-01-19 03:13:40,260 [INFO] Overall violation rate: 10.3600%\n",
      "2025-01-19 03:13:40,260 [INFO] Maximum violation: 0.530045\n",
      "2025-01-19 03:13:40,261 [INFO] System sizes with violations: [2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0]\n",
      "2025-01-19 03:13:40,261 [INFO] \n",
      "Top 10 worst violations:\n",
      "2025-01-19 03:13:40,261 [INFO]   Size 12.0 (nA=7, nB=5): MI=0.973731, VN=0.443687, Diff=0.530045\n",
      "2025-01-19 03:13:40,262 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.698826, VN=0.655488, Diff=0.043338\n",
      "2025-01-19 03:13:40,263 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.698107, VN=0.660415, Diff=0.037692\n",
      "2025-01-19 03:13:40,264 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.043036, VN=0.007637, Diff=0.035398\n",
      "2025-01-19 03:13:40,264 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.040381, VN=0.005473, Diff=0.034908\n",
      "2025-01-19 03:13:40,264 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.053921, VN=0.021417, Diff=0.032504\n",
      "2025-01-19 03:13:40,265 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.697582, VN=0.665234, Diff=0.032348\n",
      "2025-01-19 03:13:40,265 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.050177, VN=0.018288, Diff=0.031889\n",
      "2025-01-19 03:13:40,265 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.043756, VN=0.014000, Diff=0.029756\n",
      "2025-01-19 03:13:40,266 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.697731, VN=0.668357, Diff=0.029374\n",
      "2025-01-19 03:13:40,266 [INFO] \n",
      "Statistics per system size:\n",
      "2025-01-19 03:13:40,266 [INFO] Size 2.0:\n",
      "2025-01-19 03:13:40,266 [INFO]   Samples: 657\n",
      "2025-01-19 03:13:40,268 [INFO]   Violation rate: 17.5038%\n",
      "2025-01-19 03:13:40,268 [INFO]   Mean MI/VN ratio: 25.5728\n",
      "2025-01-19 03:13:40,268 [INFO]   Max MI/VN ratio: 9735.7139\n",
      "2025-01-19 03:13:40,269 [INFO] Size 4.0:\n",
      "2025-01-19 03:13:40,270 [INFO]   Samples: 717\n",
      "2025-01-19 03:13:40,271 [INFO]   Violation rate: 11.0181%\n",
      "2025-01-19 03:13:40,272 [INFO]   Mean MI/VN ratio: 0.7312\n",
      "2025-01-19 03:13:40,272 [INFO]   Max MI/VN ratio: 2.7868\n",
      "2025-01-19 03:13:40,272 [INFO] Size 6.0:\n",
      "2025-01-19 03:13:40,272 [INFO]   Samples: 733\n",
      "2025-01-19 03:13:40,273 [INFO]   Violation rate: 13.3697%\n",
      "2025-01-19 03:13:40,274 [INFO]   Mean MI/VN ratio: 8.1206\n",
      "2025-01-19 03:13:40,274 [INFO]   Max MI/VN ratio: 1700.8682\n",
      "2025-01-19 03:13:40,274 [INFO] Size 8.0:\n",
      "2025-01-19 03:13:40,274 [INFO]   Samples: 732\n",
      "2025-01-19 03:13:40,275 [INFO]   Violation rate: 6.0109%\n",
      "2025-01-19 03:13:40,275 [INFO]   Mean MI/VN ratio: 1.6924\n",
      "2025-01-19 03:13:40,276 [INFO]   Max MI/VN ratio: 713.6320\n",
      "2025-01-19 03:13:40,276 [INFO] Size 10.0:\n",
      "2025-01-19 03:13:40,277 [INFO]   Samples: 762\n",
      "2025-01-19 03:13:40,277 [INFO]   Violation rate: 9.7113%\n",
      "2025-01-19 03:13:40,278 [INFO]   Mean MI/VN ratio: 4.9833\n",
      "2025-01-19 03:13:40,278 [INFO]   Max MI/VN ratio: 1990.7725\n",
      "2025-01-19 03:13:40,279 [INFO] Size 12.0:\n",
      "2025-01-19 03:13:40,279 [INFO]   Samples: 680\n",
      "2025-01-19 03:13:40,280 [INFO]   Violation rate: 7.2059%\n",
      "2025-01-19 03:13:40,280 [INFO]   Mean MI/VN ratio: 0.6986\n",
      "2025-01-19 03:13:40,281 [INFO]   Max MI/VN ratio: 2.1946\n",
      "2025-01-19 03:13:40,281 [INFO] Size 14.0:\n",
      "2025-01-19 03:13:40,282 [INFO]   Samples: 719\n",
      "2025-01-19 03:13:40,282 [INFO]   Violation rate: 8.2058%\n",
      "2025-01-19 03:13:40,282 [INFO]   Mean MI/VN ratio: 6.0055\n",
      "2025-01-19 03:13:40,283 [INFO]   Max MI/VN ratio: 3625.8649\n",
      "2025-01-19 03:13:40,334 [WARNING] Found violations! Details saved to mi_violations.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "\n",
    "class SimpleDataset:\n",
    "    \"\"\"Simplified dataset class to load the processed data.pt file\"\"\"\n",
    "    def __init__(self, root='./processed_experimental/processed'):\n",
    "        data_path = os.path.join(root, 'data.pt')\n",
    "        self.data, self.slices = torch.load(data_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.slices['x'].size(0) - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return [self[i] for i in range(*idx.indices(len(self)))]\n",
    "        \n",
    "        # Create a class to hold the data similar to Data object\n",
    "        class DataObject:\n",
    "            pass\n",
    "        \n",
    "        data = DataObject()\n",
    "        \n",
    "        for key in self.slices.keys():\n",
    "            item, slices = self.data[key], self.slices[key]\n",
    "            s, e = slices[idx].item(), slices[idx + 1].item()\n",
    "            data.__setattr__(key, item[s:e])\n",
    "        \n",
    "        return data\n",
    "\n",
    "def verify_mutual_information_bound(dataset):\n",
    "    \"\"\"\n",
    "    Verify that mutual information is always lower than or equal to von Neumann entropy\n",
    "    and analyze any violations.\n",
    "    \"\"\"\n",
    "    logging.info(\"Verifying Mutual Information bounds...\")\n",
    "    \n",
    "    violations = []\n",
    "    violation_sizes = []\n",
    "    max_violation = 0\n",
    "    total_samples = len(dataset)\n",
    "    \n",
    "    # Collect statistics per system size\n",
    "    size_stats = {}\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        data = dataset[idx]\n",
    "        mi = data.mutual_info.item()\n",
    "        vn = data.y.item()  # von Neumann entropy\n",
    "        system_size = data.system_size.item()\n",
    "        \n",
    "        # Check if MI > VN (allowing for small numerical errors)\n",
    "        if mi > vn + 1e-6:  # tolerance of 1e-6\n",
    "            violations.append({\n",
    "                'idx': idx,\n",
    "                'mi': mi,\n",
    "                'vn': vn,\n",
    "                'difference': mi - vn,\n",
    "                'system_size': system_size,\n",
    "                'nA': data.nA.item(),\n",
    "                'nB': data.nB.item()\n",
    "            })\n",
    "            violation_sizes.append(system_size)\n",
    "            max_violation = max(max_violation, mi - vn)\n",
    "            \n",
    "        # Update size statistics\n",
    "        if system_size not in size_stats:\n",
    "            size_stats[system_size] = {\n",
    "                'count': 0,\n",
    "                'violations': 0,\n",
    "                'max_ratio': 0,  # MI/VN ratio\n",
    "                'mean_ratio': 0,\n",
    "                'ratios': []\n",
    "            }\n",
    "        \n",
    "        stats = size_stats[system_size]\n",
    "        stats['count'] += 1\n",
    "        if mi > vn + 1e-6:\n",
    "            stats['violations'] += 1\n",
    "        \n",
    "        # Calculate MI/VN ratio\n",
    "        ratio = mi / (vn + 1e-10)  # avoid division by zero\n",
    "        stats['ratios'].append(ratio)\n",
    "        stats['max_ratio'] = max(stats['max_ratio'], ratio)\n",
    "\n",
    "        # Print progress every 10k samples\n",
    "        if (idx + 1) % 10000 == 0:\n",
    "            logging.info(f\"Processed {idx + 1}/{total_samples} samples...\")\n",
    "    \n",
    "    # Compute final statistics per size\n",
    "    for size, stats in size_stats.items():\n",
    "        stats['violation_rate'] = (stats['violations'] / stats['count']) * 100\n",
    "        stats['mean_ratio'] = np.mean(stats['ratios'])\n",
    "    \n",
    "    # Print summary\n",
    "    logging.info(f\"\\nMutual Information Bound Analysis:\")\n",
    "    logging.info(f\"Total samples analyzed: {total_samples}\")\n",
    "    logging.info(f\"Number of violations: {len(violations)}\")\n",
    "    logging.info(f\"Overall violation rate: {(len(violations)/total_samples)*100:.4f}%\")\n",
    "    if violations:\n",
    "        logging.info(f\"Maximum violation: {max_violation:.6f}\")\n",
    "        logging.info(f\"System sizes with violations: {sorted(set(violation_sizes))}\")\n",
    "        \n",
    "        logging.info(\"\\nTop 10 worst violations:\")\n",
    "        sorted_violations = sorted(violations, key=lambda x: x['difference'], reverse=True)\n",
    "        for v in sorted_violations[:10]:\n",
    "            logging.info(\n",
    "                f\"  Size {v['system_size']:2} (nA={v['nA']:.0f}, nB={v['nB']:.0f}): \"\n",
    "                f\"MI={v['mi']:.6f}, VN={v['vn']:.6f}, Diff={v['difference']:.6f}\"\n",
    "            )\n",
    "    \n",
    "    logging.info(\"\\nStatistics per system size:\")\n",
    "    for size in sorted(size_stats.keys()):\n",
    "        stats = size_stats[size]\n",
    "        logging.info(f\"Size {size:2}:\")\n",
    "        logging.info(f\"  Samples: {stats['count']}\")\n",
    "        logging.info(f\"  Violation rate: {stats['violation_rate']:.4f}%\")\n",
    "        logging.info(f\"  Mean MI/VN ratio: {stats['mean_ratio']:.4f}\")\n",
    "        logging.info(f\"  Max MI/VN ratio: {stats['max_ratio']:.4f}\")\n",
    "    \n",
    "    return violations, size_stats\n",
    "\n",
    "def main():\n",
    "    setup_logging()\n",
    "    \n",
    "    # Load dataset\n",
    "    try:\n",
    "        dataset = SimpleDataset()\n",
    "        logging.info(f\"Loaded dataset with {len(dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Verify MI bounds\n",
    "    violations, size_stats = verify_mutual_information_bound(dataset)\n",
    "    \n",
    "    # Save violations if any found\n",
    "    if violations:\n",
    "        violation_data = pd.DataFrame(violations)\n",
    "        violation_data.to_csv('mi_violations.csv', index=False)\n",
    "        logging.warning(f\"Found violations! Details saved to mi_violations.csv\")\n",
    "    else:\n",
    "        logging.info(\"No violations found - MI is a proper lower bound for VN entropy\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4425f7-9185-4d5c-8b86-7553eb0acfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amssa\\AppData\\Local\\Temp\\ipykernel_28532\\438414421.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(data_path)\n",
      "2025-01-19 03:22:31,655 [INFO] Loaded dataset with 5000 samples\n",
      "2025-01-19 03:22:31,656 [INFO] Verifying Mutual Information bounds...\n",
      "2025-01-19 03:22:32,164 [INFO] \n",
      "Mutual Information Bound Analysis:\n",
      "2025-01-19 03:22:32,165 [INFO] Total samples analyzed: 5000\n",
      "2025-01-19 03:22:32,165 [INFO] Number of violations: 518\n",
      "2025-01-19 03:22:32,166 [INFO] Overall violation rate: 10.3600%\n",
      "2025-01-19 03:22:32,166 [INFO] Maximum violation: 0.530045\n",
      "2025-01-19 03:22:32,167 [INFO] System sizes with violations: [2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0]\n",
      "2025-01-19 03:22:32,167 [INFO] \n",
      "Top 10 worst violations:\n",
      "2025-01-19 03:22:32,167 [INFO]   Size 12.0 (nA=7, nB=5): MI=0.973731, VN=0.443687, Diff=0.530045\n",
      "2025-01-19 03:22:32,167 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.698826, VN=0.655488, Diff=0.043338\n",
      "2025-01-19 03:22:32,167 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.698107, VN=0.660415, Diff=0.037692\n",
      "2025-01-19 03:22:32,169 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.043036, VN=0.007637, Diff=0.035398\n",
      "2025-01-19 03:22:32,169 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.040381, VN=0.005473, Diff=0.034908\n",
      "2025-01-19 03:22:32,170 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.053921, VN=0.021417, Diff=0.032504\n",
      "2025-01-19 03:22:32,170 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.697582, VN=0.665234, Diff=0.032348\n",
      "2025-01-19 03:22:32,170 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.050177, VN=0.018288, Diff=0.031889\n",
      "2025-01-19 03:22:32,171 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.043756, VN=0.014000, Diff=0.029756\n",
      "2025-01-19 03:22:32,172 [INFO]   Size 2.0 (nA=1, nB=1): MI=0.697731, VN=0.668357, Diff=0.029374\n",
      "2025-01-19 03:22:32,172 [INFO] \n",
      "Statistics per system size:\n",
      "2025-01-19 03:22:32,172 [INFO] Size 2.0:\n",
      "2025-01-19 03:22:32,174 [INFO]   Samples: 657\n",
      "2025-01-19 03:22:32,175 [INFO]   Violation rate: 17.5038%\n",
      "2025-01-19 03:22:32,175 [INFO]   Mean MI/VN ratio: 25.5728\n",
      "2025-01-19 03:22:32,176 [INFO]   Max MI/VN ratio: 9735.7139\n",
      "2025-01-19 03:22:32,176 [INFO] Size 4.0:\n",
      "2025-01-19 03:22:32,177 [INFO]   Samples: 717\n",
      "2025-01-19 03:22:32,177 [INFO]   Violation rate: 11.0181%\n",
      "2025-01-19 03:22:32,178 [INFO]   Mean MI/VN ratio: 0.7312\n",
      "2025-01-19 03:22:32,178 [INFO]   Max MI/VN ratio: 2.7868\n",
      "2025-01-19 03:22:32,178 [INFO] Size 6.0:\n",
      "2025-01-19 03:22:32,180 [INFO]   Samples: 733\n",
      "2025-01-19 03:22:32,180 [INFO]   Violation rate: 13.3697%\n",
      "2025-01-19 03:22:32,180 [INFO]   Mean MI/VN ratio: 8.1206\n",
      "2025-01-19 03:22:32,181 [INFO]   Max MI/VN ratio: 1700.8682\n",
      "2025-01-19 03:22:32,181 [INFO] Size 8.0:\n",
      "2025-01-19 03:22:32,182 [INFO]   Samples: 732\n",
      "2025-01-19 03:22:32,183 [INFO]   Violation rate: 6.0109%\n",
      "2025-01-19 03:22:32,183 [INFO]   Mean MI/VN ratio: 1.6924\n",
      "2025-01-19 03:22:32,184 [INFO]   Max MI/VN ratio: 713.6320\n",
      "2025-01-19 03:22:32,185 [INFO] Size 10.0:\n",
      "2025-01-19 03:22:32,186 [INFO]   Samples: 762\n",
      "2025-01-19 03:22:32,186 [INFO]   Violation rate: 9.7113%\n",
      "2025-01-19 03:22:32,186 [INFO]   Mean MI/VN ratio: 4.9833\n",
      "2025-01-19 03:22:32,187 [INFO]   Max MI/VN ratio: 1990.7725\n",
      "2025-01-19 03:22:32,187 [INFO] Size 12.0:\n",
      "2025-01-19 03:22:32,187 [INFO]   Samples: 680\n",
      "2025-01-19 03:22:32,188 [INFO]   Violation rate: 7.2059%\n",
      "2025-01-19 03:22:32,188 [INFO]   Mean MI/VN ratio: 0.6986\n",
      "2025-01-19 03:22:32,189 [INFO]   Max MI/VN ratio: 2.1946\n",
      "2025-01-19 03:22:32,189 [INFO] Size 14.0:\n",
      "2025-01-19 03:22:32,190 [INFO]   Samples: 719\n",
      "2025-01-19 03:22:32,191 [INFO]   Violation rate: 8.2058%\n",
      "2025-01-19 03:22:32,191 [INFO]   Mean MI/VN ratio: 6.0055\n",
      "2025-01-19 03:22:32,192 [INFO]   Max MI/VN ratio: 3625.8649\n",
      "2025-01-19 03:22:32,197 [WARNING] Found violations! Details saved to mi_violations.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "\n",
    "class SimpleDataset:\n",
    "    \"\"\"Simplified dataset class to load the processed data.pt file\"\"\"\n",
    "    def __init__(self, root='./processed_experimental/processed'):\n",
    "        data_path = os.path.join(root, 'data.pt')\n",
    "        self.data, self.slices = torch.load(data_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.slices['x'].size(0) - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return [self[i] for i in range(*idx.indices(len(self)))]\n",
    "        \n",
    "        # Create a class to hold the data similar to Data object\n",
    "        class DataObject:\n",
    "            pass\n",
    "        \n",
    "        data = DataObject()\n",
    "        \n",
    "        for key in self.slices.keys():\n",
    "            item, slices = self.data[key], self.slices[key]\n",
    "            s, e = slices[idx].item(), slices[idx + 1].item()\n",
    "            data.__setattr__(key, item[s:e])\n",
    "        \n",
    "        return data\n",
    "\n",
    "def verify_mutual_information_bound(dataset):\n",
    "    \"\"\"\n",
    "    Verify that mutual information is always lower than or equal to von Neumann entropy\n",
    "    and analyze any violations.\n",
    "    \"\"\"\n",
    "    logging.info(\"Verifying Mutual Information bounds...\")\n",
    "    \n",
    "    violations = []\n",
    "    violation_sizes = []\n",
    "    max_violation = 0\n",
    "    total_samples = len(dataset)\n",
    "    \n",
    "    # Collect statistics per system size\n",
    "    size_stats = {}\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        data = dataset[idx]\n",
    "        mi = data.mutual_info.item()\n",
    "        vn = data.y.item()  # von Neumann entropy\n",
    "        system_size = data.system_size.item()\n",
    "        \n",
    "        # Check if MI > VN (allowing for small numerical errors)\n",
    "        if mi > vn + 1e-6:  # tolerance of 1e-6\n",
    "            violations.append({\n",
    "                'idx': idx,\n",
    "                'mi': mi,\n",
    "                'vn': vn,\n",
    "                'difference': mi - vn,\n",
    "                'system_size': system_size,\n",
    "                'nA': data.nA.item(),\n",
    "                'nB': data.nB.item()\n",
    "            })\n",
    "            violation_sizes.append(system_size)\n",
    "            max_violation = max(max_violation, mi - vn)\n",
    "            \n",
    "        # Update size statistics\n",
    "        if system_size not in size_stats:\n",
    "            size_stats[system_size] = {\n",
    "                'count': 0,\n",
    "                'violations': 0,\n",
    "                'max_ratio': 0,  # MI/VN ratio\n",
    "                'mean_ratio': 0,\n",
    "                'ratios': []\n",
    "            }\n",
    "        \n",
    "        stats = size_stats[system_size]\n",
    "        stats['count'] += 1\n",
    "        if mi > vn + 1e-6:\n",
    "            stats['violations'] += 1\n",
    "        \n",
    "        # Calculate MI/VN ratio\n",
    "        ratio = mi / (vn + 1e-10)  # avoid division by zero\n",
    "        stats['ratios'].append(ratio)\n",
    "        stats['max_ratio'] = max(stats['max_ratio'], ratio)\n",
    "\n",
    "        # Print progress every 10k samples\n",
    "        if (idx + 1) % 10000 == 0:\n",
    "            logging.info(f\"Processed {idx + 1}/{total_samples} samples...\")\n",
    "    \n",
    "    # Compute final statistics per size\n",
    "    for size, stats in size_stats.items():\n",
    "        stats['violation_rate'] = (stats['violations'] / stats['count']) * 100\n",
    "        stats['mean_ratio'] = np.mean(stats['ratios'])\n",
    "    \n",
    "    # Print summary\n",
    "    logging.info(f\"\\nMutual Information Bound Analysis:\")\n",
    "    logging.info(f\"Total samples analyzed: {total_samples}\")\n",
    "    logging.info(f\"Number of violations: {len(violations)}\")\n",
    "    logging.info(f\"Overall violation rate: {(len(violations)/total_samples)*100:.4f}%\")\n",
    "    if violations:\n",
    "        logging.info(f\"Maximum violation: {max_violation:.6f}\")\n",
    "        logging.info(f\"System sizes with violations: {sorted(set(violation_sizes))}\")\n",
    "        \n",
    "        logging.info(\"\\nTop 10 worst violations:\")\n",
    "        sorted_violations = sorted(violations, key=lambda x: x['difference'], reverse=True)\n",
    "        for v in sorted_violations[:10]:\n",
    "            logging.info(\n",
    "                f\"  Size {v['system_size']:2} (nA={v['nA']:.0f}, nB={v['nB']:.0f}): \"\n",
    "                f\"MI={v['mi']:.6f}, VN={v['vn']:.6f}, Diff={v['difference']:.6f}\"\n",
    "            )\n",
    "    \n",
    "    logging.info(\"\\nStatistics per system size:\")\n",
    "    for size in sorted(size_stats.keys()):\n",
    "        stats = size_stats[size]\n",
    "        logging.info(f\"Size {size:2}:\")\n",
    "        logging.info(f\"  Samples: {stats['count']}\")\n",
    "        logging.info(f\"  Violation rate: {stats['violation_rate']:.4f}%\")\n",
    "        logging.info(f\"  Mean MI/VN ratio: {stats['mean_ratio']:.4f}\")\n",
    "        logging.info(f\"  Max MI/VN ratio: {stats['max_ratio']:.4f}\")\n",
    "    \n",
    "    return violations, size_stats\n",
    "\n",
    "def main():\n",
    "    setup_logging()\n",
    "    \n",
    "    # Load dataset\n",
    "    try:\n",
    "        dataset = SimpleDataset()\n",
    "        logging.info(f\"Loaded dataset with {len(dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Verify MI bounds\n",
    "    violations, size_stats = verify_mutual_information_bound(dataset)\n",
    "    \n",
    "    # Save violations if any found\n",
    "    if violations:\n",
    "        violation_data = pd.DataFrame(violations)\n",
    "        violation_data.to_csv('mi_violations.csv', index=False)\n",
    "        logging.warning(f\"Found violations! Details saved to mi_violations.csv\")\n",
    "    else:\n",
    "        logging.info(\"No violations found - MI is a proper lower bound for VN entropy\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fb4ac-79fd-4b26-ac7c-4983aac5684c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
